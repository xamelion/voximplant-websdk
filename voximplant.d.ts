// Generated by dts-bundle v0.7.3

declare module 'voximplant-websdk' {
    import { Client } from "voximplant-websdk/Client";
    import Messaging from "voximplant-websdk/Messaging";
    export { Messaging } from "voximplant-websdk/Messaging";
    export { Events } from "voximplant-websdk/Events";
    export { CallEvents } from "voximplant-websdk/Call/CallEvents";
    export { Endpoint } from "voximplant-websdk/Call/EndPoints/Endpoint";
    export { EndpointEvents } from "voximplant-websdk/Call/EndPoints/EndpointEvents";
    export { OperatorACDStatuses, LoginTokens, VideoFlags, LogRecord, CallstatsIoParams } from "voximplant-websdk/Structures";
    export { LogCategory, LogLevel, ClientState } from "voximplant-websdk/Logger";
    export * from "voximplant-websdk/Hardware/index";
    /**
        * Get a [Client] instance to use platform functions
        * @example
        *  var vox = VoxImplant.getInstance();
        *  vox.init({micRequired: true});
        *  vox.addEventListener(VoxImplant.Events.SDKReady, handleSDKReady);
        * @returns {Client}
        */
    export function getInstance(): Client;
    /**
        * VoxImplant Web SDK lib version
        */
    export const version: string;
    /**
        * Get a [Messenger] instance to use Messaging functions
        * @returns {Messenger}
        *
        */
    export function getMessenger(): Messaging.Messenger;
}

declare module 'voximplant-websdk/Client' {
    import { Call } from 'voximplant-websdk/Call/Call';
    import { AudioOutputInfo, AudioSourceInfo, CallSettings, Config, LoginOptions, LogRecord, OperatorACDStatuses, VideoFlags, VideoSettings, VideoSourceInfo } from 'voximplant-websdk/Structures';
    import { Events } from 'voximplant-websdk/Events';
    import { VoxSignalingHandler } from 'voximplant-websdk/Signaling/VoxSignalingHandler';
    import { ClientState, LogCategory, LogLevel } from 'voximplant-websdk/Logger';
    import { EventListenerOption, EventTarget } from 'voximplant-websdk/EventTarget';
    import { ZingayaAPI } from 'voximplant-websdk/Legacy/ZingayaAPI';
    import { EventHandlers } from 'voximplant-websdk/EventHandlers';
    import { MediaRenderer } from 'voximplant-websdk/Media/MediaRenderer';
    import AuthTokenResult = EventHandlers.AuthTokenResult;
    /**
        * The Client class is used to control platform functions. Can't be instantiated directly (singleton), so use the [getInstance] method to get the class instance.
        *
        *
        * Example:
        * ``` jss
        * // Getting an instance
        * const vox = VoxImplant.getInstance();
        * ```
    
        */
    export class Client extends EventTarget<Events> implements VoxSignalingHandler {
            /**
                * @hidden
                */
            videoSupport: boolean;
            /**
                * @hidden
                */
            localVideoContainerId: string;
            /**
                * @hidden
                */
            remoteVideoContainerId: string;
            /**
                * @hidden
                */
            _defaultSinkId: string;
            /**
                * @hidden
                */
            loginState: number;
            /**
                * @hidden
                */
            constructor();
            /**
                * Return VoxImplant Web SDK version
                * @function
                * @hidden
                */
            readonly version: string;
            /**
                * @hidden
                */
            static getInstance(): Client;
            /**
                * Plays progress tone according to specified country in config.progressToneCountry
                * @hidden
                */
            playProgressTone(check?: boolean): void;
            /**
                * Stop progress tone
                * @hidden
                */
            stopProgressTone(): void;
            /**
                * @hidden
                */
            onIncomingCall(id: any, callerid: any, displayName: any, headers: any, hasVideo: any): void;
            readonly alreadyInitialized: boolean;
            /**
                * Initialize SDK. The [Events.SDKReady] event will be dispatched after successful SDK initialization. SDK can't be used until it's initialized
                * @param {VoxImplant.Config} [config] Client configuration options
                */
            init(config: Config): Promise<EventHandlers.SDKReady | string>;
            /**
                * Create call
                * @name VoxImplant.Client.call
                * @param {String} num The number to call. For SIP compatibility reasons it should be a non-empty string even if the number itself is not used by a Voximplant cloud scenario.
                * @param {Boolean} useVideo Tells if video should be supported for the call. It's false by default.
                * @param {String} customData Custom string associated with the call session. It can be passed to the cloud to be obtained from the [CallAlerting](https://voximplant.com/docs/references/voxengine/appevents#callalerting) event or [Call History](https://voximplant.com/docs/references/httpapi/managing_history#getcallhistory) using HTTP API. Maximum size is 200 bytes. Use the [Call.sendMessage] method to pass a string over the limit; in order to pass a large data use [media_session_access_url](https://voximplant.com/docs/references/httpapi/managing_scenarios#startscenarios) on your backend.
                * @param {Object} extraHeaders Optional custom parameters (SIP headers) that should be passed with call (INVITE) message. Parameter names must start with "X-" to be processed by application. IMPORTANT: Headers size limit is 200 bytes.
        
                * @returns {VoxImplant.Call}
                */
            call(num: string | CallSettings, useVideo?: boolean | VideoFlags, customData?: string, extraHeaders?: {
                    [id: string]: string;
            }): Call;
            /**
                * Create call to a dedicated conference without proxy session. For details see <a href="https://medium.com/voximplant/video-conferencing-guide-for-voximplant-developers-8b1096e30129"> the video conferencing guide</a>
                * @param {String} num The number to call. For SIP compatibility reasons it should be a non-empty string even if the number itself is not used by a Voximplant cloud scenario.
                * @param {Boolean} useVideo Tells if video should be supported for the call. It's false by default.
                * @param {String} customData Custom string associated with the call session. It can be passed to the cloud to be obtained from the [CallAlerting](https://voximplant.com/docs/references/voxengine/appevents#callalerting) event or [Call History](https://voximplant.com/docs/references/httpapi/managing_history#getcallhistory) using HTTP API. Maximum size is 200 bytes. Use the [Call.sendMessage] method to pass a string over the limit; in order to pass a large data use [media_session_access_url](https://voximplant.com/docs/references/httpapi/managing_scenarios#startscenarios) on your backend.
                * @param {Object} extraHeaders Optional custom parameters (SIP headers) that should be passed with call (INVITE) message. Parameter names must start with "X-" to be processed by application. IMPORTANT: Headers size limit is 200 bytes.
                * @returns {Call}
                */
            callConference(num: string | CallSettings, useVideo?: boolean | VideoFlags, customData?: string, extraHeaders?: {
                    [id: string]: string;
            }): Call;
            /**
                * Get current config
                */
            config(): Config;
            /**
                * Connect to VoxImplant Cloud
                */
            connect(connectivityCheck?: boolean): Promise<Object>;
            /**
                * Connect to specific VoxImplant Cloud host
                * @name VoxImplant.Client.connectTo
                * @hidden
                */
            connectTo(host: string, omitMicDetection?: boolean, connectivityCheck?: boolean): Promise<any>;
            /**
                * Disconnect from VoxImplant Cloud
                */
            disconnect(): void;
            /**
                * Set ACD status
                * @param {OperatorACDStatuses} Automatic call distributor status
                */
            setOperatorACDStatus(status: OperatorACDStatuses): Promise<OperatorACDStatuses>;
            /**
                * Set SQ Messaging status
                * @param {OperatorACDStatuses} Automatic call distributor status
                */
            setOperatorSQMessagingStatus(status: OperatorACDStatuses): Promise<OperatorACDStatuses>;
            /**
                * Return current ACD status of the operator.
                * @returns {Promise<OperatorACDStatuses>}
                */
            getOperatorACDStatus(): Promise<OperatorACDStatuses>;
            /**
                * Return current SQ Messaging status of the operator.
                * @returns {Promise<OperatorACDStatuses>}
                */
            getOperatorSQMessagingStatus(): Promise<OperatorACDStatuses>;
            /**
                * Log in to an application. The method triggers the [Events.AuthResult] event.
                * @param {String} username Fully-qualified username that includes Voximplant user, application and account names. The format is: "username@appname.accname.voximplant.com".
                * @param {String} password
                * @param {VoxImplant.LoginOptions} [options]
                */
            login(username: string, password: string, options?: LoginOptions): Promise<EventHandlers.AuthResult>;
            /**
                * Log in to an application using the 'code' auth method. The method triggers the [Events.AuthResult] event.
                *
                * Please, read <a href="http://voximplant.com/docs/quickstart/24/automated-login/">howto page</a>
                * @param {String} username Fully-qualified username that includes Voximplant user, application and account names. The format is: "username@appname.accname.voximplant.com".
                * @param {String} code
                * @param {VoxImplant.LoginOptions} [options]
                * @hidden
                */
            loginWithCode(username: string, code: string, options?: LoginOptions): Promise<EventHandlers.AuthResult>;
            /**
                * Log in to an application using an accessToken. The method triggers the [Events.AuthResult] event.
                * @param {String} username Fully-qualified username that includes Voximplant user, application and account names. The format is: "username@appname.accname.voximplant.com".
                * @param {String} token
                * @param {VoxImplant.LoginOptions} [options]
                */
            loginWithToken(username: string, token: string, options?: LoginOptions): Promise<EventHandlers.AuthResult>;
            /**
                * Refresh expired access token
                * @param {String} username Fully-qualified username that includes Voximplant user, application and account names. The format is: "username@appname.accname.voximplant.com".
                * @param {String} refreshToken
                * @param {String} deviceToken A unique token for the current device
                */
            tokenRefresh(username: string, refreshToken: string, deviceToken?: string): Promise<AuthTokenResult>;
            /**
                * Request a key for the 'onetimekey' auth method.
                * Server will send the key in the [Events.AuthResult] event with the code 302.
                *
                * Please, read the <a href="http://voximplant.com/docs/quickstart/24/automated-login/">how-to page</a>.
                * @param {String} username
                */
            requestOneTimeLoginKey(username: string): Promise<EventHandlers.AuthResult>;
            /**
                * Log in to an application using the 'onetimekey' auth method.
                * Hash should be calculated with the key from the triggered [Events.AuthResult] event.
                *
                * Please, read the <a href="http://voximplant.com/docs/quickstart/24/automated-login/">how-to page</a>.
                * @param {String} username
                * @param {String} hash
                * @param {VoxImplant.LoginOptions} [options]
                */
            loginWithOneTimeKey(username: string, hash: string, options?: LoginOptions): Promise<EventHandlers.AuthResult>;
            /**
                * Check if connected to VoxImplant Cloud
                * @deprecated
                * See [[Client.getClientState]]
                */
            connected(): boolean;
            /**
                * Show/hide local video. *IMPORTANT*: Safari browser for iOS requires a user interface for playing video during a call. It should be interactive element like an HTML "button" with "onclick" handler that calls "play" method on the "video" HTML element.
                * @param {Boolean} [flag=true] Show/hide - true/false
                * @param {Boolean} [mirror=false] Mirror local video
                * @param {Boolean} [detachCamera=false] Detach camera on hide local video
                */
            showLocalVideo(flag?: boolean, mirror?: boolean, detachCamera?: boolean): Promise<MediaRenderer | void>;
            /**
                * Set local video position
                * @param {Number} x Horizontal position (px)
                * @param {Number} y Vertical position (px)
                * @function
                * @hidden
                * @deprecated
                * @name VoxImplant.Client.setLocalVideoPosition
                */
            setLocalVideoPosition(x: number, y: number): void;
            /**
                * Set local video size
                * @param {Number} width Width in pixels
                * @param {Number} height Height in pixels
                * @function
                * @hidden
                * @deprecated
                * @name VoxImplant.Client.setLocalVideoSize
                */
            setLocalVideoSize(width: number, height: number): void;
            /**
                * Set video settings globally. This settings will be used for the next call.
                * @param {VoxImplant.VideoSettings|VoxImplant.FlashVideoSettings} settings Video settings
                * @param {Function} [successCallback] Success callback function has MediaStream object as its argument
                * @param {Function} [failedCallback] Failed callback function
                * @deprecated
                * @hidden
                */
            setVideoSettings(settings: VideoSettings, successCallback?: Function, failedCallback?: Function): void;
            /**
                * Set bandwidth limit for video calls. Currently supported by Chrome/Chromium. (WebRTC mode only). The limit will be applied for the next call.
                * @param {Number} bandwidth Bandwidth limit in kilobits per second (kbps)
                */
            setVideoBandwidth(bandwidth: number): void;
            /**
                * Play ToneScript using WebAudio API
                * @param {String} script Tonescript string
                * @param {Boolean} [loop=false] Loop playback if true
                */
            playToneScript(script: string, loop?: boolean): void;
            /**
                * Stop playing ToneScript using WebAudio API
                */
            stopPlayback(): void;
            /**
                * Change current global sound volume
                * @deprecated
                * @param {Number} level New sound volume value between 0 and 100
                * @function
                * @hidden
                */
            volume(level: number): number;
            /**
                * Get a list of all currently available audio sources / microphones
                * @deprecated
                * @hidden
                */
            audioSources(): AudioSourceInfo[];
            /**
                * Get a list of all currently available video sources / cameras
                * @deprecated
                * @hidden
                */
            videoSources(): VideoSourceInfo[];
            /**
                * Get a list of all currently available audio playback devices
                * @deprecated
                * @hidden
                */
            audioOutputs(): AudioOutputInfo[];
            /**
                * Use specified audio source, use [audioSources] to get the list of available audio sources
                * If SDK was init with micRequired: false, force attach microphone.
                * @param {String} id Id of the audio source
                * @param {Function} [successCallback] Called in WebRTC mode if audio source changed successfully
                * @param {Function} [failedCallback] Called in WebRTC mode if audio source couldn't changed successfully
                * @deprecated
                * @hidden
                */
            useAudioSource(id: string, successCallback?: Function, failedCallback?: Function): Promise<MediaStream>;
            /**
                * Use specified video source, use [videoSources] to get the list of available video sources
                * @param {String} id Id of the video source
                * @param {Function} [successCallback] Called if video source changed successfully, has MediaStream object as its argument
                * @param {Function} [failedCallback] Called if video source couldn't be changed successfully, has MediaStreamError object as its argument
                * @deprecated
                * @hidden
                */
            useVideoSource(id: string, successCallback?: Function, failedCallback?: Function): Promise<MediaStream>;
            /**
                * Use specified audio output for new calls, use [audioOutputs] to get the list of available audio output
                * @param {String} id Id of the audio source
                * @deprecated
                * @hidden
                */
            useAudioOutput(id: string): Promise<void>;
            /**
                * Enable microphone/camera if micRequired in [Config] was set to false.
                * @param {Function} successCallback Called if selected recording devices were attached successfully, has MediaStream object as its argument
                * @param {Function} failedCallback Called if selected recording devices couldn't be attached, has MediaStreamError object as its argument
                * @deprecated
                * @hidden
                */
            attachRecordingDevice(successCallback?: Function, failedCallback?: Function): Promise<MediaStreamTrack>;
            /**
                * Disable microphone/camera if micRequired in [Config] was set to false
                * @deprecated
                * @hidden
                */
            detachRecordingDevice(): void;
            /**
                * Set active call
                * @param {VoxImplant.Call} call VoxImplant call instance
                * @param {Boolean} [active=true] If true make call active, otherwise make call inactive
                * @deprecated
                * @hidden
                */
            setCallActive(call: Call, active?: boolean): Promise<EventHandlers.Updated>;
            /**
                * Start/stop sending local video to remote party/parties. *IMPORTANT*: Safari browser for iOS requires a user interface for playing video during a call. It should be interactive element like an HTML "button" with "onclick" handler that calls "play" method on the "video" HTML element.
                * @param {Boolean} [flag=true] Start/stop - true/false
                * @deprecated
                * @hidden
                */
            sendVideo(flag?: boolean): void;
            /**
                * Check if WebRTC support is available
                * @returns {Boolean}
                */
            isRTCsupported(): boolean;
            /**
                * Transfer call, depending on the result [CallEvents.TransferComplete] or [CallEvents.TransferFailed] event will be dispatched.
                * @param {VoxImplant.Call} call1 Call which will be transferred
                * @param {VoxImplant.Call} call2 Call where call1 will be transferred
                */
            transferCall(call1: Call, call2: Call): void;
            /**
                * Set logger levels for specified logger categories
                * @param {LogCategory} category Log category
                * @param {LogLevel} level Log level
                * @hidden
                */
            setLogLevel(category: LogCategory, level: LogLevel): void;
            /**
                * @hidden
                */
            onSignalingConnected(): void;
            /**
                * @hidden
                */
            onSignalingClosed(): void;
            /**
                * @hidden
                */
            onSignalingConnectionFailed(reason: any): void;
            /**
                * @hidden
                */
            onMediaConnectionFailed(): void;
            /**
                * Not documented function for backward compatibility
                * @hidden
                * @param string call_id Call ID
                * @returns {Call}
                */
            getCall(call_id: string): Call;
            /**
                * Not documented function for backward compatibility
                * Remove call from calls array
                * @param string call_id Call id
                * @hidden
                */
            removeCall(call_id: string): void;
            /**
                * Returns promise that is resolved with a boolean flag. The boolean flag
                * is set to 'true' if screen sharing is supported.
                * Promise is rejected in case of an internal error.
                */
            screenSharingSupported(): Promise<boolean>;
            /**
                * Register handler for specified event
                * @param event Event class (i.e. [Events.SDKReady]). See [Events]
                * @param handler Handler function. A single parameter is passed - object with event information
                * @deprecated
                * @hidden
                */
            addEventListener(event: Events, handler: (ev: any) => void): void;
            /**
                * Remove handler for specified event
                * @param {Function} event Event class (i.e. [Events.SDKReady]). See [Events]
                * @param {Function} [handler] Handler function, if not specified all event handlers will be removed
                * @function
                * @deprecated
                * @hidden
                */
            removeEventListener(event: Events, handler?: (ev: any) => void): void;
            /**
                * Register a handler for the specified event. The method is a shorter equivalent for *addEventListener*. One event can have more than one handler; handlers are executed in order of registration.
                * Use the [Client.off] method to delete a handler.
                * @param {Function} event Event class (i.e. [Events.SDKReady]). See [Events]
                * @param {Function} handler Handler function. A single parameter is passed - object with event information
                * @function
                */
            on(event: Events, handler: (ev: any) => void, options?: EventListenerOption): void;
            /**
                * Remove a handler for the specified event. The method is a shorter equivalent for *removeEventListener*. If a number of events has the same function as a handler, the method can be called multiple times with the same handler argument.
                * @param {Function} event Event class (i.e. [Events.SDKReady]). See [Events]
                * @param {Function} [handler] Handler function, if not specified all event handlers will be removed
                * @function
                */
            off(event: Events, handler?: (ev: any) => void): void;
            /**
                * @hidden
                */
            getZingayaAPI(): ZingayaAPI;
            /**
                * Register for push notifications. Application will receive push notifications from VoxImplant Server after first logger in.
                * @hidden
                * @param token FCM registration token that can be retrieved by calling firebase.messaging().getToken() inside a service worker
                * @returns {Promise<void>}
                */
            registerForPushNotificatuons(token: string): Promise<void>;
            /**
                * Register for push notifications. Application will receive push notifications from VoxImplant Server after first logger in.
                * @param token FCM registration token that can be retrieved by calling firebase.messaging().getToken() inside a service worker
                * @returns {Promise<void>}
                */
            registerForPushNotifications(token: string): Promise<void>;
            /**
                * Unregister from push notifications. Application will no longer receive push notifications from VoxImplant server.
                * @param token FCM registration token that was used to register for push notifications
                * @hidden
                * @returns {Promise<void>}
                */
            unregisterForPushNotificatuons(token: string): Promise<void>;
            /**
                * Unregister from push notifications. Application will no longer receive push notifications from VoxImplant server.
                * @hidden
                * @param token FCM registration token that was used to register for push notifications
                * @returns {Promise<void>}
                */
            unregisterForPushNotifications(token: string): Promise<void>;
            /**
                * Handle incoming push notification
                * @param message  Incoming push notification that comes from the firebase.messaging().setBackgroundMessageHandler callback inside a service worker
                * @returns {Promise<void>}
                */
            handlePushNotification(message: any): Promise<void>;
            /**
                * Generate a new GUID identifier. Unique each time.
                * @hidden
                */
            getGUID(): string;
            /**
                * Set the state of the silent logging inside SDK (it is disabled by default). When it is enabled, the WebSDK will save all logger messages into the logger until you disable it.
                *
                * Note that enabling of the silent logging automatically clears all existed logger records before the start.
                *
                * You can get current logger by the [getSilentLog] function and clean it by the [clearSilentLog] function.
                * @param {boolean} flag
                */
            enableSilentLogging(flag: boolean): void;
            /**
                * Clear the logger journal and free some memory.
                */
            clearSilentLog(): void;
            /**
                * Get records from the logger journal.
                * @returns {Array<string>}
                */
            getSilentLog(): Array<string>;
            /**
                * Set outer logging callback.
                *
                * The method allows integrating logging pipeline of the WebSDK into your own logger i.e. the method call sends all events to your function.
                * *IMPORTANT:* the callback strictly ignores Loglevel settings of the WebSDK.
                *
                * @param {{(record: LogRecord): void}} callback
                */
            setLoggerCallback(callback: {
                    (record: LogRecord): void;
            }): void;
            /**
                * Get current client state
                * @return {ClientState}
                */
            getClientState(): ClientState;
            /**
                * @hidden
                * @deprecated
                * @returns {any}
                */
            setSwfColor(): any;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
            setConnectionData(gateway: any, connectionId: any): void;
    }
}

declare module 'voximplant-websdk/Messaging' {
    import { Messenger as ImplementMessenger } from 'voximplant-websdk/Messaging/src/Messenger';
    import { Conversation as ImplementConversation } from 'voximplant-websdk/Messaging/src/Conversation';
    import { Message as ImplementMessage } from 'voximplant-websdk/Messaging/src/Message';
    import * as Implement from 'voximplant-websdk/Messaging/src/Structures';
    /**
        * Messaging module allows to exchange instant messages between two or more participants.
        * Messaging supports text and metadata. The conversation doesn't bind or depend on audio/video calls though there is a possibility to integrate messaging in audio/video calls.
        *
        * FEATURES:
        * 1. Messaging is the separate part of WEB SDK but it uses the [Client.login], [Client.loginWithOneTimeKey] and [Client.loginWithToken] methods. In brief, if a user has already been logged in, he can use Messaging functionality.
        * 2. Messaging doesn't use backend JS scenarios at all.
        *
        * Here is the minimum example of creating a Messenger instance and starting a conversation:
        * @example
        * const voxSDK = VoxImplant.getInstance();
        * const Messaging = VoxImplant.Messaging;
        *
        * voxSDK.init({micRequired:false})
        *   .then(() => voxSDK.connect())
        *   .then(() => sdk.login('foo@bar.baz.voximplant.com', 'secretpass'))
        *   .then((e) => {
        *     if (!e.result)
        *       throw e.message;
        *
        *     console.log('[Voximplant] Ready, connected and logged in.');
        *     return Messaging.getInstance();
        *   })
        *   .then((messenger) => {
        *     messenger.on(Messaging.MessengerEvents.CreateConversation, onCreateConversation);
        *     messenger.on(Messaging.MessengerEvents.SendMessage, onSendMessage);
        *     messenger.createConversation([]);
        *   })
        *   .catch(e => console.error('[Voximplant] Oops! Something went wrong',e));
        *
        * function onCreateConversation(e) {
        *   console.log(`[Voximplant] New conversation here! ID:${e.conversation.uuid}`);
        *   e.conversation.sendMessage('Hello world!');
        * }
        *
        * function onSendMessage(e) {
        *   console.logger(`[Voximplant] Message from ${e.message.sender}: ${e.message.text}`)
        * }
        *
        */
    export module Messaging {
            /**
                * Get a [Messenger] instance to use Messaging functions.
                */
            function getInstance(): Messenger;
            /**
                * Messenger class is used to control messaging functions. Can't be instantiated directly (singleton), please use [getMessenger] or [Messaging.get] to get the class instance.
                */
            class Messenger extends ImplementMessenger {
            }
            /**
                * Class that represents a conversation. A Conversation instance is returned by the [Messenger.createConversation] and [Messenger.createConversationFromCache] methods.
                * It's used to send messages, manage participants, receive conversation events history etc.
                */
            class Conversation extends ImplementConversation {
            }
            /**
                * Describes single message. Received via the [MessengerEvents.SendMessage] or [MessengerEvents.EditMessage] events and used to serialize or edit the message.
                */
            class Message extends ImplementMessage {
            }
            /**
                * Serialized [Message] that can be stored (e.g. in IndexedDB) and restored later via the [Messenger.createMessageFromCache] method.
                */
            interface SerializedMessage extends Implement.SerializedMessage {
            }
            /**
                * Serialized [Conversation] that can be stored (e.g. in IndexedDB) and restored later via the [Messenger.createConversationFromCache] method.
                */
            interface SerializedConversation extends Implement.SerializedConversation {
            }
            /**
                * Interface that represents a participant of the conversation (see [Conversation.participants].
                * The default permissions for all participants are: write / edit / remove their own messages.
                */
            interface ConversationParticipant extends Implement.ConversationParticipant {
            }
            /**
                * Interface that represents a Voximplant user with Messaging user id.
                * Voximplant users are created in [Voximplant control panel](https://manage.voximplant.com) or via [HTTP API](https://voximplant.com/docs/references/httpapi).
                * To get user(s) information use the [Messenger.getUser], [Messenger.getUsers], [Messenger.getUserById] and [Messenger.getUsersById] methods.
                */
            interface User extends Implement.User {
            }
            /**
                * Interface that represents user subscription information. Available in the [MessengerEvents.GetSubscriptionList] event.
                */
            interface UserSubscriptions extends Implement.MsgOutput.UserSubscriptions {
            }
            /**
                * Interface that represents user status information. Available in the [MessengerEvents.SetStatus] event.
                */
            interface UserStatus extends Implement.MsgInOutput.PresenceMessage {
            }
            /**
                * Enum that represents actions that trigger messenger events.
                * Each action is the reason for every triggered event and is specified in the [EventHandlers.MessengerEvent.messengerAction] property.
                */
            enum MessengerAction {
                    /**
                        * @hidden
                        */
                    UNKNOWN = "UNKNOWN",
                    createConversation = "createConversation",
                    editConversation = "editConversation",
                    /**
                        * @hidden
                        */
                    removeConversation = "removeConversation",
                    joinConversation = "joinConversation",
                    leaveConversation = "leaveConversation",
                    getConversation = "getConversation",
                    getConversations = "getConversations",
                    getPublicConversations = "getPublicConversations",
                    /**
                        * @hidden
                        */
                    searchConversations = "searchConversations",
                    /**
                        * @hidden
                        */
                    removeEmptyConversation = "removeEmptyConversation",
                    addParticipants = "addParticipants",
                    editParticipants = "editParticipants",
                    removeParticipants = "removeParticipants",
                    getUser = "getUser",
                    getUsers = "getUsers",
                    editUser = "editUser",
                    setStatus = "setStatus",
                    sendMessage = "sendMessage",
                    editMessage = "editMessage",
                    removeMessage = "removeMessage",
                    typingMessage = "typingMessage",
                    isRead = "isRead",
                    subscribe = "subscribe",
                    unsubscribe = "unsubscribe",
                    manageNotification = "manageNotification",
                    getSubscriptionList = "getSubscriptionList",
                    /**
                        * @hidden
                        */
                    createBot = "createBot",
                    /**
                        * @hidden
                        */
                    removeBot = "removeBot",
                    retransmitEvents = "retransmitEvents"
            }
            /**
                * Enum that represents types of messenger events.
                */
            enum MessengerEvents {
                    /**
                        * The event is triggered when any user has created a new conversation with the current user in the participant array.
                        */
                    CreateConversation = "CreateConversation",
                    /**
                        * The event is triggered when conversation the current user belongs to wat modified.
                        */
                    EditConversation = "EditConversation",
                    /**
                        * @hidden
                        * @deprecated
                        * The conversation was removed.
                        */
                    RemoveConversation = "RemoveConversation",
                    /**
                        * The event is triggered when the [Messenger.getConversation] or [Messenger.getConversations] was were called by the current user.
                        */
                    GetConversation = "GetConversation",
                    /**
                        * The event is triggered when the [Conversation.GetPublicConversations] method was called by the current user.
                        */
                    GetPublicConversations = "GetPublicConversations",
                    /**
                        * The event is triggered when a new message was sent to a conversation via the [Conversation.sendMessage] method by any conversation participant.
                        */
                    SendMessage = "SendMessage",
                    /**
                        * The event is triggered when a message was edited via the [Message.update] method by any conversation participant.
                        */
                    EditMessage = "EditMessage",
                    /**
                        * The event is triggered when a message was removed via the [Message.remove] method by any conversation participant.
                        */
                    RemoveMessage = "RemoveMessage",
                    /**
                        * The event is triggered when any participant of a conversation the current user belongs to has called the [Conversation.typing] method.
                        */
                    Typing = "Typing",
                    /**
                        * The event is triggered when information about a user the current user is subscribed to or the current user was changed via the [Messenger.editUser] method.
                        */
                    EditUser = "EditUser",
                    /**
                        * The event is triggered when the [Messenger.getUser], [Messenger.getUsers], [Messenger.getUserById] or [Messenger.getUsersById] method was called by the current user.
                        */
                    GetUser = "GetUser",
                    /**
                        * The event is triggered when error occurs. Refer to the error codes in the [MessengerError] enum.
                        */
                    Error = "Error",
                    /**
                        * The event is triggered when the [Conversation.retransmitEvents] method was called by the current user.
                        */
                    RetransmitEvents = "RetransmitEvents",
                    /**
                        * The event is triggered when any participant of a conversation the current user belongs to called the [Conversation.markAsRead] method.
                        */
                    Read = "Read",
                    /**
                        * The event is triggered when the [Messenger.subscribe] method was called by the current user.
                        */
                    Subscribe = "Subscribe",
                    /**
                        * The event is triggered when the [Messenger.unsubscribe] method was called by the current user.
                        */
                    Unsubscribe = "Unsubscribe",
                    /**
                        * The event is triggered when any user the current user is subscribed to or the current user called the [Messenger.setStatus] method.
                        */
                    SetStatus = "SetStatus",
                    /**
                        * The event is triggered when the [Messenger.getSubscriptionList] method was called by the current user.
                        */
                    GetSubscriptionList = "GetSubscriptionList",
                    /**
                        * @hidden
                        */
                    CreateBot = "CreateBot",
                    /**
                        * @hidden
                        */
                    RemoveBot = "RemoveBot"
            }
            enum MessengerError {
                    /**
                        *  Something went wrong. Please check your input or required parameters.
                        */
                    Error_0 = 0,
                    /**
                        * Transport message structure is wrong. From GW.
                        */
                    Error_1 = 1,
                    /**
                        * Event name is unknown.
                        */
                    Error_2 = 2,
                    /**
                        * User is not authorized. From GW.
                        */
                    Error_3 = 3,
                    /**
                        * Conversation does not exist.
                        */
                    Error_8 = 8,
                    /**
                        * Message with this UUID does not exist in the conversation.
                        */
                    Error_10 = 10,
                    /**
                        *  Message with this UUID is deleted from the conversation.
                        */
                    Error_11 = 11,
                    /**
                        *  ACL error.
                        */
                    Error_12 = 12,
                    /**
                        *  User is already in the participants list.
                        */
                    Error_13 = 13,
                    /**
                        *  Public join is not available for this conversation.
                        */
                    Error_15 = 15,
                    /**
                        *  Conversation with this UUID is deleted.
                        */
                    Error_16 = 16,
                    /**
                        *  User validation error.
                        */
                    Error_18 = 18,
                    /**
                        *  User is not in the participants list.
                        */
                    Error_19 = 19,
                    /**
                        *  Number of requested objects is 0 or larger than allowed by the service.
                        */
                    Error_21 = 21,
                    /**
                        *  Number of requested objects is larger than allowed by the service.
                        */
                    Error_22 = 22,
                    /**
                        *  Message size exceeds the limit of 5000 symbols.
                        */
                    Error_23 = 23,
                    /**
                        *  The 'seq' parameter value is greater than currently possible.
                        */
                    Error_24 = 24,
                    /**
                        *  User is not found.
                        */
                    Error_25 = 25,
                    /**
                        *  The notification event is incorrect.
                        */
                    Error_26 = 26,
                    /**
                        *  The 'from' field value is greater than the 'to' field value.
                        */
                    Error_28 = 28,
                    /**
                        *  Messaging service is not available. Try again later. From GW.
                        */
                    Error_30 = 30,
                    /**
                        *  N messages per second limit reached. Please try again later. From GW.
                        */
                    Error_32 = 32,
                    /**
                        *  N messages per minute limit reached. Please try again later. From GW.
                        */
                    Error_33 = 33,
                    /**
                        *  Direct conversation cannot be public or uber.
                        */
                    Error_34 = 34,
                    /**
                        *  Direct conversation is allowed between two users only.
                        */
                    Error_35 = 35,
                    /**
                        *  Passing the 'eventsFrom', 'eventsTo' and 'count' parameters simultaneously is not allowed. You should use only two of them.
                        */
                    Error_36 = 36,
                    /**
                        *  Adding participant to a direct conversation is not allowed.
                        */
                    Error_37 = 37,
                    /**
                        *  Removing participant from a direct conversation is not allowed.
                        */
                    Error_38 = 38,
                    /**
                        *  Joining a direct conversation is not allowed.
                        */
                    Error_39 = 39,
                    /**
                        *  Leaving a direct conversation is not allowed.
                        */
                    Error_40 = 40,
                    /**
                        *  Specify at least two parameters: eventsFrom, eventsTo or count.
                        */
                    Error_41 = 41,
                    /**
                        *  Current messaging tier has been exceeded.
                        */
                    Error_42 = 42,
                    /**
                        *  Messaging tier is being upgraded. Please try again later.
                        */
                    Error_43 = 43,
                    /**
                        *  Internal error.
                        */
                    Error_500 = 500
            }
            module EventHandlers {
                    /**
                        * Interface that represents all messenger events which are passed
                        * - as a resolve value by all [Messenger], [Conversation] and [Message] methods that return a Promise
                        * - as an argument to a callback function registered via the [Messenger.on] method
                        */
                    interface MessengerEvent {
                            /**
                                * Messaging user id of the user that initiated the event.
                                */
                            initiator: number;
                            /**
                                * [MessengerAction] which is the reason the event was triggered.
                                */
                            messengerAction: MessengerAction;
                            /**
                                * Messenger request UUID.
                                * There's no requestUuid only in [EventHandlers.RetransmittedEvent] and in [EventHandlers.ErrorEvent] when the actual request has not been made due to an invalid payload.
                                */
                            requestUuid?: string;
                            /**
                                * UNIX timestamp (seconds) that specifies the time the event was dispatched by the cloud.
                                */
                            timestamp?: number;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.getConversation] and [Messenger.getConversations]
                        * - as an argument to a callback function registered for the [MessengerEvents.GetConversation] event
                        */
                    interface GetConversationEvent extends MessengerEvent {
                            /**
                                * Array of conversations.
                                */
                            conversations: Array<Conversation>;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.getPublicConversations] method
                        * - as an argument to a callback function registered for the [MessengerEvents.GetPublicConversations] event
                        */
                    interface GetPublicConversationsEvent extends MessengerEvent {
                            /**
                                * Array of conversation UUIDs.
                                */
                            conversations: Array<string>;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.createConversation] method
                        * - as an argument to a callback function registered for the [MessengerEvents.CreateConversation] event
                        */
                    interface CreateConversationEvent extends MessengerEvent {
                            /**
                                * The created conversation.
                                */
                            conversation: Conversation;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Conversation.addParticipants], [Conversation.editParticipants], [Conversation.removeParticipants], [Conversation.setTitle], [Conversation.setPublicJoin], [Conversation.setCustomData] and [Conversation.update] methods
                        * - as an argument to a callback function registered for the [MessengerEvents.EditConversation] event
                        */
                    interface EditConversationEvent extends MessengerEvent {
                            /**
                                * Conversation uuid.
                                */
                            uuid: Conversation;
                            /**
                                * Sequence of this event.
                                */
                            seq: number;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Conversation.removeConversation] method
                        * - as an argument to a callback function registered for the [MessengerEvents.RemoveConversation] event
                        */
                    interface RemoveConversationEvent extends MessengerEvent {
                            /**
                                * Conversation uuid.
                                */
                            uuid: string;
                            /**
                                * Sequence of this event.
                                */
                            seq: number;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.getUser], [Messenger.getUsers], [Messenger.getUserById] and [Messenger.getUsersById] methods
                        * - as an argument to a callback function registered for the [MessengerEvents.GetUser] event
                        */
                    interface GetUserEvent extends MessengerEvent {
                            /**
                                * The user object.
                                */
                            user: User;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.editUser] method
                        * - as an argument to a callback function registered for the [MessengerEvents.EditUser] event
                        */
                    interface EditUserEvent extends MessengerEvent {
                            /**
                                * The edited user object.
                                */
                            user: User;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.setStatus] method
                        * - as an argument to a callback function registered for the [MessengerEvents.SetStatus] event
                        */
                    interface SetStatusEvent extends MessengerEvent {
                            /**
                                * True if the user is online.
                                */
                            online: boolean;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.subscribe] method
                        * - as an argument to a callback function registered for the [MessengerEvents.Subscribe] event
                        */
                    interface SubscribeEvent extends MessengerEvent {
                            /**
                                * Array of Messaging user ids.
                                */
                            users: Array<number>;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Messenger.unsubscribe] method
                        * - as an argument to a callback function registered for the [MessengerEvents.Unsubscribe] event
                        */
                    interface UnsubscribeEvent extends MessengerEvent {
                            /**
                                * Array of Messaging user ids.
                                */
                            users: number[];
                    }
                    /**
                        * Interface that represents the event passedMessngerEvents
                        * - as a resolve value by the [Messenger.getSubscriptionList] method
                        * - as an argument to a callback function registered for the [MessengerEvents.GetSubscriptionList] event
                        */
                    interface GetSubscriptionListEvent extends MessengerEvent {
                            /**
                                * Array of Messaging user ids.
                                */
                            users: Array<number>;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Conversation.sendMessage] method
                        * - as an argument to a callback function registered for the [MessengerEvents.SendMessage] event
                        */
                    interface SendMessageEvent extends MessengerEvent {
                            /**
                                * Message object.
                                */
                            message: Message;
                            /**
                                * Sequence of this event.
                                */
                            seq: number;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Message.update] method
                        * - as an argument to a callback function registered for the [MessengerEvents.EditMessage] event
                        */
                    interface EditMessageEvent extends MessengerEvent {
                            /**
                                * Edited message object.
                                */
                            message: Message;
                            /**
                                * Sequence of this event.
                                */
                            seq: number;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Message.remove] method
                        * - as an argument to a callback function registered for the [MessengerEvents.RemoveMessage] event
                        */
                    interface RemoveMessageEvent extends MessengerEvent {
                            /**
                                * Message UUID.
                                */
                            uuid: string;
                            /**
                                * Sequence of this event.
                                */
                            seq: number;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Conversation.typing] method
                        * - as an argument to a callback function registered for the [MessengerEvents.Typing] event
                        */
                    interface TypingEvent extends MessengerEvent {
                            /**
                                * Conversation UUID.
                                */
                            conversation: string;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Conversation.markAsRead] method
                        * - as an argument to a callback function registered for the [MessengerEvents.Read] event
                        */
                    interface ReadEvent extends MessengerEvent {
                            /**
                                * Conversation UUID.
                                */
                            conversation: string;
                            /**
                                * Sequence of this event.
                                */
                            seq: number;
                    }
                    /**
                        * Interface that represents the event passed
                        * - as a resolve value by the [Conversation.retransmitEvents] method
                        * - as an argument to a callback function registered for the [MessengerEvents.RetransmitEvents] event
                        */
                    interface RetransmitEventsEvent extends MessengerEvent {
                            /**
                                * Array of retransmitted events.
                                */
                            events: Array<RetransmittedEvent>;
                    }
                    /**
                        * Interface that represents a single event in the array of retransmitted events passed in [EventHandlers.RetransmitEventsEvent]
                        * - by the [Conversation.retransmitEvents] method
                        * - to a callback function registered for the [MessengerEvents.RetransmitEvents] event
                        */
                    interface RetransmittedEvent extends MessengerEvent {
                            /**
                                * Conversation object. Only in Conversation events.
                                */
                            conversation?: Conversation;
                            /**
                                * Message object. Only in Message events.
                                */
                            message?: Message;
                            /**
                                * Sequence of this event.
                                */
                            seq: number;
                    }
                    interface ErrorEvent extends MessengerEvent {
                            /**
                                * Messaging error code.
                                */
                            code: MessengerError;
                            /**
                                * Human-readable error description.
                                */
                            description: string;
                    }
            }
            /**
                * @hidden
                */
            type MessengerEventsPayload<E extends MessengerEvents> = EventHandlers.MessengerEvent & MessengerEventPayloads[E];
            /**
                * @hidden
                */
            interface MessengerEventPayloads {
                    CreateConversation: EventHandlers.CreateConversationEvent;
                    EditConversation: EventHandlers.EditConversationEvent;
                    RemoveConversation: EventHandlers.RemoveConversationEvent;
                    GetConversation: EventHandlers.GetConversationEvent;
                    GetPublicConversations: EventHandlers.GetPublicConversationsEvent;
                    SendMessage: EventHandlers.SendMessageEvent;
                    EditMessage: EventHandlers.EditMessageEvent;
                    RemoveMessage: EventHandlers.RemoveMessageEvent;
                    Typing: EventHandlers.TypingEvent;
                    GetUser: EventHandlers.GetUserEvent;
                    EditUser: EventHandlers.EditUserEvent;
                    Read: EventHandlers.ReadEvent;
                    Subscribe: EventHandlers.SubscribeEvent;
                    Unsubscribe: EventHandlers.UnsubscribeEvent;
                    SetStatus: EventHandlers.SetStatusEvent;
                    GetSubscriptionList: EventHandlers.GetSubscriptionListEvent;
                    ManageNotifications: EventHandlers.EditUserEvent;
                    CreateBot: {};
                    RemoveBot: {};
                    RetransmitEvents: EventHandlers.RetransmitEventsEvent;
                    Error: EventHandlers.ErrorEvent;
            }
    }
    export default Messaging;
}

declare module 'voximplant-websdk/Events' {
    /**
        * The events that are triggered by [Client] instance. See the [getInstance] method.
        *
        *
        * Example:
        * ``` js
        * var vox = VoxImplant.getInstance();
        * vox.init({micRequired: true});
        * vox.addEventListener(VoxImplant.Events.SDKReady, function() {
        *   vox.connect();
        * });
        * ```
        */
    export enum Events {
            /**
                *    The event is triggered after SDK was successfully initialized after the [Client.init] function call
                *
                *    Handler function receives [EventHandlers.SDKReady] object as an argument.
                */
            SDKReady,
            /**
                *    The event is triggered after connection to VoxImplant Cloud was established successfully.
                *    See [Client.connect] function
                *
                *    Handler function receives no arguments.
                */
            ConnectionEstablished,
            /**
                *    The event is triggered if a connection to the VoxImplant cloud couldn't be established.
                *    See [Client.connect] function
                *
                *    Handler function receives the [EventHandlers.ConnectionFailed] object as an argument.
                */
            ConnectionFailed,
            /**
                * The event is triggered if a connection to VoxImplant Cloud was closed because of network problems.
                *
                *    See the [Client.connect] function
                *
                *    Handler function receives no arguments.
                */
            ConnectionClosed,
            /**
                * The event is triggered after the [Client.login], [Client.loginWithOneTimeKey] and [Client.loginWithCode] methods call.
                *
                * Handler function receives [EventHandlers.AuthResult] object as an argument.
                */
            AuthResult,
            /**
                *   The event is triggered after the [LoginTokens.refreshToken] call
                *   Handler function receives the the [EventHandlers.AuthTokenResult] object as an argument.
                */
            RefreshTokenResult,
            /**
                *    The event is triggered after sound playback was stopped.
                *
                *    See [Client.playToneScript]
                *    and [Client.stopPlayback] functions
                *
                *    Handler function receives no arguments.
                */
            PlaybackFinished,
            /**
                * @hidden
                * @deprecated
                */
            MicAccessResult,
            /**
                *    The event is triggered when there is a new incoming call to current user
                *
                *    Handler function receives [EventHandlers.IncomingCall] object as an argument.
                */
            IncomingCall,
            /**
                * The event is triggered when audio and video sources information was updated.
                *    See the [Client.audioSources] and [Client.videoSources] for details
                * @hidden
                * @deprecated
                */
            SourcesInfoUpdated,
            /**
                * @hidden
                * @deprecated
                */
            NetStatsReceived,
            /**
                * @hidden
                */
            SIPRegistrationSuccessful,
            /**
                * @hidden
                */
            SIPRegistrationFailed,
            /**
                * The event is triggered when ACD status of current user changed from SDK or from inside the ACD service.
                */
            ACDStatusUpdated,
            /**
                * The event is triggered when ACD status of current user changed from SDK or from inside the ACD service.
                */
            SQMessagingStatusUpdated,
            /**
                * The event is triggered when the Web SDK detects incorrect use of the ACD module, e.g.,
                * using the same credentials in the different browsers or multiple browser's windows.
                */
            ACDError,
            /**
                * The event is triggered when the Web SDK detects incorrect use of the SQ module, e.g.,
                * using the same credentials in the different browsers or multiple browser's windows.
                */
            SQError,
            /**
                * @hidden
                */
            PlaybackError
    }
}

declare module 'voximplant-websdk/Call/CallEvents' {
    /**
        * The events that are triggered by [Call] instance.
        *
        * Use [Call.on] to subscribe on
        * any of these events.
        *
        *
        * Example:
        * ``` js
        * var currentCall = vox.call("exampleUser");
        * currentCall.on(VoxImplant.CallEvents.Connected,onConnected);
        * currentCall.on(VoxImplant.CallEvents.Disconnected,onDisconnected);
        * currentCall.on(VoxImplant.CallEvents.Failed,onFailed);
        * currentCall.on(VoxImplant.CallEvents.ICETimeout,onICETimeout)
        * ```
        */
    export enum CallEvents {
            /**
                * Event is triggered when a reliable connection is established for the call. Depending on network conditions there can be a 2-3 seconds delay between first audio data and this event.
                * Handler function receives [EventHandlers.CallEventWithHeaders] object as an argument.
                */
            Connected,
            /**
                *  Event is triggered when a call was disconnected
                *  Handler function receives the [EventHandlers.Disconnected] object as an argument.
                */
            Disconnected,
            /**
                *  Event is triggered due to a call failure
                *
                *  Most frequent status codes:
                *
                * |Code|Description                      |
                * |----|---------------------------------|
                * |486 |Destination number is busy       |
                * |487 |Request terminated               |
                * |603 |Call was rejected                |
                * |404 |Invalid number                   |
                * |480 |Destination number is unavailable|
                * |402 |Insufficient funds               |
                *
                * Handler function receives the [EventHandlers.Failed] object as an argument.
                */
            Failed,
            /**
                *  Event is triggered when a progress tone playback starts.
                *  Handler function receives the [EventHandlers.CallEvent] object as an argument.
                */
            ProgressToneStart,
            /**
                *  Event is triggered when a progress tone playback stops.
                *  Handler function receives the [EventHandlers.CallEvent] object as an argument.
                */
            ProgressToneStop,
            /**
                *  Event is triggered when a text message is received.
                *  Handler function receives the [EventHandlers.MessageReceived] object as an argument.
                */
            MessageReceived,
            /**
                *  Event is triggered when the INFO message is received
                *  Handler function receives [EventHandlers.InfoReceived] object as an argument.
                */
            InfoReceived,
            /**
                *  Event is triggered when a call has been transferred successfully.
                *  Handler function receives the [EventHandlers.CallEvent] object as an argument.
                */
            TransferComplete,
            /**
                *  Event is triggered when a call transfer failed
                *  Handler function receives the [EventHandlers.CallEvent] object as an argument.
                */
            TransferFailed,
            /**
                *  Event is triggered when connection was not established due to a network connection problem between 2 peers
                *  Handler function receives [EventHandlers.CallEvent] object as an argument.
                *  @deprecated
                */
            ICETimeout,
            /**
                *  Event is triggered every 10 seconds when the call is CONNECTED.
                *  Handler function receives RTCStatsReport dictionary as it is returned by a browser RTCPeerConnection.getStats() method as an argument.
                *  RTCStatsReport provides statistics about the specified [Call] and may differ from one vendor to another.
                *  @deprecated Use [CallStatsReceived] instead
                */
            RTCStatsReceived,
            /**
                *  Event is triggered when the call is CONNECTED at the interval specified by [Config.rtcStatsCollectionInterval] (defaults to 10 seconds).
                *  Handler function receives [CallStats] object as an argument.
                */
            CallStatsReceived,
            /**
                * Event is triggered when a new HTMLMediaElement for the call's media playback has been created
                * Handler function receives [EventHandlers.MediaElementCreated] object as an argument.
                * @hidden
                * @deprecated
                */
            MediaElementCreated,
            /**
                * @hidden
                * @deprecated
                * @type {string}
                */
            MediaElementRemoved,
            /**
                *  Event is triggered when an ICE connection is complete
                *  Handler function receives [EventHandlers.CallEvent] object as an argument.
                *  @deprecated
                */
            ICECompleted,
            /**
                * Event is triggered when a call was updated. For example, video was added/removed.
                * Handler function receives the [EventHandlers.Updated] object as an argument.
                */
            Updated,
            /**
                * Event is triggered when user receives the call update from another side. For example, a video was added/removed on the remote side.
                * Handler function receives [EventHandlers.CallEvent] object as an argument.
                * @hidden
                * @deprecated
                */
            PendingUpdate,
            /**
                * Event is triggered when multiple participants tried to update the same call simultaneously. For example, video added/removed on a local and remote side at the same time.
                * Handler function receives [EventHandlers.UpdateFailed] object as an argument.
                * @hidden
                * @deprecated
                */
            UpdateFailed,
            /**
                * Handler function receives [EventHandlers.LocalVideoStreamAdded] object as an argument.
                * @deprecated
                * @hidden
                */
            LocalVideoStreamAdded,
            /**
                * Event is triggered when a new Endpoint is created. [Endpoint] represents an another participant in your call or conference.
                */
            EndpointAdded,
            /**
                * Handler function receives [EventHandlers.StateUpdated] object as an argument.
                */
            StateUpdated,
            /**
                * Handler function receives [EventHandlers.ActiveUpdated] object as an argument.
                */
            ActiveUpdated,
            /**
                * Event is triggered when the local audio, video or shared stream is encoded by a codec different from the one specified in [Config] or [CallSettings].
                * @beta
                */
            QualityIssueCodecMismatch,
            /**
                * Event is triggered when network-based media latency is detected in the call.
                * @beta
                */
            QualityIssueHighMediaLatency,
            /**
                * Event is triggered when the ICE connection is switched to the "disconnected" state during the call.
                * @beta
                */
            QualityIssueICEDisconnected,
            /**
                * Event is triggered when the video resolution sent to the endpoint is lower than a captured video resolution.
                * @beta
                */
            QualityIssueLocalVideoDegradation,
            /**
                * Event is triggered when the current bitrate is insufficient for sending video in the current resolution.
                * @beta
                * @hidden
                */
            QualityIssueLowBandwidth,
            /**
                * Event is triggered when no audio is captured by the microphone.
                * @beta
                * @hidden
                */
            QualityIssueNoAudioSignal,
            /**
                * Event is triggered every 2.5 seconds and indicates packet loss for the last period.
                * @beta
                */
            QualityIssuePacketLoss
    }
}

declare module 'voximplant-websdk/Call/EndPoints/Endpoint' {
    import { EventListenerOption, EventTarget } from 'voximplant-websdk/EventTarget';
    import { EndpointEvents } from 'voximplant-websdk/Call/EndPoints/EndpointEvents';
    import { MediaRenderer } from 'voximplant-websdk/Media/MediaRenderer';
    import { EndpointInfoData } from 'voximplant-websdk/Call/EndpointListDescription';
    /**
        * Interface that represents any remote media unit in a call. Current endpoints can be retrieved via the [Call.getEndpoints] method.
        *
        * Endpoint can be :
        * <ol>
        * <li><a href="//voximplant.com/docs/references/appengine/Module_ASR.html">ASR</a></li>
        * <li><a href="//voximplant.com/docs/references/appengine/Module_Recorder.html">Recorder</a></li>
        * <li><a href="//voximplant.com/docs/references/appengine/Module_Player.html">Player</a></li>
        * <li> or another <a href="//voximplant.com/docs/references/appengine/Call.html">call</a> (e.g. which is joined to the conference)</li>
        * </ol>
        */
    export class Endpoint extends EventTarget<EndpointEvents> {
            isDefault: boolean;
            /**
                * Unique ID of current Endpoint
                */
            id: string;
            /**
                * The list of all [mediaRenderers].
                */
            mediaRenderers: MediaRenderer[];
            /**
                * Get <a href="https://tools.ietf.org/html/rfc3261##section-19.1.1" target="_blank">SIP URI</a> of the endpoint
                */
            sipUri: string;
            /**
                * Get user display name of the endpoint.
                */
            displayName: string;
            /**
                * Get user name of the endpoint.
                */
            userName: string;
            /**
                * @hidden
                */
            constructor(isDefault?: boolean);
            /**
                * @hidden
                */
            place: number;
            /**
                * Set audio output device for current Endpoint. Now supported by Google Chrome only
                * @param {string} id
                */
            useAudioOutput(id: string): void;
            /**
                * @hidden
                */
            updateInfo(data: EndpointInfoData): void;
            /**
                * Register a handler for the specified event. The method is a shorter equivalent for *addEventListener*. One event can have more than one handler; handlers are executed in order of registration.
                * Use the [Endpoint.off] method to delete a handler.
                */
            on(event: EndpointEvents, handler: (ev: any) => void, options?: EventListenerOption): void;
            /**
                * Remove a handler for the specified event. The method is a shorter equivalent for *removeEventListener*. If a number of events has the same function as a handler, the method can be called multiple times with the same handler argument.
                */
            off(event: EndpointEvents, handler?: (ev: any) => void): void;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Call/EndPoints/EndpointEvents' {
    /**
        * Events that are triggered when Endpoint is updated/edited, removed or started/stopped to receive stream from another Endpoint.
        */
    export enum EndpointEvents {
            /**
                * Event is triggered when an Endpoint is updated/edited. E.g. when
                * a display name is changed via the [setDisplayName](https://voximplant.com/docs/references/voxengine/conference/endpoint#setdisplayname) method.
                * [Voxengine](https://voximplant.com/docs/references/voxengine) example:
                * ```javascript
                * require(Modules.Conference);
                * // ...
                * endpoint.setDisplayName("Chuck Spadina");
                * ```
                * Web SDK example:
                * ```javascript
                * Endpoint.on(Voximplant.EndpointEvents.InfoUpdated, (e)=>{
                *   console.logger(e.endpoint.displayName);
                *   // > Chuck Spadina
                * });
                * ```
                * Handler function receives the [EventHandlers.EndpointHandler] object as an argument.
                */
            InfoUpdated,
            /**
                * Event is triggered when an Endpoint is removed. E.g. when a participant left the conference or [player](https://voximplant.com/docs/references/voxengine/player) was removed.
                * Handler function receives the [EventHandlers.EndpointHandler] object as an argument.
                */
            Removed,
            /**
                * Event is triggered when an Endpoint started to receive an audio / video / screensharing stream from another Endpoint.
                * __IMPORTANT__: if you subscribe to the event, Web SDK will no longer render remote audio/video stream automatically; you have to render remote streams manually via the [MediaRenderer.render] method.
                * Handler function receives the [EventHandlers.EndpointMediaHandler] object as an argument.
                */
            RemoteMediaAdded,
            /**
                * Event is triggered when an Endpoint stopped to receive an audio / video / screensharing stream from another Endpoint.
                * Handler function receives the [EventHandlers.EndpointMediaHandler] object as an argument.
                */
            RemoteMediaRemoved,
            /**
                * @hidden
                */
            RTCStatsReceived
    }
}

declare module 'voximplant-websdk/Structures' {
    import { TrackType } from "voximplant-websdk/Types";
    import { CallMode, CallState } from "voximplant-websdk/Call/Call";
    import { LogCategory, LogLevel } from "voximplant-websdk/Logger";
    /**
        *    VoxImplant SDK Configuration
        */
    export interface Config {
            /**
                * Reconnect to IM subsystem automatically
                * @hidden
                */
            imAutoReconnect?: boolean;
            /**
                * Interval (ms) before reconnect
                * @hidden
                */
            imReconnectInterval?: number;
            /**
                * XSS protection for inbound instant messages that can contain HTML content
                * @hidden
                */
            imXSSprotection?: boolean;
            /**
                * If it's true a microphone access dialog will be shown and all functions will become available only after user granted access
                */
            micRequired?: boolean;
            /**
                * Automatically plays progress tone by means of SDK according to specified progressToneCountry. It's true by default.
                */
            progressTone?: boolean;
            /**
                * Country code for progress tone generated automatically if *progressTone* is set to true. Available values are: RU, US
                */
            progressToneCountry?: string;
            /**
                * Show trace in console. It's false by default.
                */
            enableTrace?: boolean;
            /**
                * Show debug info in console. It's false by default.
                */
            showDebugInfo?: boolean;
            /**
                * Show warnings. It's false by default.
                */
            showWarnings?: boolean;
            /**
                * Default constraints that will be applied on the next attachRecordingDevice function call or if micRequired set to true. *IMPORTANT*: the value has to be the [VideoSettings] object. *Boolean* values exist only in order to ensure backward compatibility.
                */
            videoConstraints?: VideoSettings | boolean;
            /**
                * IP address of particular media gateway for connection
                */
            serverIp?: Array<string> | string;
            /**
                * Id of HTMLElement that will be used as a default container for local video elements, i.e. caller could see himself in this container during the conversation. Local videos are appended to the body element by default.
                * @see remoteVideoContainerId
                * @see localVideoContainerId
                * @deprecated
                */
            videoContainerId?: string;
            /**
                * Id of HTMLElement that will be used as a default container for remote video elements. Remote videos are appended to the body element by default
                *
                */
            remoteVideoContainerId?: string;
            /**
                * Id of HTMLElement that will be used as a default container for local video elements. Local videos are appended to the body element by default
                *
                */
            localVideoContainerId?: string;
            /**
                * *DEPRECATED*
                * Request video access rights immediately.
                * @deprecated
                * @hidden
                */
            videoSupport?: boolean;
            /**
                * Set sdk protocol manual. Can be "2" or "3"
                * @hidden
                */
            protocolVersion?: string;
            /**
                * Use H264 video codec, if it's available on the target device
                */
            H264first?: boolean;
            /**
                * RTC Stats collection interval (ms)
                */
            rtcStatsCollectionInterval?: number;
            /**
                * Params for <a href="https://calstats.io/">https://calstats.io/</a> integration
                */
            callstatsIoParams?: CallstatsIoParams;
            /**
                * Use VP8 video codec, if exist
                * @hidden
                */
            VP8first?: boolean;
            /**
                * @hidden
                */
            prettyPrint?: boolean;
            /**
                * @hidden
                */
            experiments?: any;
            /**
                * @hidden
                */
            tryingServers?: Array<string>;
    }
    /**
        * WebRTC Video Settings (aka Constraints)
        * @hidden
        *
        * @deprecated
        */
    export interface VideoSettings {
            /**
                * The width or width range, in pixels
                */
            width?: number | any;
            /**
                * The height or height range, in pixels
                */
            height?: number | any;
            /**
                * The exact aspect ratio (width in pixels divided by height in pixels, represented as a double rounded to the tenth decimal place) or aspect ratio range
                */
            aspectRatio?: number | any;
            /**
                * The exact frame rate (frames per second) or frame rate range
                */
            frameRate?: number | any;
            /**
                * This string (or each string, when a list) should be one of the members of VideoFacingModeEnum
                */
            facingMode?: string | any;
            /**
                * The origin-unique identifier for the source of the MediaStreamTrack
                */
            deviceId?: string;
            /**
                * The origin-unique group identifier for the source of the MediaStreamTrack. Two devices have the same group identifier if they belong to the same physical device
                */
            groupId?: string;
            /**
                *    Mandatory constraints object
                */
            mandatory?: Object;
            /**
                *    Optional constraints object
                */
            optional?: Object;
    }
    /**
        * Audio recording device info
        */
    export interface AudioSourceInfo {
            /**
                * Device id that can be used to choose audio playback device, see [Client.useAudioOutput]
                */
            id: number | string;
            /**
                * Device name
                */
            name: string;
            group: string;
    }
    /**
        * Video recording device info
        */
    export interface VideoSourceInfo {
            /**
                * Device id that can be used to choose video recording device, see [Client.useVideoSource]
                */
            id: number | string;
            /**
                * Device name
                */
            name: string;
            group: string;
    }
    /**
        * Audio playback device info
        * @class
        * @hidden
        * @deprecated
        */
    export interface AudioOutputInfo {
            /**
                * Device id that can be used to choose audio playback device, see [Client.useAudioOutput]</a>
                */
            id: number | string;
            /**
                * Device name, in WebRTC mode populated with real data only when application has been opened using HTTPS protocol
                */
            name: string;
            /**
                * @hidden
                */
            group: string;
    }
    /**
        * Network information
        * @hidden
        * @deprecated
        */
    export interface NetworkInfo {
            /**
                * Packet loss percentage
                */
            packetLoss: number;
    }
    /**
        * Enumeration of ACD statuses, use
        * [Client.setOperatorACDStatus] to set the status.
        *  For detailed information of ACD concept see the <a href="https://voximplant.com/docs/references/appengine/Module_ACD.html">Modules.ACD</a> documentation and the <a href="http://voximplant.com/docs/howto/#callcenter">appropriate HowTo's</a>.
        *
        * <img src="//voximplant.com/assets/images/2018/03/13/acdflow-2018-updated.svg" style="width: 500px;display: block;margin: 10px auto 0 auto;"/>
        *
        *
        * Example:
        * ``` js
        * // Enable ACD module
        * require(Modules.ACD);
        * //create Client instance and connect to the cloud
        * var vox = VoxImplant.getInstance();
        * vox.init({micRequired: true});
        * vox.addEventListener(VoxImplant.Events.SDKReady, function() {
        *   vox.connect();
        * });
        * //set the operator's status
        * vox.setOperatorACDStatus(VoxImplant.OperatorACDStatuses.Ready);
        * ```
    
        */
    export enum OperatorACDStatuses {
            /**
                * Operator is offline
                *
                *
                * <strong>Recommended logic flow</strong>
                *
                * |From status  |This status|To status|
                * |-------------|-----------|---------|
                * |NONE         |OFFLINE    |ONLINE   |
                * |ONLINE       |OFFLINE    |ONLINE   |
                * |READY        |OFFLINE    |ONLINE   |
                * |AFTER_SERVICE|OFFLINE    |ONLINE   |
                * |DND          |OFFLINE    |ONLINE   |
                * |TIMEOUT      |OFFLINE    |ONLINE   |
                *
                */
            Offline,
            /**
                * The operator is logged in, but not ready to handle incoming calls yet
                *
                *
                * <strong>Recommended logic flow</strong>
                *
                * |From status  |This status|To status|
                * |-------------|-----------|---------|
                * |OFFLINE      |ONLINE     |READY    |
                * |READY        |OFFLINE    |ONLINE   |
                *
                * <strong>!!! Set status to ONLINE and then to READY, if you want to flush operator's ban (after missed call)</strong>
                */
            Online,
            /**
                * Ready to handle incoming calls
                *
                *
                * <strong>Recommended logic flow</strong>
                *
                * |From status  |This status|To status |
                * |-------------|-----------|----------|
                * |OFFLINE      |READY      |IN_SERVICE|
                * |DND          |READY      |ONLINE    |
                * |AFTER_SERVICE|READY      |DND       |
                * |TIMEOUT      |READY      |TIMEOUT   |
                *
                */
            Ready,
            /**
                * Incoming call is in service
                *
                *
                * <strong>Recommended logic flow</strong>
                *
                * |From status|This status|To status    |
                * |-----------|-----------|-------------|
                * |READY      |IN_SERVICE |AFTER_SERVICE|
                *
                */
            InService,
            /**
                * An incoming call has ended and now an operator is processing after service work.
                *
                *
                * <strong>Recommended logic flow</strong>
                *
                * |From status|This status  |To status|
                * |-----------|-------------|---------|
                * |IN_SERVICE |AFTER_SERVICE|READY    |
                * |IN_SERVICE |AFTER_SERVICE|TIMEOUT  |
                * |IN_SERVICE |AFTER_SERVICE|DND      |
                * |IN_SERVICE |AFTER_SERVICE|OFFLINE  |
                *
                */
            AfterService,
            /**
                * The operator is on a break (e.g. having lunch).
                *
                *
                * <strong>Recommended logic flow</strong>
                *
                * |From status  |This status|To status|
                * |-------------|-----------|---------|
                * |READY        |TIMEOUT    |READY    |
                * |AFTER_SERVICE|TIMEOUT    |READY    |
                *
                */
            Timeout,
            /**
                * The operator is busy now and not ready to handle incoming calls (e.g. working on another call)
                *
                *
                * <strong>Recommended logic flow</strong>
                *
                * |From status  |This status|To status|
                * |-------------|-----------|---------|
                * |READY        |DND        |READY    |
                * |AFTER_SERVICE|DND        |READY    |
                *
                */
            DND
    }
    /**
        * VoxImplant login options
        * @class
        */
    export interface LoginOptions {
            /**
                * If set to false Web SDK can be used only for ACD status management
                */
            receiveCalls?: boolean;
            /**
                * If set to true user presence will be changed automatically while a call is in progress
                * @hidden
                */
            serverPresenceControl?: boolean;
            /**
                * @hidden
                */
            accessToken?: string;
            /**
                * A unique token for the current device. Use Client.getGUID() and save it at client storage (foe LocalStorage or IndexedDB)
                * @hidden
                */
            deviceToken?: string;
            /**
                * @hidden
                */
            mediaServer?: string;
    }
    export interface CallSettings {
            /**
                * The number to call. The international format E.164 is preferable
                */
            number: string;
            /**
                * Tells if video should be supported for the call
                */
            video?: VideoFlags | boolean;
            /**
                * Auto wire local streams to participants
                * if false - create empty localStream from audio api to generate sdp
                * @hidden
                */
            wiredLocal?: boolean;
            /**
                * Auto wire remote streams to DOM elements
                * @hidden
                */
            wiredRemote?: boolean;
            /**
                * Optional custom parameters (SIP headers) that should be passed with call (INVITE) message. Parameter names must start with "X-" to be processed by application. IMPORTANT: Headers size limit is 200 bytes.
                */
            extraHeaders?: {
                    [id: string]: string;
            };
            /**
                * Custom string associated with the call session. It can be passed to the cloud to be obtained from the [CallAlerting](https://voximplant.com/docs/references/voxengine/appevents#callalerting) event or [Call History](https://voximplant.com/docs/references/httpapi/managing_history#getcallhistory) using HTTP API. Maximum size is 200 bytes. Use the [Call.sendMessage] method to pass a string over the limit; in order to pass a large data use [media_session_access_url](https://voximplant.com/docs/references/httpapi/managing_scenarios#startscenarios) on your backend.
                */
            customData?: string;
            /**
                * @deprecated
                * @hidden
                */
            extraParams?: {
                    [id: string]: string;
            };
            /**
                * Use H264 video codec, if exist
                */
            H264first?: boolean;
            /**
                * Use VP8 video codec, if exist
                * @hidden
                */
            VP8first?: boolean;
            /**
                * @hidden
                */
            forceActive?: boolean;
            /**
                * @hidden
                */
            isConference?: boolean;
    }
    /**
        * @hidden
        */
    export interface InnerCallSettings extends CallSettings {
            id: string;
            displayName: string;
            active: boolean;
            state: CallState;
            mode: CallMode;
            usedSinkId: number | string;
            videoDirections: VideoFlags;
            hasEarlyMedia: boolean;
            audioDirections: AudioFlags;
            incoming: boolean;
    }
    /**
        * Call disconnecting flags
        */
    export interface DisconnectingFlags {
            /**
                * It is true, when call is answered elsewhere
                */
            answeredElsewhere: boolean;
    }
    /**
        * Structure for callstats.io integration,
        * see https://www.callstats.io/api/
        */
    export interface CallstatsIoParams {
            /**
                * Application ID is obtained from callstats.io.
                */
            AppID: string;
            /**
                * Application secret is obtained from callstats.io.
                */
            AppSecret: string;
            /**
                * If it's true it disables callstats.jss *window.onbeforeunload* parameter. It's false by default.
                */
            disableBeforeUnloadHandler?: boolean;
            /**
                * Application version specified by the developer.
                */
            applicationVersion?: string;
    }
    export interface LoginTokens {
            /**
                * You can use this token for login before accessExpire.
                */
            accessToken: string;
            /**
                * Refresh token. You can use it 1 time before refreshExpire.
                */
            refreshToken: string;
            /**
                * Seconds before the access token expiration (in UNIX timestamp format)
                */
            accessExpire: number;
            /**
                * Seconds before the refresh token expiration (in UNIX timestamp format)
                */
            refreshExpire: number;
    }
    /**
        * Video direction settings for <a href="../classes/client.html#call">Client.call()</a> and <a href="../classes/call.html#answer">Call.answer()</a>
        */
    export interface VideoFlags {
            /**
                * Set to true if you want to send video to the remote participant. It's false by default.
                */
            sendVideo: boolean;
            /**
                * Set to true if you want to receive video from remote participant. It's false by default. If it's false and an incoming call sends a video stream, the call will provide only an audio stream.
                */
            receiveVideo: boolean;
    }
    /**
        * @hidden
        */
    export interface AudioFlags {
            sendAudio: boolean;
    }
    /**
        * @hidden
        */
    export interface reinviteDescription {
            tracks: {
                    [id: string]: TrackType;
            };
            restartTransport?: boolean;
    }
    /**
        * Structure for outer logging
        */
    export interface LogRecord {
            /**
                * The text that is displayed in the browser console.
                */
            formattedText: string;
            /**
                * Name of the module that creates a record.
                */
            category: LogCategory;
            /**
                * Record label
                */
            label: string;
            /**
                * Possible LogLevel values:
                *
                * |Value|Mean   |
                * |-----|-------|
                * |1    |ERROR  |
                * |2    |WARNING|
                * |3    |INFO   |
                * |4    |TRACE  |
                *
                */
            level: LogLevel;
            /**
                * Record message
                */
            message: string;
    }
}

declare module 'voximplant-websdk/Logger' {
    /**
        * @hidden
        */
    export enum LogLevel {
            NONE = 0,
            ERROR = 1,
            WARNING = 2,
            INFO = 3,
            TRACE = 4
    }
    /**
        * @hidden
        */
    export enum LogCategory {
            SIGNALING = 0,
            RTC = 1,
            USERMEDIA = 2,
            CALL = 3,
            CALLEXP2P = 4,
            CALLEXSERVER = 5,
            CALLMANAGER = 6,
            CLIENT = 7,
            AUTHENTICATOR = 8,
            PCFACTORY = 9,
            UTILS = 10,
            ORTC = 11,
            MESSAGING = 12,
            REINVITEQ = 13,
            HARDWARE = 14,
            ENDPOINT = 15,
            EVENTTARGET = 16
    }
    /**
        * The client states
        */
    export enum ClientState {
            /**
                * The client is currently disconnected
                */
            DISCONNECTED,
            /**
                * The client is currently connecting
                */
            CONNECTING,
            /**
                * The client is currently connected
                */
            CONNECTED,
            /**
                * The client is currently logging in
                */
            LOGGING_IN,
            /**
                * The client is currently logged in
                */
            LOGGED_IN
    }
    /**
        * Common logger
        * @hidden
        */
    export class Logger {
            constructor(category: LogCategory, label: string, provider: LogManager);
            log(level: LogLevel, message: string): void;
            error(message: string): void;
            warning(message: string): void;
            info(message: string): void;
            trace(message: string): void;
    }
    /**
        * @hidden
        */
    export class LogManager {
            static logTick: number;
            static traceTick: number;
            shadowLogging: boolean;
            static get(): LogManager;
            /**
                * Decorator for tracing
                */
            static d_trace(category: LogCategory): (target: object, propertyKey: string, descriptor: TypedPropertyDescriptor<(...args: any[]) => any>) => TypedPropertyDescriptor<(...args: any[]) => any>;
            getSLog(): Array<string>;
            clearSilentLog(): void;
            setLoggerCallback(callback: {
                    (record: {
                            formattedText: string;
                            category: LogCategory;
                            label: string;
                            level: LogLevel;
                            message: string;
                    }): void;
            }): void;
            setPrettyPrint(state: boolean): void;
            setLogLevel(category: LogCategory, level: LogLevel): void;
            writeMessage(category: LogCategory, label: string, level: LogLevel, message: string | object): void;
            createLogger(category: LogCategory, label: string): Logger;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Hardware/index' {
    import * as Implement from 'voximplant-websdk/Hardware/src';
    export module Hardware {
            /**
                * Events that are triggered when hardware device is added/removed/updated.
                */
            enum HardwareEvents {
                    /**
                        * Event is triggered each time when device is added/removed. Devices that trigger the event: microphones, video camera and sound output (available only in Google Chrome).
                        */
                    DevicesUpdated,
                    /**
                        * Event is triggered when local video or audio is started. E.g. when local video or screen sharing is stared.
                        */
                    MediaRendererAdded,
                    MediaRendererUpdated,
                    /**
                        * Event is triggered when local video or audio streaming is stopped. E.g. when local video or screen sharing streaming is stopped.
                        */
                    MediaRendererRemoved,
                    /**
                        * Event is triggered before local video or audio streaming is stopped. E.g. before local video or screen sharing streaming is stopped.
                        */
                    BeforeMediaRendererRemoved
            }
            /**
                * Enum that represents video quality.
                */
            enum VideoQuality {
                    /**
                        * Set better video quality for the current web camera.
                        * This option uses the last value from the [CameraManager.testResolutions] function result,
                        * or the data set to the [CameraManager.loadResolutionTestResult].
                        * If there is no result for a target web camera, use 1280x720 resolution
                        */
                    VIDEO_QUALITY_HIGH,
                    /**
                        * Set medium video quality for the current web camera.
                        * This option uses the last value from the [CameraManager.testResolutions] function result,
                        * or the data set to the [CameraManager.loadResolutionTestResult].
                        * If there is no result for a target web camera, use 640x480 resolution
                        */
                    VIDEO_QUALITY_LOW,
                    /**
                        * Set lower video quality for the current web camera.
                        * This option uses the last value from the [CameraManager.testResolutions] function result,
                        * or the data set to the [CameraManager.loadResolutionTestResult].
                        * If there is no result for a target web camera, use 320x240 resolution
                        */
                    VIDEO_QUALITY_MEDIUM,
                    /**
                        * 160x120 resolution
                        */
                    VIDEO_SIZE_QQVGA,
                    /**
                        * 176x144 resolution
                        */
                    VIDEO_SIZE_QCIF,
                    /**
                        * 320x240 resolution
                        */
                    VIDEO_SIZE_QVGA,
                    /**
                        * 352x288 resolution
                        */
                    VIDEO_SIZE_CIF,
                    /**
                        * 640x360 resolution
                        */
                    VIDEO_SIZE_nHD,
                    /**
                        * 640x480 resolution
                        */
                    VIDEO_SIZE_VGA,
                    /**
                        * 800x600 resolution
                        */
                    VIDEO_SIZE_SVGA,
                    /**
                        * 1280x720 resolution
                        */
                    VIDEO_SIZE_HD,
                    /**
                        * 1600x1200 resolution
                        */
                    VIDEO_SIZE_UXGA,
                    /**
                        * 1920x1080 resolution
                        */
                    VIDEO_SIZE_FHD,
                    /**
                        * 3840x2160 resolution
                        */
                    VIDEO_SIZE_UHD
            }
            /**
                * Interface that may be used to manage audio devices, i.e. see current active device, select another active device and get the list of available devices.
                */
            class AudioDeviceManager extends Implement.AudioDeviceManager {
            }
            /**
                * Audio constraints. Audio device will be chosen according to these settings.</br>
                * Settings are specified via
                * [AudioDeviceManager.setDefaultAudioSettings]
                *   and
                *   [AudioDeviceManager.setCallAudioSettings].
                */
            interface AudioParams extends Implement.AudioParams {
            }
            /**
                * Interface that may be used to manage cameras on Android device.
                */
            class CameraManager extends Implement.CameraManager {
            }
            /**
                * Camera constraints. Hardware camera will be chosen according to these settings.</br>
                * Settings are specified via
                * [CameraManager.setDefaultVideoSettings]
                *   and [CameraManager.setCallVideoSettings].
                */
            interface CameraParams extends Implement.CameraParams {
            }
            /**
                * @hidden
                */
            interface SharingStream extends Implement.SharingStream {
            }
            /**
                * Interface for extended management of local audio/video streams.
                */
            class StreamManager extends Implement.StreamManager {
            }
            /**
                * @hidden
                */
            class IOSCacheManager extends Implement.IOSCacheManager {
            }
    }
    export default Hardware;
}

declare module 'voximplant-websdk/Call/Call' {
    import { CallEvents } from 'voximplant-websdk/Call/CallEvents';
    import { CallSettings, DisconnectingFlags, InnerCallSettings, VideoFlags, VideoSettings } from 'voximplant-websdk/Structures';
    import { PeerConnection } from 'voximplant-websdk/PeerConnection/PeerConnection';
    import { CallManager } from 'voximplant-websdk/Call/CallManager';
    import { CodecSorterUserCodecList } from 'voximplant-websdk/PeerConnection/SDP/Interfaces';
    import { EventListenerOption, EventTarget } from 'voximplant-websdk/EventTarget';
    import { EventHandlers } from 'voximplant-websdk/EventHandlers';
    import { Endpoint } from 'voximplant-websdk/Call/EndPoints/Endpoint';
    /**
        *
        */
    export enum CallState {
            ALERTING,
            PROGRESSING,
            CONNECTED,
            UPDATING,
            ENDED
    }
    /**
        * @hidden
        */
    export enum CallMode {
            P2P = 0,
            SERVER = 1
    }
    /**
        *
        */
    export abstract class Call extends EventTarget<CallEvents> {
            /**
                * @hidden
                */
            signalingConnected: boolean;
            /**
                * @hidden
                */
            settings: InnerCallSettings;
            /**
                * Callback for manual rearrangement or setup compatible codec list. If will set unknown/unsupported codec - it will
                * be ignored
                * @example
                * // example sorting video section to set h264 first
                * var currentCall = vox.call("exampleUser");
                * currentCall.rearangeCodecs = function(codecList){
                *   return new Promise(function(resolve,reject){
                *     for(var i=0;i<codecList.sections.length;i++){
                *       if(codecList.sections[i].kind.toLowerCase()=="video"){
                *         codecList.sections[i].codec.sort((a:string,b:string)=>{
                *           if(a.toLowerCase().indexOf("h264")!=-1
                *            &&a.toLowerCase().indexOf("uc")==-1)
                *              return -1;
                *           if(b.toLowerCase().indexOf("h264")!=-1
                *            &&b.toLowerCase().indexOf("uc")==-1)
                *              return 1;
                *           return 0;
                *         })
                *       }
                *     }
                *     resolve(codecList);
                *   })
                * };
                */
            rearangeCodecs: (codecList: CodecSorterUserCodecList, incoming?: boolean) => Promise<CodecSorterUserCodecList>;
            /**
                * @hidden
                */
            protected _callManager: CallManager;
            /**
                * @hidden
                */
            constructor(id: string, dn: string, incoming: boolean, settings: CallSettings);
            /**
                * @hidden
                */
            protected _promise: Promise<Object>;
            /**
                * @hidden
                * @returns {Promise<Object>}
                */
            readonly promise: Promise<Object>;
            /**
                * @hidden
                */
            protected _peerConnection: PeerConnection;
            /**
             * @hidden
             * @param peerConnection
             */
            peerConnection: PeerConnection;
            /**
                * @hidden
                * @returns {CallState}
                */
            readonly stateValue: CallState;
            /**
                * Returns call id
                * @returns {String}
                */
            id(): string;
            /**
                * Returns dialed number or caller id
                * @returns {String}
                */
            number(): string;
            /**
                * Returns display name, i.e. a name of the calling user, that will be displayed to the called user. Normally it's a human-readable version of CallerID, e.g. a person's name.
                */
            displayName(): string;
            /**
                * Returns headers
                * @returns {Object}
                */
            headers(): {
                    [id: string]: string;
            };
            /**
                * Returns 'true' if a call is active, otherwise returns 'false'. A single call (either inbound or outbound) is active by default, all other calls are inactive and should be activated via the <a href="#setactive">setActive</a> method. Only the active call sends and receives an audio/video stream.
                */
            active(): boolean;
            /**
                * @hidden
                * @param newState
                * @private
                */
            protected _setActive(newState: boolean): boolean;
            /**
                * Get the current state of a call.
                * Possible values are: "ALERTING", "PROGRESSING", "CONNECTED", "ENDED".
                * @returns {String}
                */
            state(): string;
            /**
                * Answer the incoming call. There are two methods for an <a href="//voximplant.com/docs/references/websdk/voximplant/events#incomingcall">incoming call</a>: <a href="#answer">answer</a> and <a href="#decline">decline</a>. Voice can be sended only after the <a href="#answer">answer</a> method call.
                * @param {String} customData Set custom string associated with call session. It can be later obtained from Call History <a href="//voximplant.com/docs/references/httpapi/#toc-getcallhistory">using HTTP API</a>, see the <a href="//voximplant.com/docs/references/httpapi/#struct_CallSessionInfoType">custom_data field in result</a>. Custom data can be retrieved on the part of Voxengine via the <a href="//voximplant.com/docs/references/appengine/VoxEngine.html#VoxEngine_customData">customData</a> method. Maximum size is 200 bytes.
                * @param {Object} extraHeaders Optional custom parameters (SIP headers) that are sent to another participant after accepting an incoming call. Header names have to begin with the 'X-' prefix. The "X-" headers could be handled only by SIP phones/devices.
                * @param {VideoFlags} useVideo [A set of flags](https://voximplant.com/docs/references/websdk/voximplant/videoflags) defining if sending and receiving video is allowed.
                */
            answer(customData?: string, extraHeaders?: {
                    [id: string]: string;
            }, useVideo?: VideoFlags): void;
            /**
                * Reject incoming call on all devices, where this user logged in.
                * @param {Object} extraHeaders Optional custom parameters (SIP headers) that should be sent after rejecting incoming call. Parameter names must start with "X-" to be processed by application
                */
            decline(extraHeaders?: {
                    [id: string]: string;
            }): void;
            /**
                * Reject incoming call on the part of Web SDK. If a call is initiated from the PSTN, the network will receive "reject" command; in case of a call from another Web SDK client, it will receive the [CallEvents.Failed] event with the 603 code.
                * @param {Object} extraHeaders Optional custom parameters (SIP headers) that should be sent after rejecting incoming call. Parameter names must start with "X-" to be processed by application
                */
            reject(extraHeaders?: {
                    [id: string]: string;
            }): void;
            /**
                * Hangup call
                * @param {[id:string]:string} extraHeaders Optional custom parameters (SIP headers) that should be sent after disconnecting/cancelling call. Parameter names must start with "X-" to be processed by application
                */
            hangup(extraHeaders?: {
                    [id: string]: string;
            }): void;
            /**
                * Send tone (DTMF). It triggers the <a href="https://voximplant.com/docs/references/appengine/CallEvents.html#CallEvents_ToneReceived">CallEvents.ToneReceived</a> event in our cloud.
                * @param {String} key Send tone according to pressed key: 0-9 , * , #
                */
            sendTone(key: string): void;
            /**
                * Mute sound
                */
            mutePlayback(): void;
            /**
                * Unmute sound
                */
            unmutePlayback(): void;
            /**
                * @hidden
                */
            restoreRMute(): void;
            /**
                * Mute microphone
                */
            muteMicrophone(): void;
            /**
                * Unmute microphone
                */
            unmuteMicrophone(): void;
            /**
                * Show/hide remote party video. *IMPORTANT*: Safari browser for iOS requires a user interface for playing video during a call. It should be interactive element like an HTML "button" with "onclick" handler that calls "play" method on the "video" HTML element.
                * @param {Boolean} [flag=true] Show/hide - true/false
                * @deprecated
                * @hidden
                */
            showRemoteVideo(flag?: boolean): void;
            /**
                * Set remote video position
                * @param {Number} x Horizontal position (px)
                * @param {Number} y Vertical position (px)
                * @function
                * @hidden
                */
            setRemoteVideoPosition(x: number, y: number): void;
            /**
                * Set remote video size
                * @param {Number} width Width in pixels
                * @param {Number} height Height in pixels
                * @function
                * @deprecated
                * @hidden
                */
            setRemoteVideoSize(width: number, height: number): void;
            /**
                * Send Info (SIP INFO) message inside the call
                *
                * You can get this message via the Voxengine [CallEvents.InfoReceived] event in our cloud.
                *
                * You can get this message in Web SDK on other side via the [CallEvents.InfoReceived] event; see the similar events for the <a href="//voximplant.com/docs/references/mobilesdk/ios/all/index.html#//api/name/call:didReceiveInfo:type:headers:">iOS</a> and <a href="//voximplant.com/docs/references/mobilesdk/android/com/voximplant/sdk/call/ICallListener.html#onSIPInfoReceived-com.voximplant.sdk.call.ICall-java.lang.String-java.lang.String-java.util.Map-">Android</a> SDKs.
                * @param {String} mimeType MIME type of the message, e.g. "text/plain", "multipart/mixed" etc.
                * @param {String} body Message content
                * @param {[id:string]:string} extraHeaders Optional headers to be passed with the message
                */
            sendInfo(mimeType: string, body: string, extraHeaders?: {
                    [id: string]: string;
            }): void;
            /**
                * Send text message. It is a special case of the [sendInfo] method as it allows to send messages only of "text/plain" type.
                *
                * You can get this message via the Voxengine [CallEvents.MessageReceived] event in our cloud.
                *
                * You can get this message in Web SDK on other side via the [CallEvents.MessageReceived] event; see the similar events for the <a href="//voximplant.com/docs/references/mobilesdk/ios/all/index.html#//api/name/call:didReceiveMessage:headers:">iOS</a> and <a href="//voximplant.com/docs/references/mobilesdk/android/com/voximplant/sdk/call/ICallListener.html#onMessageReceived-com.voximplant.sdk.call.ICall-java.lang.String-">Android</a> SDKs.
                * @param {String} msg Message text
                */
            sendMessage(msg: string): void;
            /**
                * Set video settings
                * @param {VoxImplant.VideoSettings|VoxImplant.FlashVideoSettings} settings Video settings for current call
                * @param {Function} [successCallback] Called in WebRTC mode if video settings were applied successfully
                * @param {Function} [failedCallback] Called in WebRTC mode if video settings couldn't be applied
                * @deprecated
                * @hidden
                */
            setVideoSettings(settings: VideoSettings, successCallback?: Function, failedCallback?: Function): void;
            /**
                * Returns HTML video element's id for the call
                * @deprecated
                * @hidden
                */
            getVideoElementId(): string;
            /**
                * Register a handler for the specified event. One event can have more than one handler; handlers are executed in order of registration.
                * Use the [removeEventListener] method to delete a handler.
                * @param {Function} event Event class (i.e. [CallEvents.Connected]). See [CallEvents].
                * @param {Function} handler Handler function. A single parameter is passed - object with event information
                * @deprecated
                * @hidden
                */
            addEventListener(event: CallEvents, handler: (ev: any) => void): void;
            /**
                * Register a handler for the specified event. The method is a shorter equivalent for *addEventListener*. One event can have more than one handler; handlers are executed in order of registration.
                * Use the [Call.off] method to delete a handler.
                *
                *
                * @example
                *   var currentCall = vox.call("exampleUser");
                *   currentCall.on(VoxImplant.CallEvents.Connected,onConnected);
                *   currentCall.on(VoxImplant.CallEvents.Disconnected,onDisconnected);
                *   currentCall.on(VoxImplant.CallEvents.Failed,onFailed);
                *   currentCall.on(VoxImplant.CallEvents.ICETimeout,onICETimeout);
                * @param {Function} event Event class (i.e. [CallEvents.Connected]. See [CallEvents].
                * @param {Function} handler Handler function. A single parameter is passed - object with event information
                */
            on(event: CallEvents, handler: (ev: any) => void, options?: EventListenerOption): void;
            /**
                * Remove handler for specified event
                * @param {Function} event Event class (i.e. [CallEvents.Connected]). See [CallEvents].
                * @param {Function} handler Handler function, if not specified all event handlers will be removed
                * @deprecated
                * @hidden
                */
            removeEventListener(event: CallEvents, handler?: (ev: any) => void): void;
            /**
                * Remove a handler for the specified event. The method is a shorter equivalent for *removeEventListener*. If a number of events has the same function as a handler, the method can be called multiple times with the same handler argument.
                * @param {Function} event Event class (i.e. [CallEvents.Connected]). See [CallEvents].
                * @param {Function} handler Handler function, if not specified all event handlers will be removed
                * @function
                */
            off(event: CallEvents, handler?: (ev: any) => void): void;
            /**
                * @hidden
                */
            dispatchEvent(e: any): void;
            /**
                * @hidden
                * @param headers
                * @param sdp
                * @returns {boolean}
                */
            onConnected(headers: {
                    [id: string]: string;
            }, sdp: string): boolean;
            /**
                * @hidden
                * @param headers
                * @param params
                * @returns {boolean}
                */
            onDisconnected(headers: {
                    [id: string]: string;
            }, params: DisconnectingFlags): Promise<boolean>;
            /**
                * @hidden
                * @param code
                * @param reason
                * @param headers
                * @returns {boolean}
                */
            onFailed(code: number, reason: string, headers: {
                    [id: string]: string;
            }): boolean;
            /**
                * @hidden
                * @returns {boolean}
                */
            onStopRinging(): boolean;
            /**
                * @hidden
                * @returns {boolean}
                */
            onRingOut(): boolean;
            /**
                * @hidden
                * @returns {boolean}
                */
            onTransferComplete(): boolean;
            /**
                * @hidden
                * @returns {boolean}
                */
            onTransferFailed(): boolean;
            /**
                * @hidden
                * @param call
                * @param type
                * @param subType
                * @param body
                * @param headers
                * @returns {boolean}
                */
            onInfo(call: Call, type: string, subType: string, body: string, headers: {
                    [id: string]: string;
            }): boolean;
            /**
                *
                * The method makes a call active, i.e. change the [active] flag to 'true'.
                *  A single call (either inbound or outbound) is active by default, all other calls are inactive and should be activated.
                * @param {boolean} flag
                * @returns {Promise<EventHandlers.Updated>}
                */
            setActive(flag: boolean): Promise<EventHandlers.Updated>;
            /**
                * @hidden
                */
            checkCallMode(mode: CallMode): boolean;
            /**
                * @hidden
                */
            canStartSendingCandidates(): void;
            /**
                * @hidden
                */
            notifyICETimeout(): void;
            /**
                *  Start/stop sending video from a call. In case of a remote participant uses a Web SDK client, it will receive either the [EndpointEvents.RemoteMediaAdded] or [EndpointEvents.RemoteMediaRemoved] event accordingly.
                * *IMPORTANT*: Safari browser for iOS requires a user interface for playing video during a call. It should be interactive element like an HTML "button" with "onclick" handler that calls "play" method on the "video" HTML element.
                * @param flag
                */
            sendVideo(flag: boolean): Promise<EventHandlers.Updated>;
            /**
                * @hidden
                */
            receiveVideo(): Promise<EventHandlers.Updated>;
            /**
                * @hidden
                * @param audio
                * @param video
                */
            sendMedia(audio: boolean, video: boolean): Promise<EventHandlers.Updated>;
            /**
                * @hidden
                * @param flag
                */
            sendAudio(flag: boolean): Promise<EventHandlers.Updated>;
            /**
                * Get current PeerConnection LocalStream OR if set wiredLocal === false - try get newOne from UserMediaManager
                * @hidden
                * @deprecated
                */
            getLocalStream(): Promise<MediaStream>;
            /**
                * @hidden
                * @deprecated
                * @param stream
                * @returns {Promise<void>|Promise}
                */
            setLocalStream(stream: MediaStream): Promise<void>;
            /**
                * Enable screen sharing. Works in Chrome and Firefox. For Chrome, custom
                * extension must be created and installed from this template:
                * "https://github.com/voximplant/voximplant-chrome-extension". "matches"
                * section in the extension's "manifest.json" should be set to app website url(s).
                * Browser will ask user for a window or screen to share. Can be called multiple times
                * to share multiple windows.
                * @param {boolean} showLocalView if set to true, a screen sharing preview will be displayed locally in the same
                * way as it's done for video calls. It is false by default. *IMPORTANT*: Safari browser for iOS requires a user interface for playing video during a call. It should be interactive element like an HTML "button" with "onclick" handler that calls "play" method on the "video" HTML element.
                *
                */
            shareScreen(showLocalView?: boolean, replaceVideo?: boolean): Promise<EventHandlers.Updated>;
            /**
                * Stops screen sharing. If 'shareScreen' was called multiple times, this will stop
                * sharing for all windows/screens
                */
            stopSharingScreen(): Promise<EventHandlers.Updated>;
            /**
                * @hidden
                * @deprecated
                * @returns {Promise<void>|Promise}
                */
            wireRemoteStream(): Promise<void>;
            /**
                * @hidden
                * @returns {Promise<MediaStream>|Promise}
                */
            getRemoteAudioStreams(): Promise<MediaStream>;
            /**
                * @hidden
                * @deprecated
                * @returns {Promise<MediaStream>|Promise}
                */
            getRemoteVideoStreams(): Promise<MediaStream>;
            /**
                * get wired state for remote audio streams
                * @hidden
                * @deprecated
                * @returns {boolean}
                */
            getRemoteWiredState(): boolean;
            /**
                * get wired state for local audio streams
                * @hidden
                * @deprecated
                * @returns {boolean}
                */
            getLocalWiredState(): boolean;
            /**
                * Use specified audio output , use [audioOutputs] to get the list of available audio output
                * @param {String} id Id of the audio source
                * @hidden
                * @deprecated
                */
            useAudioOutput(id: string): Promise<void>;
            /**
                * Returns HTML audio element's id for the audio call
                * @returns string
                * @deprecated
                * @hidden
                */
            getAudioElementId(): string;
            /**
                * For testing and debug
                * @hidden
                */
            getDirections(): Object;
            /**
                * For testing and debug
                * @hidden
                */
            getStreamActivity(): Object;
            /**
                * @hidden
                */
            hdnFRS(): void;
            /**
                * @hidden
                */
            hdnFRSPrep(): void;
            /**
                * @hidden
                * @param headers
                * @param sdp
                */
            runIncomingReInvite(headers: {
                    [id: string]: string;
            }, sdp: string): void;
            /**
                * @hidden
                * @param state
                */
            setActiveForce(state: any): void;
            /**
                * Get the call duration
                * @return the call duration in milliseconds
                */
            getCallDuration(): number;
            /**
                * Get all current [Endpoint]s in the call.
                * @returns {Endpoint[]}
                */
            getEndpoints(): Endpoint[];
            capMaxBitrate(maxBitrate: any): void;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Signaling/VoxSignalingHandler' {
    /**
      * Handler of signaling connection events
      * @hidden
      */
    export interface VoxSignalingHandler {
        onSignalingConnected(): any;
        onSignalingClosed(): any;
        onSignalingConnectionFailed(errorMessage: string): any;
        onMediaConnectionFailed(): any;
    }
}

declare module 'voximplant-websdk/EventTarget' {
    type EventNamespace = 'user' | 'system' | 'default';
    /**
        * @hidden
        */
    interface EventListenerInstance {
            listener: Function;
            options?: EventListenerOption;
            _triggered: boolean;
            _namespace: EventNamespace;
    }
    /**
        *
        */
    export interface EventListenerOption {
            once?: boolean;
            capture?: boolean;
    }
    /**
        * @hidden
        */
    export abstract class EventTarget<EventType> {
            /**
                * @hidden
                * @type {{}}
                */
            eventListeners: {
                    (event: any): EventListenerInstance[];
            };
            /**
                *
                * @param event
                * @param handler
                * @param options
                * @hidden
                */
            sysOn(event: EventType, handler: (ev: any) => void, options?: EventListenerOption): void;
            /**
                *
                * @param event
                * @param handler
                * @hidden
                */
            sysOff(event: EventType, handler?: (ev: any) => void): void;
            on(event: EventType, handler: (ev: any) => void, options?: EventListenerOption): void;
            off(event: EventType, handler?: (ev: any) => void): void;
            /**
                * @hidden
                * @param e
                */
            dispatchEvent(e: any): void;
            /**
                * @hidden
                * @deprecated
                * @param {EventType} event
                * @param {Function} handler
                */
            removeEventListener(event: EventType, handler?: (ev: any) => void): void;
            /**
                * @hidden
                * @deprecated
                * @param {EventType} event
                * @param {EventListenerObject} handler
                * @param options
                */
            addEventListener(event: EventType, handler: (ev: any) => void, options?: EventListenerOption): void;
            /**
                * @hidden
                * @param {EventType} event
                * @param {EventListenerObject} handler
                */
            addDefaultEventListener(event: EventType, handler?: (ev: any) => void): void;
            /**
                * @hidden
                * @param {EventType} event
                */
            removeDefaultEventListener(event: EventType): void;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
    export {};
}

declare module 'voximplant-websdk/Legacy/ZingayaAPI' {
    import { Client } from "voximplant-websdk/Client";
    /**
        * @hidden
        */
    export class ZingayaAPI {
            /**
                * @hidden
                */
            onConnectionFailed: any;
            /**
                * @hidden
                */
            onConnectionEstablished: any;
            /**
                * @hidden
                */
            onCheckComplete: any;
            /**
                * @hidden
                */
            onCallFailed: any;
            /**
                * @hidden
                */
            onCallConnected: any;
            /**
                * @hidden
                */
            onCallEnded: any;
            /**
                * @hidden
                */
            onCallRinging: any;
            /**
                * @hidden
                */
            onCallMediaStarted: any;
            /**
                * @hidden
                */
            onVoicemail: any;
            /**
                * @hidden
                */
            onNetStatsReceived: any;
            /**
                * @hidden
                * @param client
                */
            constructor(client: Client);
            /**
                * @hidden
                * @param serverAddress
                * @param referrer
                * @param extra
                * @param appName
                */
            connectTo(serverAddress: string, referrer: string, extra: any, appName: string): void;
            /**
                * @hidden
                */
            connect(): void;
            /**
                * @hidden
                * @param video
                * @param onMediaAccessGranted
                * @param onMediaAccessRejected
                * @param stopStream
                */
            requestMedia(video: boolean, onMediaAccessGranted?: Function, onMediaAccessRejected?: Function, stopStream?: boolean): void;
            /**
                * @hidden
                * @param callId
                * @param headers
                */
            hangupCall(callId: string, headers: {
                    [id: string]: string;
            }): void;
            /**
                * @hidden
                * @param destination
                * @param useVideo
                * @param headers
                * @param extraParams
                */
            callTo(destination: string, useVideo: boolean, headers: {
                    [id: string]: string;
            }, extraParams: {
                    [id: string]: string;
            }): void;
            /**
                * @hidden
                * @param callId
                */
            voicemailPromptFinished(callId: string): void;
            /**
                * @hidden
                * @param len
                */
            makeid(len: number): string;
            /**
                * @hidden
                * @param doMute
                */
            muteMicrophone(doMute: boolean): void;
            /**
                * @hidden
                * @param callId
                * @param digit
                */
            sendDigit(callId: string, digit: string): void;
            /**
                * @hidden
                * @param mic
                * @param net
                */
            startPreFlightCheck(mic?: boolean, net?: boolean): void;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/EventHandlers' {
    import { DisconnectingFlags, LoginTokens, NetworkInfo, OperatorACDStatuses } from 'voximplant-websdk/Structures';
    import { Call, CallState } from 'voximplant-websdk/Call/Call';
    import { Endpoint } from 'voximplant-websdk/Call/EndPoints/Endpoint';
    import { MediaRenderer } from 'voximplant-websdk/Media/MediaRenderer';
    import { TrackType } from 'voximplant-websdk/Types';
    import { Statistic } from 'voximplant-websdk/Stats/Structures';
    /**
        *
        * | Handler               | Event                         | Dispatch by               |
        * |-----------------------|-------------------------------|---------------------------|
        * |[AuthResult]           |[Events.AuthResult]            |[Client.login]<br>[Client.loginWithOneTimeKey]<br>[Client.loginWithToken]       |
        * |[AuthTokenResult]      |[Events.RefreshTokenResult]    |[Client.tokenRefresh]      |
        * |[ConnectionFailed]     |[Events.ConnectionFailed]      |[Client.connect]           |
        * |[IncomingCall]         |[Events.IncomingCall]          |None                       |
        * |[MicAccessResult]      |[Events.MicAccessResult]       |[Client.init]<br>[Client.attachRecordingDevice]<br>[Client.setVideoSettings] |
        * |[NetStatsReceived]     |[Events.NetStatsReceived]      |None                       |
        * |[SDKReady]             |[Events.SDKReady]              |[Client.init]              |
        * |[CallEvent]            |[CallEvents.ICECompleted]<br>[CallEvents.ICETimeout]<br>[CallEvents.ProgressToneStart]<br>[CallEvents.ProgressToneStop]<br>[CallEvents.TransferComplete]<br>[CallEvents.TransferFailed]|[Client.connect]<br>[Client.call]<br>[Call.answer]<br>[Client.transferCall]|
        * |[CallEventWithHeaders] |[CallEvents.Connected]         |[Client.call]<br>[Call.answer]|
        * |[Disconnected]         |[CallEvents.Disconnected]      |[Call.reject]<br>[Call.hangup]<br>Call disconnected from another side|
        * |[Failed]               |[CallEvents.Failed]            |[Client.call]              |
        * |[InfoReceived]         |[CallEvents.InfoReceived]      |[Call.sendInfo]            |
        * |[MessageReceived]      |[CallEvents.CallEvents]        |[Call.sendMessage]         |
        * |[MediaElementCreated]  |[CallEvents.MediaElementCreated]|New remote media stream received.|
        * |[Updated]              |[CallEvents.Updated]           |[Call.sendVideo]<br>[Call.setActive]<br>[Call.setVideoSettings]<br>[Call.shareScreen]<br>[Call.stopSharingScreen]<br>[Call.useAudioOutput]|
        * |[StateUpdated]         |[CallEvent.StateUpdated]       |  |
        * |[ActiveUpdated]        |[CallEvent.ActiveUpdated]      |  |
        */
    export namespace EventHandlers {
            import QualityIssueLevel = Statistic.QualityIssueLevel;
            interface AuthResult extends AuthTokenResult {
                    /**
                        *    Authorized user's display name
                        */
                    displayName?: string;
                    /**
                        *    This parameter is used to calculate hash parameter for
                        *    [Client.loginWithOneTimeKey] method. AuthResult with the key dispatched after
                        *    [Client.requestOneTimeLoginKey] method was called
                        */
                    key?: string;
            }
            interface AuthTokenResult {
                    /**
                        * @hidden
                        */
                    name: string;
                    /**
                        * Refresh token error code, possible values are:
                        *
                        * |Code|Description            |
                        * |----|-----------------------|
                        * |401 |invalid token          |
                        * |404 |invalid username       |
                        * |500 |internal error         |
                        * |701 |refresh token expired  |
                        */
                    code?: number;
                    /**
                        *    True in case of successful refresh, false - otherwise
                        */
                    result: boolean;
                    /**
                        * New tokens structure
                        */
                    tokens?: LoginTokens;
            }
            interface ConnectionFailed {
                    /**
                        *    Failure reason description
                        */
                    message: string;
            }
            interface IncomingCall {
                    /**
                        *    Incoming call instance.
                        *    See [Call] function for details
                        */
                    call: Call;
                    /**
                        *    Optional SIP headers received with the message
                        */
                    headers?: Object;
                    /**
                        * True if the caller initiated video call
                        */
                    video?: boolean;
            }
            interface MicAccessResult {
                    /**
                        *    True is access was allowed, false - otherwise
                        */
                    result: boolean;
                    /**
                        *    MediaStream object
                        */
                    stream: MediaStream;
            }
            interface NetStatsReceived {
                    /**
                        *    Network info object
                        */
                    stats: NetworkInfo;
            }
            interface SDKReady {
                    /**
                        *    SDK version
                        */
                    version: string;
            }
            interface CallEvent {
                    /**
                        *  Call that triggered the event
                        */
                    call: Call;
                    /**
                        * @hidden
                        */
                    name: string;
            }
            interface CallEventWithHeaders extends CallEvent {
                    /**
                        * Optional SIP headers are received with the message
                        */
                    headers?: Object;
            }
            interface Disconnected extends CallEventWithHeaders {
                    /**
                        * Optional disconnecting flags
                        */
                    params?: DisconnectingFlags;
            }
            interface Failed extends CallEventWithHeaders {
                    /**
                        * Call status code (i.e. 486)
                        *
                        * Most frequent status codes:
                        *
                        * |Code|Description                       |
                        * |----|----------------------------------|
                        * |486 |Destination number is busy        |
                        * |487 |Request terminated                |
                        * |603 |Call was rejected                 |
                        * |404 |Invalid number                    |
                        * |480 |Destination number is unavailable |
                        * |402 |Insufficient funds                |
                        */
                    code: number;
                    /**
                        *  Status message of a call failure (i.e. Busy Here)
                        */
                    reason: string;
            }
            interface InfoReceived extends CallEventWithHeaders {
                    /**
                        *  Content of the message
                        */
                    body: string;
                    /**
                        *  MIME type of INFO message
                        */
                    mimeType: string;
            }
            interface MessageReceived extends CallEvent {
                    /**
                        *  Content of the message
                        */
                    text: string;
            }
            interface MediaElementCreated extends CallEvent {
                    /**
                        *  Type of media
                        */
                    type: string;
                    /**
                        * Renderer element
                        */
                    element: HTMLMediaElement;
            }
            interface Updated extends CallEvent {
                    /**
                        * True in case of successful updating, false in other cases.
                        */
                    result: boolean;
            }
            /**
                * @hidden
                */
            interface UpdateFailed extends CallEvent {
                    /**
                        *  Most frequent status codes:
                        *
                        * |Code|Description                                |
                        * |----|-------------------------------------------|
                        * |10  |Timeout                                    |
                        * |11  |Trying to hold call in wrong state         |
                        * |12  |Trying change call in state UPDATING       |
                        * |13  |Media access denied                      |
                        * |14  |Trying change call state to the same state |
                        * |20  |Server reject                              |
                        */
                    code: number;
            }
            /**
                * @hidden
                */
            interface LocalVideoStreamAdded extends MediaElementCreated {
                    videoStream: MediaStream;
            }
            interface SIPRegistrationResult {
                    /**
                        * @hidden
                        */
                    name: string;
                    /**
                        * SIP registration id
                        */
                    id: string;
                    /**
                        * SIP URI
                        */
                    sipuri: string;
                    /**
                        * Status code, if error
                        */
                    status?: number;
                    /**
                        * Reason, if error
                        */
                    reason?: string;
            }
            interface EndpointHandler {
                    /**
                        * @hidden
                        */
                    name: string;
                    call: Call;
                    endpoint: Endpoint;
            }
            interface EndpointMediaHandler extends EndpointHandler {
                    mediaRenderer: MediaRenderer;
            }
            interface ACDStatusEvent {
                    id: string;
                    status: OperatorACDStatuses;
            }
            interface ACDErrorEvent {
                    message: string;
                    code: number;
            }
            interface SQErrorEvent {
                    message: string;
                    code: number;
            }
            interface ActiveUpdated extends CallEvent {
                    /**
                        * Old call's activity status
                        */
                    old: boolean;
                    /**
                        * Current call's activity status
                        */
                    new: boolean;
            }
            interface StateUpdated extends CallEvent {
                    /**
                        * Old call's state
                        */
                    old: CallState;
                    /**
                        * Current call's state
                        */
                    new: CallState;
            }
            /**
                * Reported in a handler function for [CallEvents.QualityIssueCodecMismatch].
                * The issue level is [QualityIssueLevel.Critical] if a stream is not sent or [QualityIssueLevel.Major] in case of codec mismatch.
                * Possible reasons:
                * - The device does not support a selected codec. For example, if H264first is specified and the device does not support this hardware codec, the issue will be triggered.
                * - The stream is not being sent for some reasons. In this case sendCodec will be undefined.
                * - Different codecs are specified in the call endpoints.
                *
                * Only in Chrome
                */
            interface CodecMismatchIssue extends CallEvent {
                    /**
                        * Issue level.
                        */
                    level: QualityIssueLevel;
                    /**
                        * Type of stream.
                        */
                    kind: TrackType;
                    /**
                        * Codec that is currently used or undefined if a stream is not sent.
                        */
                    sendCodec: string | undefined;
            }
            /**
                * Reported in a handler function for [CallEvents.QualityIssueHighMediaLatency].
                * Latency is calculated based on rtt (round trip time) and jitter buffer delay. Latency refers to the time it takes a voice/video packet to reach its destination plus the time it waits in a jitter buffer. Sufficient latency causes call participants to speak over the top of each other.
                * The issue level may vary during the call.
                * Possible reasons:
                * - Network congestion/delays.
                * - Lack of bandwidth.
                *
                * Only in Chrome
                */
            interface HighMediaLatencyIssue extends CallEvent {
                    /**
                        * Issue level.
                        */
                    level: QualityIssueLevel;
                    /**
                        * Average latency for the last 2.5 seconds measured in milliseconds.
                        */
                    latency: number;
            }
            /**
                * Reported in a handler function for [CallEvents.QualityIssueICEDisconnected].
                * The issue level is always [QualityIssueLevel.Critical] as there is no media in the call until the issue is resolved or [QualityIssueLevel.None] when the issue has been resolved.
                * Event may be triggered intermittently and resolved just as spontaneously on less reliable networks, or during temporary disconnections.
                * Possible reasons:
                * - Network issues.
                */
            interface ICEDisconnectedIssue extends CallEvent {
                    /**
                        * Issue level.
                        */
                    level: QualityIssueLevel;
            }
            /**
                * Reported in a handler function for [CallEvents.QualityIssueLocalVideoDegradation].
                * Reports that a video resolution being sent to an endpoint is lower than a captured video resolution, so it affects the quality of remote video or screen sharing on a remote participant side, but do not affect the quality of a local video preview.
                * The issue level may vary during the call.
                * Possible reasons:
                * - High CPU load during the video call.
                * - Network issues such as poor internet connection or low bandwidth.
                *
                * Only in Chrome for video
                * Only in Firefox for sharing
                */
            interface LocalVideoDegradationIssue extends CallEvent {
                    /**
                        * Issue level.
                        */
                    level: QualityIssueLevel;
                    /**
                        * Type of stream.
                        */
                    kind: TrackType;
                    /**
                        * Video frame width set in [Config.videoConstraints].
                        */
                    targetWidth?: number;
                    /**
                        * Video frame height set in [Config.videoConstraints].
                        */
                    targetHeight?: number;
                    /**
                        * Sent video frame width.
                        */
                    actualWidth?: number;
                    /**
                        * Sent video frame height.
                        */
                    actualHeight?: number;
                    /**
                        * Sent sharing fps. 15 fps is maximum for sharing in Firefox. When fps if lower then 4, the issue level is [QualityIssueLevel.Critical], when fps is lower then 8, the issue level is [QualityIssueLevel.Major], when fps is lower than 15, the issue level is [QualityIssueLevel.Minor].
                        */
                    fps?: number;
            }
            /**
                * Reported in a handler function for [CallEvents.QualityIssueLowBandwidth].
                * Issue level may vary during the call. SDK may report [QualityIssueLevel.Major] or [QualityIssueLevel.Minor] while detecting network capabilities right after the call start.
                * Target bitrate depends on the outbound video frame resolution. If the resolution of outbound video frames is changed, target bitrate can also be changed (increased or degraded).
                * Possible reasons:
                * - Network issues.
                * - Background state of an application.
                * @hidden
                */
            interface LowBandwidthIssue extends CallEvent {
                    /**
                        * Issue level.
                        */
                    level: QualityIssueLevel;
                    /**
                        * Bitrate required to send video with current resolution with a good quality. Measured in bits per second.
                        */
                    targetBitrate: number;
                    /**
                        * Actual bitrate. Measured in bits per second.
                        */
                    actualBitrate: number;
            }
            /**
                * Reported in a handler function for [CallEvents.QualityIssueNoAudioSignal].
                * Issue level can be only [QualityIssueLevel.Critical] if the issue is detected or [QualityIssueLevel.None] if the issue is not detected or is already resolved.
                * Depending on the audio capturing device manufacturer, the issue may be occasionally reported in case of a pause in a conversation.
                * Possible reasons:
                * - Application or other library mutes the microphone via the muteMicrophone Web SDK API.
                *
                * Only in Chrome
                * @hidden
                */
            interface NoAudioSignalIssue extends CallEvent {
                    /**
                        * Issue level.
                        */
                    level: QualityIssueLevel;
            }
            /**
                * Reported in a handler function for [CallEvents.QualityIssuePacketLoss].
                * Packet loss can lead to missing of entire sentences, awkward pauses in the middle of a conversation or robotic voice during the call.
                * Issue level may vary during the call.
                * Possible reasons:
                * - Network congestion.
                * - Bad hardware (parts of the network infrastructure).
                */
            interface PacketLossIssue extends CallEvent {
                    /**
                        * Issue level.
                        */
                    level: QualityIssueLevel;
                    /**
                        * Average packet loss for 2.5 seconds.
                        */
                    packetLoss: number;
            }
    }
}

declare module 'voximplant-websdk/Media/MediaRenderer' {
    /**
        * It is the wrapper for the HTMLMediaElement and its MediaStream.
        *   You can get this object on
        *   the [HardwareEvents.MediaRendererAdded] and
        *   [HardwareEvents.MediaRendererRemoved] for local media.
        *
        *   For remote media sources, you can get an instance
        *   of this object from [Endpoint] or
        *   [EndpointEvents.RemoteMediaAdded]
        *   or
        *   [EndpointEvents.RemoteMediaRemoved]
        */
    export class MediaRenderer {
            /**
                * A source stream sended from/to some Endpoint. The type of a stream is specified via the [kind] property.
                *
                * You can use the property for modifying and filtering source streams. E.g. for face masks and CV (computer vision).
                */
            stream: MediaStream;
            /**
                * Describe the tag and type of media, which are placed in this container.
                *   <ul>
                *   <li>Kind "audio" means &lt;audio&gt; HTML element and sound-only media stream</li>
                *   <li>Kind "video" means &lt;video&gt; HTML element and either video-only or audio plus video media stream</li>
                *   <li>Kind "sharing" the same as kind "video", but literally tell you "This is screen sharing"</li>
                *   </ul>
                */
            kind: 'audio' | 'video' | 'sharing';
            /**
                * @hidden
                */
            placeOnDom: boolean;
            /**
                * Source of the media stream. Set to "true" for the local streams, "false" for the remote streams.
                */
            isLocal: boolean;
            /**
                * HTML element where rendering is executed.
                */
            element: HTMLMediaElement;
            /**
                * Create new MediaRenderer for a local or a remote media stream
                * @param {MediaStream} stream
                * @param {"audio" | "video" | "sharing"} kind
                * @param {boolean} placeOnDom
                * @param {boolean} isLocal
                * @hidden
                */
            constructor(
            /**
                * A source stream sended from/to some Endpoint. The type of a stream is specified via the [kind] property.
                *
                * You can use the property for modifying and filtering source streams. E.g. for face masks and CV (computer vision).
                */
            stream: MediaStream, 
            /**
                * Describe the tag and type of media, which are placed in this container.
                *   <ul>
                *   <li>Kind "audio" means &lt;audio&gt; HTML element and sound-only media stream</li>
                *   <li>Kind "video" means &lt;video&gt; HTML element and either video-only or audio plus video media stream</li>
                *   <li>Kind "sharing" the same as kind "video", but literally tell you "This is screen sharing"</li>
                *   </ul>
                */
            kind: 'audio' | 'video' | 'sharing', 
            /**
                * @hidden
                */
            placeOnDom?: boolean, 
            /**
                * Source of the media stream. Set to "true" for the local streams, "false" for the remote streams.
                */
            isLocal?: boolean, deprecatedId?: string, isConference?: boolean);
            /**
                * Unique ID of MediaRender
                */
            readonly id: string;
            /**
                * @hidden
                */
            renderDefault(): void;
            /**
                * Render (display) current instance of MediaRenderer to the HTMLElement in the DOM tree. If the container paramater is not specified, the method will append rendering to the body element.
                * The method allows to render manually in cases of:
                * 1. Default rendering was turned off. If you subscribe to the [EndpointEvents.RemoteMediaAdded] event, Web SDK will no longer render remote audio/video stream automatically so you have to call this method with optional __container__ parameter.
                * 2. default rendering is active, but you want to change rendering container. Call the method with the specified HTMLElement.
                * @param {HTMLElement} container place for rendering.
                */
            render(container?: HTMLElement): void;
            /**
                * @hidden
                * @type {MediaStream}
                */
            replaceVideo(stream: MediaStream): void;
            /**
                * Destroy current unit and free resources.
                * @hidden
                */
            clear(): void;
            /**
                * Set current MediaRenderer output volume. The range is from 0 to 1.
                * @param {number} level
                */
            setVolume(level: number): void;
            /**
                * Set the output audio device for current MediaRenderer. ID can be retrieved via the [AudioDeviceManager.getOutputDevices] method.
                * @param {string} id`
                */
            useAudioOutput(id: string): void;
            /**
                * Run when current MediaRenderer unit was destroyed
                * @hidden
                */
            onDestroy: Function;
            /**
                * Run when current MediaRenderer unit will destroyed
                * @hidden
                */
            onBeforeDestroy: Function;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Messaging/src/Messenger' {
    import { MsgEvent } from "voximplant-websdk/Signaling/MsgEvent";
    import { Conversation } from 'voximplant-websdk/Messaging/src/Conversation';
    import { Message } from 'voximplant-websdk/Messaging/src/Message';
    import { ConversationParticipant, SerializedConversation, SerializedMessage } from "voximplant-websdk/Messaging/src/Structures";
    import Messaging from 'voximplant-websdk/Messaging';
    /**
        * @hidden
        */
    export class Messenger {
            /**
                * @hidden
                */
            static rejectTimeout: number;
            /**
                * @hidden
                */
            constructor();
            /**
                * @hidden
                */
            static getInstance(): Messenger;
            /**
                * Register a handler for the specified event.
                * @hidden
                * @deprecated
                * @param event Event identifier
                * @param handler JavaScript function that will be called when the specified event is triggered. Please note that function is called without 'this' binding.
                */
            addEventListener(event: Messaging.MessengerEvents, handler: Function): void;
            /**
                * Remove a handler for the specified event.
                * @hidden
                * @deprecated
                * @param event Event identifier
                * @param handler Reference to the JavaScript function to remove from event listeners. If not specified, removes all event listeners from the specified event.
                */
            removeEventListener(event: Messaging.MessengerEvents, handler?: Function): void;
            /**
                * Register a handler for any of the [MessengerEvents].
                * One event can have more than one handler. Handlers are executed in the order of registration.
                * Use the [Messenger.off] method to remove a handler.
                * @param event
                * @param handler
                */
            on(event: Messaging.MessengerEvents, handler: Function): void;
            /**
                * Remove a handler for one of the [MessengerEvents].
                * If a number of events has the same function as a handler, the method can be called multiple times with the same handler argument.
                * @param event
                * @param handler
                */
            off(event: Messaging.MessengerEvents, handler?: Function): void;
            /**
                * @hidden
                * @param event
                * @param payload
                */
            _dispatchEvent<E extends Messaging.MessengerEvents>(event: E, payload: Messaging.MessengerEventsPayload<E>, uuid?: string): void;
            /**
                * Add new promise for awaiting.
                * @param uuid
                * @param resolve
                * @param reject
                * @hidden
                */
            _registerPromise(uuid: string, resolve: Function, reject: Function): void;
            /**
                * Get a conversation by its UUID.
                * Triggers the [MessengerEvents.GetConversation] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetConversation] event and provide a handler consuming an object with the [EventHandlers.GetConversationEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * Rejects to a [Messaging.MessengerError] if the requested conversation is not public (see [Conversation.publicJoin]) or the current user isn't/wasn't a participant of the non-public conversation.
                * @see [MessengerEvents.GetConversation]
                * @see [MessengerEvents.Error]
                * @param uuid
                * @returns {Promise<EventHandlers.GetConversationEvent>|Promise}
                */
            getConversation(uuid: string): Promise<Messaging.EventHandlers.GetConversationEvent>;
            /**
                * Get the multiple conversations by an array of UUIDs. Maximum 30 conversation.
                * Triggers multiple [MessengerEvents.GetConversation] events.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetConversation] event and provide a handler consuming an object with the [EventHandlers.GetConversationEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * Rejects to a [Messaging.MessengerError] if the requested conversations are not public (see [Conversation.publicJoin]) or the current user isn't/wasn't a participant any requested non-public conversation.
                * @see [MessengerEvents.GetConversation]
                * @see [MessengerEvents.Error]
                * @param conversations Array of conversation UUIDs. Maximum 30 conversations.
                * @returns {Promise<Array<Messaging.EventHandlers.GetConversationEvent>>|Promise}
                */
            getConversations(conversations: Array<string>): Promise<Array<Messaging.EventHandlers.GetConversationEvent>>;
            /**
                * Get UUIDs of all public conversations (see [Conversation.publicJoin]) created by the current user, other users of the same child account or any user of the main Voximplant developer account.
                * Triggers  [MessengerEvents.GetPublicConversations] events.
                * To get te result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetPublicConversations] event and provide a handler consuming an object with the [EventHandlers.GetPublicConversationsEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * @returns {Promise<EventHandlers.GetPublicConversationsEvent>|Promise}
                */
            getPublicConversations(): Promise<Messaging.EventHandlers.GetPublicConversationsEvent>;
            /**
                * @hidden
                */
            getRawConversations(conversations: Array<string>): Promise<Messaging.EventHandlers.GetConversationEvent[]>;
            /**
                * Create a new conversation.
                * The creator of any conversation by default:
                * - is an owner (see [ConversationParticipant.isOwner])
                * - can write messages
                * - can edit and remove own and other participants' messages
                * - can manage conversation participants
                * Triggers either the [MessengerEvents.CreateConversation] event on for all parties of the conversation (online participants and logged in clients) which are in 'participants' array.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.CreateConversation] event and provide a handler consuming an object with the [EventHandlers.CreateConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.CreateConversation] may be triggered by another user , so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.CreateConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if
                * - at least one user in array of participants does not exist or is not a user of the main Voximplant developer account or its child accounts,
                * - the specified parameters are contradicting (e.g. 'direct' and 'publicJoin' are both true).
                * @see MessengerEvents.CreateConversation
                * @see MessengerEvents.Error
                * @param participants Array of participants alongside with access rights params. If all flags are set to false or undefined, [ConversationParticipant.canWrite], [ConversationParticipant.canEdit] and [ConversationParticipant.canRemove] are set to true by default.
                * @param title Conversation title
                * @param direct True if the conversation is between two users only. A direct conversation cannot be public or uber. See [Conversation.direct].
                * @param enablePublicJoin True if any user can join the conversation by its uuid. See [Conversation.publicJoin].
                * @param uberConversation True if the conversation restricts access to messages. See [Conversation.uberConversation].
                * @param customData JavaScript object with custom data, up to 5Kb.
                * @returns {Promise<EventHandlers.CreateConversationEvent>|Promise}
                */
            createConversation(participants: Array<ConversationParticipant>, title?: string, direct?: boolean, publicJoin?: boolean, uber?: boolean, customData?: object): Promise<Messaging.EventHandlers.CreateConversationEvent>;
            /**
                * Restore the conversation from cache that was previously serialized by the [Conversation.toCache] method.
                * @param cachedConversation A JavaScript object for a serialized conversation
                * @returns {Conversation}
                */
            createConversationFromCache(cachedConversation: SerializedConversation): Conversation;
            /**
                * Add the current user to the conversation specified by the UUID.
                * Triggers the [MessengerEvents.EditConversation] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if
                * - the conversation was created not by a user of the main Voximplant developer account or its child accounts,
                * - public join is disabled for the conversation (see [Conversation.publicJoin]),
                * - the conversation is direct (see [Conversation.direct]).
                * @see [MessengerEvents.EditConversation]
                * @see [MessengerEvents.Error]
                * @param uuid Universally Unique Identifier of the conversation
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            joinConversation(uuid: string): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Remove the current user from the conversation specified by the UUID.
                * Triggers the [MessengerEvents.EditConversation] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the conversation is direct (see [Conversation.direct]).
                * @see [MessengerEvents.EditConversation]
                * @see [MessengerEvents.Error]
                * @param uuid  Universally Unique Identifier of the conversation
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            leaveConversation(uuid: string): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Get the Voximplant user identifier for the current user (e.g. 'username@appname.accname').
                * @returns {string} Voximplant user identifier for the current user, or null if the client is not logged in
                */
            getMe(): string;
            /**
                * Get the Messaging user id for the current user.
                * Triggers the [MessengerEvents.GetUser] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetUser] event and provide a handler consuming an object with the [EventHandlers.GetUserEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * @returns {Promise<number>|Promise} Messaging user id
                */
            getMyId(): Promise<number>;
            /**
                * Get [User] information for the user specified by the Voximplant user name (e.g. 'username@appname.accname').
                * It's possible to get any user of the main Voximplant developer account or its child accounts.
                * Triggers the [MessengerEvents.GetUser] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetUser] event and provide a handler consuming an object with the [EventHandlers.GetUserEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * @param user_name User name
                * @returns {Promise<EventHandlers.GetUserEvent>|Promise}
                */
            getUser(userName: string): Promise<Messaging.EventHandlers.GetUserEvent>;
            /**
                * Get [User] information for the user specified by the Messaging user id.
                * It's possible to get any user of the main Voximplant developer account or its child accounts.
                * Triggers the [MessengerEvents.GetUser] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetUser] event and provide a handler consuming an object with the [EventHandlers.GetUserEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * @param userId Messaging user id
                * @returns {Promise<EventHandlers.GetUserEvent>|Promise}
                */
            getUserById(userId: number): Promise<Messaging.EventHandlers.GetUserEvent>;
            /**
                * Get [User] information for the users specified by an array of the Voximplant user names (e.g. 'username@appname.accname'). Maximum 50 users.
                * It's possible to get any users of the main Voximplant developer account or its child accounts.
                * Triggers multiple [MessengerEvents.GetUser] events.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetUser] event and provide a handler consuming an object with the [EventHandlers.GetUserEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * @param users Array of the Voximplant user names (e.g. 'username@appname.accname'). Maximum 50 users.
                * @returns {Promise<Array<Messaging.EventHandlers.GetUserEvent>>|Promise}
                */
            getUsers(users: Array<string>): Promise<Array<Messaging.EventHandlers.GetUserEvent>>;
            /**
                * Get [User] information for the users specified by an array of Messaging user ids. Maximum 50 users.
                * It's possible to get any users of the main Voximplant developer account or its child accounts.
                * Triggers multiple [MessengerEvents.GetUser] events.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetUser] event and provide a handler consuming an object with the [EventHandlers.GetUserEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * @param users Array of Messaging user ids. Maximum 50 users.
                * @returns {Promise<Array<Messaging.EventHandlers.GetUserEvent>>|Promise}
                */
            getUsersById(userIds: Array<number>): Promise<Array<Messaging.EventHandlers.GetUserEvent>>;
            /**
                * Edit the current user information.
                * Triggers the [MessengerEvents.EditUser] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditUser] event and provide a handler consuming an object with the [EventHandlers.EditUserEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditUser] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditUser] event to handle events from other parties.
                * @param customData Public custom data available to any user. If null or undefined, previously set custom data will not be changed. If an empty object, previously set custom data will be removed.
                * @param privateCustomData Private custom data available only to the current user. If null or undefined, previously set custom data will not be changed. If an empty object, previously set custom data will be removed.
                * @returns {Promise<EventHandlers.EditUserEvent>|Promise}
                */
            editUser(customData?: Object, privateCustomData?: Object): Promise<Messaging.EventHandlers.EditUserEvent>;
            /**
                * Set the current user presence status.
                * Triggers the [MessengerEvents.SetStatus] event for all parties of the conversation (online participants and logged in clients) which are subscribed on this user.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.SetStatus] event and provide a handler consuming an object with the [EventHandlers.SetStatusEvent] interface as a parameter.
                * Remember that [MessengerEvents.SetStatus] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.SetStatus] event to handle events from other parties.
                * @param online True if the user is available for messaging.
                * @returns {Promise<EventHandlers.SetStatusEvent>|Promise}
                */
            setStatus(online: boolean): Promise<Messaging.EventHandlers.SetStatusEvent>;
            /**
                * Subscribe for other user(s) information and status changes.
                * It's possible to subscribe for any user of the main Voximplant developer account or its child accounts.
                * Triggers the [MessengerEvents.Subscribe] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.Subscribe] event and provide a handler consuming an object with the [EventHandlers.SubscribeEvent] interface as a parameter.
                * Remember that [MessengerEvents.Subscribe] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.Subscribe] event to handle events from other parties.
                * @param users Array of Messaging user ids.
                * @returns {Promise<EventHandlers.SubscribeEvent>|Promise}
                */
            subscribe(users: Array<number>): Promise<Messaging.EventHandlers.SubscribeEvent>;
            /**
                * Unsubscribe from other user(s) information and status changes.
                * Triggers the [MessengerEvents.Unsubscribe] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.Unsubscribe] event and provide a handler consuming an object with the [EventHandlers.UnsubscribeEvent] interface as a parameter.
                * Remember that [MessengerEvents.Subscribe] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.Unsubscribe] event to handle events from other parties.
                * @param users Array of Messaging user ids.
                * @param all If true, an array of user ids is ignored and the current user is unsubscribed from all the conversation users.
                * @returns {Promise<EventHandlers.UnsubscribeEvent>|Promise}
                */
            unsubscribe(users: Array<number>, all?: boolean): Promise<Messaging.EventHandlers.UnsubscribeEvent>;
            /**
                * Get the list of users the current user is subscribed to.
                * Triggers the [MessengerEvents.GetSubscriptionList] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.GetSubscriptionList] event and provide a handler consuming an object with the [EventHandlers.GetSubscriptionListEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * @returns {Promise<EventHandlers.GetSubscriptionListEvent>|Promise}
                */
            getSubscriptionList(): Promise<Messaging.EventHandlers.GetSubscriptionListEvent>;
            /**
                * Manage push notifications on Messenger events for the current user.
                * Only subscriptions to the [MessengerEvents.CreateConversation], [MessengerEvents.SendMessage] and [MessengerEvents.EditMessage] events are available.
                * \nNote that you need to set up push notifications to use this method.
                * You'll find all the setup steps in our [Push Notifications tutorial](https://voximplant.com/docs/references/websdk/push-notifications).
                * Triggers the [MessengerEvents.EditConversation] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * @returns {Promise<EventHandlers.ManageNotifications>|Promise}
                */
            manageNotification(notifications: Array<Messaging.MessengerEvents>): Promise<Messaging.EventHandlers.EditUserEvent>;
            /**
                * Restore a [Message] from its serialisation previously created by the [Message.toCache] method.
                * @param cachedMessage A JavaScript object for a serialized message
                * @returns {Message}
                */
            createMessageFromCache(cachedMessage: SerializedMessage): Message;
            /**
                * @hidden
                */
            reject(errorCode: Messaging.MessengerError, action: Messaging.MessengerAction): Promise<Messaging.EventHandlers.ErrorEvent>;
            /**
                * @hidden
                */
            msgEventToMessengerEvent(e: MsgEvent): Messaging.MessengerEvents;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Messaging/src/Conversation' {
    import { MsgInput, MsgOutput, SerializedConversation, ConversationParticipant } from "voximplant-websdk/Messaging/src/Structures";
    import Messaging from 'voximplant-websdk/Messaging';
    /**
        * @hidden
        */
    export class Conversation {
            /**
                * The universally unique identifier (UUID) of the conversation.
                * @returns {string}
                */
            readonly uuid: string;
            /**
             * The conversation title.
             * Note that setting this property does not send changes to the server. Use the [Conversation.update] method to send all the changes at once or [Conversation.setTitle] to update only the title.
             * @param value
             */
            title: string;
            /**
                * UNIX timestamp (seconds) that specifies the time the conversation was created.
                */
            readonly createdAt: number;
            /**
                * UNIX timestamp (seconds) that specifies the time of the last event in the conversation.
                */
            readonly lastUpdate: any;
            /**
                * A direct conversation includes only 2 participants. There can't be more than 1 direct conversation between the same 2 users.
                * If one of these users tries to create a new direct conversation with the same participant via [Messenger.createConversation], the method will return the existing direct conversation.
                * A direct conversation can't be uber and/or public.
                */
            readonly direct: boolean;
            /**
                * Users in a uber conversation are not able to retrieve messages that were posted to the conversation after they quit or before they joined.
                * A uber conversation can't be direct.
                */
            readonly uberConversation: boolean;
            /**
             * If true, anyone can join the conversation by UUID.
             * A public conversation can't be direct.
             * Note that setting this property does not send changes to the cloud. Use the [Conversation.update] method to send all changes at once or [Conversation.setPublicJoin] to update only the public join property.
             * @param value
             */
            publicJoin: boolean;
            /**
                * The list of conversation participants alongside with their rights.
                * The default permissions for all participants are: write / edit / remove their own messages (see [ConversationParticipant.canWrite], [ConversationParticipant.canEdit] and [ConversationParticipant.canRemove]).
                * The creator of the conversation is an owner by default.
                * An owner of the conversation (see [ConversationParticipant.isOwner]):
                * - can write messages
                * - can edit and remove own and other participants' messages
                * - can manage conversation participants
                */
            readonly participants: Array<ConversationParticipant>;
            /**
             * Any JavaScript structure with custom data, up to 5Kb.
             * Note that setting this property does not send changes to the cloud.
             * Use the [Conversation.update] method to send all changes at once or [Conversation.setCustomData] to update just the custom data.
             * @param value
             */
            customData: any;
            /**
                * The sequence of the last event in the conversation.
                */
            readonly lastSeq: any;
            /**
                * @hidden
                */
            constructor(data: {
                    participants: Array<ConversationParticipant>;
            } & Partial<SerializedConversation>);
            /**
                * @hidden
                * @param newSeq
                */
            updateSeq(newSeq: number): void;
            /**
                * Create conversation from buss
                * @param busConversation
                * @returns {Conversation}
                * @hidden
                */
            static _createFromBus(busConversation: MsgOutput.Conversation, seq: number): Conversation;
            /**
                * Restore conversation from cache
                * @param cacheConversation
                * @returns {Conversation}
                * @hidden
                */
            static createFromCache(cacheConversation: SerializedConversation): Conversation;
            /**
                * Serialize the conversation so it can be stored (e.g. in IndexedDB) and restored later via the [Messenger.createConversationFromCache] method.
                * @returns {SerializedConversation}
                */
            toCache(): SerializedConversation;
            /**
                * @hidden
                */
            _getCreatePayload(): MsgInput.CreateConversation;
            /**
                *
                * @hidden
                */
            _getEditPayload(): MsgInput.EditConversation;
            /**
                * @hidden
                * Revert changes if [Conversation.update], [Conversation.setTitle], [Conversation.setPublicJoin] or [Conversation.setCustomData] fails.
                */
            _revertChanges(): void;
            /**
                * Send changes made via modifying conversation properties ([Conversation.title], [Conversation.publicJoin] and [Conversation.customData]) to the cloud.
                * Triggers the [MessengerEvents.EditConversation] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the current user is not an owner of the conversation (see [ConversationParticipant.isOwner])
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            update(): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Set a new title for the current conversation.
                * Triggers the [MessengerEvents.EditConversation] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the current user is not an owner of the conversation (see [ConversationParticipant.isOwner])
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            setTitle(title: string): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Set the public join flag and send changes to the server.
                * Triggers the [MessengerEvents.EditConversation] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the current user is not an owner of the conversation (see [ConversationParticipant.isOwner])
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            setPublicJoin(publicJoin: boolean): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Set new custom data for the conversation.
                * Triggers the [MessengerEvents.EditConversation] event.
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the current user is not an owner of the conversation (see [ConversationParticipant.isOwner])
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            setCustomData(customData: any): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Add new participants to the conversation. Duplicated users are ignored.
                * Triggers the [MessengerEvents.EditConversation] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if
                * - at least one user does not exist or already belongs to the conversation,
                * - at least one participant is not a user of the main Voximplant developer account or its child accounts,
                * - the current user cannot manage other participants (see [ConversationParticipant.canManageParticipants] and [ConversationParticipant.isOwner]),
                * - the conversation is direct (see [Conversation.direct]).
                * @param participants
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            addParticipants(participants: Array<ConversationParticipant>): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Change permissions for conversation participants. Duplicated users are ignored.
                * This method doesn't add or remove participants. Use the [Conversation.addParticipants] and [Conversation.removeParticipants] methods instead.
                * Triggers the [MessengerEvents.EditConversation] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the current user cannot manage other participants (see [ConversationParticipant.canManageParticipants]).
                * @param participants
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            editParticipants(participants: Array<ConversationParticipant>): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Remove participants from the conversation. Duplicated users are ignored.
                * Will fail if any user does not exist.
                * Triggers the [MessengerEvents.EditConversation] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditConversation] event and provide a handler consuming an object with the [EventHandlers.EditConversationEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditConversation] may be triggered by another user and as a result of a number of other methods. So check 'messengerAction' and 'initiator' fields.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditConversation] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if:
                * - the current user cannot manage other participants (see [ConversationParticipant.canManageParticipants]),
                * - the conversation is direct (see [Conversation.direct]),
                * - at least one user does not exist or already removed to the conversation,
                * @param participants
                * @returns {Promise<EventHandlers.EditConversationEvent>|Promise}
                */
            removeParticipants(participants: Array<ConversationParticipant>): Promise<Messaging.EventHandlers.EditConversationEvent>;
            /**
                * Send a message to the conversation.
                * Triggers the [MessengerEvents.SendMessage] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.SendMessage] event and provide a handler consuming an object with the [EventHandlers.SendMessageEvent] interface as a parameter.
                * Remember that [MessengerEvents.SendMessage] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.SendMessage] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the current user doesn't have write permissions see [ConversationParticipant.canWrite] and [ConversationParticipant.isOwner]).
                * @param test Message text, maximum 5000 characters
                * @param payload Custom payload; can be an array of any objects, but not primitive types
                * @returns {Promise<EventHandlers.SendMessageEvent>|Promise}
                */
            sendMessage(text: string, payload?: Array<Object>): Promise<Messaging.EventHandlers.SendMessageEvent>;
            /**
                * Inform the cloud that the user is typing some text.
                * The minimum interval between the two method calls must be 10 seconds.
                * Triggers the [MessengerEvents.Typing] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.Typing] event and provide a handler consuming an object with the [EventHandlers.TypingEvent] interface as a parameter.
                * Remember that [MessengerEvents.Typing] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.Typing] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if the method is called within 10s since the last call.
                * Calls within 10s interval from the last call are discarded.
                * @returns {Promise<EventHandlers.TypingEvent | false>|Promise} Resolves to [EventHandlers.TypingEvent] if notification was actually sent to the server the server, 'false' if it was discarded.
                */
            typing(): Promise<Messaging.EventHandlers.TypingEvent | false>;
            /**
                * Mark the event which has the specified sequence as read.
                * This affects the current participant's [ConversationParticipant.lastRead] property and can be used to display unread messages.
                * Triggers the [MessengerEvents.Read] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.Read] event and provide a handler consuming an object with the [EventHandlers.ReadEvent] interface as a parameter.
                * Remember that [MessengerEvents.Read] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.Read] event to handle events from other parties.
                * @param seq
                * @returns {Promise<EventHandlers.ReadEvent>|Promise}
                */
            markAsRead(seq: number): Promise<Messaging.EventHandlers.ReadEvent>;
            /**
                * Request events in the specified sequence range to be sent from the cloud to this client.
                * Only [MessengerEvents.CreateConversation], [MessengerEvents.EditConversation], [MessengerEvents.SendMessage] and [MessengerEvents.EditMessage] events can be retransmitted; any other events cannot.
                * The method is used to get history or missed events in case of network disconnect.
                * Client should use this method to request all events based on the last conversation event sequence received from the cloud and last event sequence saved locally (if any).
                * If the current user quits an uber conversation (see [Conversation.uberConversation]), messages that are posted during the user's absence will not be retransmitted later.
                * The maximum amount for requested events per method call is 100.
                * Triggers multiple [MessengerEvents.RetransmitEvents] events (for each retransmitted event).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.RetransmitEvents] event and provide a handler consuming an object with the [EventHandlers.RetransmitEventsEvent] interface as a parameter.
                * - Handle the returned promise (recommended).
                * Rejects to a [Messaging.MessengerError] if  more than 100 events are requested.
                * @param eventsFrom First event in sequence range, inclusive
                * @param eventsTo Last event in sequence range, inclusive
                * @returns {Promise<EventHandlers.RetransmitEventsEvent>|Promise}
                */
            retransmitEvents(eventsFrom: number, eventsTo: number, count?: number): Promise<Messaging.EventHandlers.RetransmitEventsEvent>;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Messaging/src/Message' {
    import { Conversation } from "voximplant-websdk/Messaging/src/Conversation";
    import { MsgInput, MsgOutput, SerializedMessage } from 'voximplant-websdk/Messaging/src/Structures';
    import Messaging from 'voximplant-websdk/Messaging';
    /**
        * @hidden
        */
    export class Message {
            /**
                * The universally unique identifier (UUID) of the message. Can be used on client side for housekeeping.
                * @returns {string}
                */
            readonly uuid: string;
            /**
                * The UUID of the conversation this message belongs to.
                */
            readonly conversation: string;
            /**
             * Setting this property does not send changes to the cloud.
             * Use the [Message.update] method to send all the changes at once.
             * @param value {string}
             */
            text: string;
            /**
             * Setting this property does not send changes to the cloud.
             * Use the [Message.update] method to send all the changes at once.
             * @param value {Array<object>}
             */
            payload: Array<Object>;
            /**
                * The id of the user who sent this message (see [ConversationParticipant.userId]).
                */
            readonly sender: number;
            /**
                * @hidden
                * @param {string} message
                * @param {Array<object>} payload
                */
            constructor(message: string, payload: Array<Object>);
            /**
                * @hidden
                * @param busMessage
                * @param seq
                */
            static _createFromBus(busMessage: MsgOutput.Message, sender: number): Message;
            /**
                * @hidden
                * @param cacheMessage
                * @returns {Message}
                */
            static createFromCache(cacheMessage: SerializedMessage): Message;
            /**
                * Serialize the message so it can be stored (e.g. in IndexedDB) and later restored via the [Messenger2.createMessageFromCache] method
                */
            toCache(): SerializedMessage;
            /**
                * @hidden
                * @returns {{text: string, conversation: string, payload?: object[]}}
                */
            getPayload(): MsgInput.SendMessage;
            /**
                * @hidden
                * @param conversation
                * @returns {Promise<EventHandlers.SendMessageEvent>|Promise}
                */
            sendTo(conversation: Conversation): Promise<Messaging.EventHandlers.SendMessageEvent>;
            /**
                * Send text and payload changes to the cloud.
                * Triggers the [MessengerEvents.EditMessage] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.EditMessage] event and provide a handler consuming an object with the [EventHandlers.EditMessageEvent] interface as a parameter.
                * Remember that [MessengerEvents.EditMessage] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.EditMessage] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if
                * - the current user cannot edit own messages (see [ConversationParticipant.canEdit] and [ConversationParticipant.isOwner]),
                * - the current user cannot edit other partisipants' messages (see [ConversationParticipant.canEditAll] and [ConversationParticipant.isOwner]).
                * @returns {Promise<EventHandlers.EditMessageEvent>|Promise}
                */
            update(): Promise<Messaging.EventHandlers.EditMessageEvent>;
            /**
                * Remove the message from the conversation.
                * Triggers the [MessengerEvents.RemoveMessage] event for all parties of the conversation (online participants and logged in clients).
                * To get the result, use one of these options:
                * - Subscribe to the [MessengerEvents.RemoveMessage] event and provide a handler consuming an object with the [EventHandlers.RemoveMessageEvent] interface as a parameter.
                * Remember that [MessengerEvents.RemoveMessage] may be triggered by another user, so check the 'initiator' field.
                * - Handle the returned promise. Though you still need to listen to [MessengerEvents.RemoveMessage] event to handle events from other parties.
                * Rejects to a [Messaging.MessengerError] if
                * - the current user cannot remove own messages (see [ConversationParticipant.canRemove] and [ConversationParticipant.isOwner]),
                * - the current user cannot remove other partisipants' messages (see [ConversationParticipant.canRemoveAll] and [ConversationParticipant.isOwner]).
                * @returns {Promise<EventHandlers.RemoveMessageEvent>|Promise}
                */
            remove(): Promise<Messaging.EventHandlers.RemoveMessageEvent>;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Messaging/src/Structures' {
    import { MsgEvent } from "voximplant-websdk/Signaling/MsgEvent";
    import Messaging from "voximplant-websdk/Messaging";
    import { MsgAction } from "voximplant-websdk/Signaling/MsgAction";
    /**
        * IM gen 2
        * @hidden
        */
    export interface MsgActionToEvent {
            [MsgEvent.onError]: MsgAction;
            [MsgEvent.onCreateConversation]: MsgAction.createConversation;
            [MsgEvent.onEditConversation]: MsgAction.editConversation | MsgAction.joinConversation | MsgAction.leaveConversation | MsgAction.addParticipants | MsgAction.editParticipants | MsgAction.removeParticipants;
            [MsgEvent.onRemoveConversation]: MsgAction.removeConversation | MsgAction.removeEmptyConversation;
            [MsgEvent.onGetConversation]: MsgAction.getConversation | MsgAction.getConversations | MsgAction.searchConversations;
            [MsgEvent.onGetPublicConversations]: MsgAction.getPublicConversations;
            [MsgEvent.onGetUser]: MsgAction.getUser | MsgAction.getUsers;
            [MsgEvent.onEditUser]: MsgAction.editUser;
            [MsgEvent.onSetStatus]: MsgAction.setStatus;
            [MsgEvent.onSendMessage]: MsgAction.sendMessage;
            [MsgEvent.onEditMessage]: MsgAction.editMessage;
            [MsgEvent.onRemoveMessage]: MsgAction.removeMessage;
            [MsgEvent.isRead]: MsgAction.isRead;
            [MsgEvent.onTyping]: MsgAction.typingMessage;
            [MsgEvent.onSubscribe]: MsgAction.subscribe;
            [MsgEvent.onUnsubscribe]: MsgAction.unsubscribe;
            [MsgEvent.onGetSubscriptionList]: MsgAction.getSubscriptionList;
            [MsgEvent.onCreateBot]: MsgAction.createBot;
            [MsgEvent.onRemoveBot]: MsgAction.removeBot;
            [MsgEvent.onRetransmitEvents]: MsgAction.retransmitEvents;
    }
    /**
        * @hidden
        */
    export enum MsgService {
            Chat
    }
    /**
        * @hidden
        */
    export interface MsgInputMessage<E extends keyof MsgInputData | MsgAction> {
            service: MsgService;
            event: E;
            payload: MsgInPayload<E>;
            /**
                * Username.
                */
            from?: string;
            connid?: string;
            request_uuid: string;
    }
    /**
        * @hidden
        */
    export interface MsgOutputMessage<E extends MsgEvent> {
            service: MsgService;
            event: E;
            payload: MsgOutPayload<MsgActionToEvent[E]> | MsgErrorPayload;
            /**
                * Current user id
                */
            to: string;
            /**
                * All receiving user ids
                */
            toId: string[];
            connid: string;
            request_uuid: string;
            version: string;
    }
    /**
        * @hidden
        */
    export type MsgInPayload<E extends keyof MsgInputData> = MsgInputData[E] & {
            '@type': string;
    };
    /**
        * Payload received from IM API
        * @hidden
        */
    export interface MsgOutPayload<E extends MsgAction> {
            '@type': string;
            /**
                * Action author id.
                */
            initiator: number;
            on_incoming_event: E;
            object: MsgOutputData[E];
            /**
                * Only for conversation objects.
                */
            seq?: number;
            /**
                * Server's timestamp when then event was processing.
                */
            timestamp?: number;
            /**
                * Retransmit only.
                */
            from_seq?: number;
            /**
                * Retransmit only.
                */
            to_seq?: number;
            /**
                * Retransmit only.
                */
            count?: number;
    }
    /**
        * Error payload received from IM API
        * @hidden
        */
    export interface MsgErrorPayload {
            '@type': string;
            /**
                * Action author id.
                */
            initiator: number;
            on_incoming_event: MsgAction;
            code: number;
            description: string;
            timestamp?: number;
    }
    /**
        * Namespace for for IM API both request or response events.
        * @hidden
        */
    export namespace MsgInOutput {
            interface PresenceMessage {
                    /**
                        * True if the user is online. Can be set by the [Messenger.setStatus] method.
                        */
                    online: boolean;
            }
            interface TypingMessage {
                    conversation: string;
            }
            interface StatusMessage {
                    conversation: string;
                    seq: number;
                    status?: string;
            }
            /**
                * Use to subscribe and unsubscribe.
                */
            interface ManageSubscribes {
                    user_id?: number[];
                    /**
                        * Only to unsubscribe.
                        */
                    all?: boolean;
            }
    }
    /**
        * Namespace for IM API request events.
        * @hidden
        */
    export namespace MsgInput {
            interface EditConversation {
                    uuid: string;
                    /**
                        * Title of conversation.
                        */
                    title: string;
                    /**
                        * Default is false.
                        */
                    enable_public_join?: boolean;
                    /**
                        * Any JSON object.
                        */
                    custom_data?: object;
            }
            interface CreateConversation {
                    /**
                        * Title of conversation.
                        */
                    title: string;
                    /**
                        * Default is false.
                        */
                    direct?: boolean;
                    /**
                        * Default is false.
                        */
                    enable_public_join?: boolean;
                    /**
                        * Default is false.
                        */
                    uber_conversation?: boolean;
                    /**
                        * Any JSON object.
                        */
                    custom_data?: object;
                    participants: MsgParticipant[];
            }
            interface RemoveConversation {
                    uuid: string;
            }
            interface JoinConversation {
                    uuid: string;
            }
            interface LeaveConversation {
                    uuid: string;
            }
            /**
                * Use to add or edit participants.
                */
            interface ManageParticipants {
                    uuid: string;
                    participants: MsgParticipant[];
            }
            /**
                * Use to remove participants.
                */
            interface RemoveParticipants {
                    uuid: string;
                    /**
                        * Array of [Messaging.MsgParticipant.user_id].
                        */
                    participants: number[];
            }
            interface GetConversation {
                    uuid: string;
            }
            interface GetConversations {
                    /**
                        * Array of conversation uuids.
                        */
                    uuid: string[];
            }
            interface GetPublicConversations {
            }
            interface SearchConversations {
                    uuid?: string[];
                    title?: string[];
                    enable_public_join?: boolean;
                    count?: number;
                    offset?: number;
            }
            interface SendMessage {
                    /**
                        * Conversation uuid.
                        */
                    conversation: string;
                    /**
                        * Message text.
                        */
                    text?: string;
                    /**
                        * Message payload.
                        */
                    payload?: object[];
            }
            interface EditMessage {
                    /**
                        * Message uuid.
                        */
                    uuid: string;
                    /**
                        * Conversation uuid.
                        */
                    conversation: string;
                    /**
                        * Message text.
                        */
                    text?: string;
                    /**
                        * Message payload.
                        */
                    payload?: object[];
            }
            interface RemoveMessage {
                    /**
                        * Message uuid.
                        */
                    uuid: string;
                    /**
                        * Conversation uuid.
                        */
                    conversation: string;
            }
            interface RetransmitRequest {
                    conversation: string;
                    events_from: number;
                    events_to: number;
                    count?: number;
            }
            interface GetUser {
                    user_id?: number;
                    user_name?: string;
            }
            interface GetUsers {
                    users: Partial<MsgUserInfo>[];
            }
            interface EditUser {
                    /**
                        * Visible only for your and parent accounts.
                        */
                    custom_data?: object;
                    /**
                        * Visible only for the user.
                        */
                    private_custom_data?: object;
            }
            interface CreateBot {
                    user_name: string;
                    /**
                        * Visible only for your and parent accounts.
                        */
                    custom_data?: object;
            }
            interface RemoveBot {
                    user_id: number;
            }
            interface ManageNotifications {
                    notifications: MsgEvent[];
            }
            interface GetSubscriptionList {
            }
    }
    /**
        * Namespace for IM API response events.
        * @hidden
        */
    export namespace MsgOutput {
            interface Conversation {
                    uuid: string;
                    /**
                        * Title of conversation.
                        */
                    title: string;
                    participants: MsgParticipant[];
                    /**
                        * Default is false.
                        */
                    direct?: boolean;
                    /**
                        * Default is false.
                        */
                    enable_public_join?: boolean;
                    /**
                        * Default is false.
                        */
                    uber_conversation?: boolean;
                    /**
                        * Any JSON object.
                        */
                    custom_data?: object;
                    /**
                        * Only in response.
                        */
                    created_at?: number;
                    /**
                        * Only in response.
                        */
                    last_update?: number;
            }
            interface PublicConversations {
                    /**
                        * Array of conversation uuids.
                        */
                    uuid: string[];
            }
            interface Message {
                    /**
                        * Message uuid.
                        */
                    uuid: string;
                    /**
                        * Conversation uuid.
                        */
                    conversation: string;
                    /**
                        * Message text.
                        */
                    text?: string;
                    /**
                        * Message payload.
                        */
                    payload?: object[];
            }
            interface UserData {
                    user_id: number;
                    user_name: string;
                    display_name: string;
                    /**
                        * Visible only for your and parent accounts.
                        */
                    custom_data?: object;
                    /**
                        * Visible only for the user.
                        */
                    private_custom_data?: object;
                    /**
                        * Visible only for the user.
                        */
                    notification_events?: MsgEvent[];
                    /**
                        * Visible only for the user.
                        */
                    conversations_list?: string[];
                    /**
                        * Visible only for the user.
                        */
                    leave_conversations?: string[];
                    deleted: boolean;
            }
            interface UserSubscriptions {
                    /**
                        * Array of Messaging user ids the user is subscribed to.
                        */
                    subscriptions: Array<number>;
            }
    }
    /**
        * @hidden
        */
    export interface MsgUserInfo {
            user_id: number;
            user_name: string;
    }
    /**
        * @hidden
        */
    export enum MsgPermissions {
            none = 0,
            can_write = 1,
            can_edit = 2,
            can_remove = 4,
            can_manage_participants = 8,
            can_edit_all = 16,
            can_remove_all = 32,
            is_owner = 32768,
            all = 65535
    }
    /**
        * @hidden
        */
    export interface MsgParticipant {
            user_id: number;
            flags: number;
            /**
                * Only in response.
                */
            last_read?: number;
    }
    /**
        * @hidden
        */
    export interface MsgInputData {
            /**
                * @hidden
                */
            UNKNOWN: any;
            createConversation: MsgInput.CreateConversation;
            editConversation: MsgInput.EditConversation;
            removeConversation: MsgInput.RemoveConversation;
            addParticipants: MsgInput.ManageParticipants;
            editParticipants: MsgInput.ManageParticipants;
            removeParticipants: MsgInput.RemoveParticipants;
            leaveConversation: MsgInput.LeaveConversation;
            joinConversation: MsgInput.JoinConversation;
            getConversation: MsgInput.GetConversation;
            getConversations: MsgInput.GetConversations;
            getPublicConversations: MsgInput.GetPublicConversations;
            /**
                * @hidden
                */
            searchConversations: MsgInput.SearchConversations;
            /**
                * @hidden
                */
            removeEmptyConversation: MsgInput.RemoveConversation;
            sendMessage: MsgInput.SendMessage;
            editMessage: MsgInput.EditMessage;
            removeMessage: MsgInput.RemoveMessage;
            retransmitEvents: MsgInput.RetransmitRequest;
            getUser: MsgInput.GetUser;
            getUsers: MsgInput.GetUsers;
            editUser: MsgInput.EditUser;
            manageNotification: MsgInput.ManageNotifications;
            subscribe: MsgInOutput.ManageSubscribes;
            unsubscribe: MsgInOutput.ManageSubscribes;
            getSubscriptionList: MsgInput.GetSubscriptionList;
            typingMessage: MsgInOutput.TypingMessage;
            isRead: MsgInOutput.StatusMessage;
            setStatus: MsgInOutput.PresenceMessage;
            /**
                * @hidden
                */
            createBot: MsgInput.CreateBot;
            /**
                * @hidden
                */
            removeBot: MsgInput.RemoveBot;
    }
    /**
        * @hidden
        */
    export interface MsgOutputData {
            /**
                * @hidden
                */
            UNKNOWN: any;
            createConversation: MsgOutput.Conversation;
            editConversation: MsgOutput.Conversation;
            removeConversation: MsgOutput.Conversation;
            joinConversation: MsgOutput.Conversation;
            leaveConversation: MsgOutput.Conversation;
            getConversation: MsgOutput.Conversation;
            getConversations: MsgOutput.Conversation[];
            getPublicConversations: MsgOutput.PublicConversations;
            /**
                * @hidden
                */
            searchConversations: MsgOutput.Conversation;
            /**
                * @hidden
                */
            removeEmptyConversation: MsgOutput.Conversation;
            addParticipants: MsgOutput.Conversation;
            editParticipants: MsgOutput.Conversation;
            removeParticipants: MsgOutput.Conversation;
            getUser: MsgOutput.UserData;
            getUsers: MsgOutput.UserData;
            editUser: MsgOutput.UserData;
            setStatus: MsgInOutput.PresenceMessage;
            sendMessage: MsgOutput.Message;
            editMessage: MsgOutput.Message;
            /**
                * Returns [Messaging.MsgOutput.Message] with uuid and conversation only
                */
            removeMessage: MsgOutput.Message;
            typingMessage: MsgInOutput.TypingMessage;
            isRead: MsgInOutput.StatusMessage;
            subscribe: MsgInOutput.ManageSubscribes;
            unsubscribe: MsgInOutput.ManageSubscribes;
            manageNotification: MsgOutput.UserData;
            getSubscriptionList: MsgOutput.UserSubscriptions;
            /**
                * @hidden
                */
            createBot: MsgOutput.UserData;
            /**
                * @hidden
                */
            removeBot: {};
            retransmitEvents: MsgOutputMessage<MsgEvent>;
    }
    /**
        * @hidden
        * */
    export interface SerializedMessage {
            /**
                * See [Message.uuid].
                */
            uuid: string;
            /**
                * See [Message.text].
                */
            text: string;
            /**
                * See [Message.payload].
                */
            payload: Array<object>;
            /**
                * See [Message.conversation].
                */
            conversation: string;
            /**
                * See [Message.sender].
                */
            sender: number;
    }
    /**
        * @hidden
        */
    export interface SerializedConversation {
            /**
                * See [Conversation.uuid].
                */
            uuid: string;
            /**
                * See [Conversation.title].
                */
            title: string;
            /**
                * See [Conversation.createdAt].
                */
            createdAt: number;
            /**
                * See [Conversation.lastUpdate].
                */
            lastUpdate: number;
            /**
                * See [Conversation.direct].
                */
            direct: boolean;
            /**
                * See [Conversation.publicJoin].
                */
            publicJoin: boolean;
            /**
                * See [Conversation.uberConversation].
                */
            uberConversation: boolean;
            /**
                * See [Conversation.lastSeq].
                */
            lastSeq: number;
            /**
                * See [Conversation.participants].
                */
            participants: Array<ConversationParticipant>;
            /**
                * See [Conversation.customData].
                */
            customData: Object;
    }
    /**
        * @hidden
        */
    export interface ConversationParticipant {
            /**
                * Messaging user id.
                */
            userId: number;
            /**
                * True if a user is an owner of the conversation. There can be more than one owner in the conversation.
                * An owner can edit the conversation and has all other permissions.
                */
            isOwner?: boolean;
            /**
                * True if a user can write messages in the conversation. The permission is given by default.
                * Could be changed only by the user that has the [ConversationParticipant.canManageParticipants] or the [ConversationParticipant.isOwner] permission.
                */
            canWrite?: boolean;
            /**
                * True if a user can edit own messages in the conversation. The permission is given by default.
                * Could be changed only by the user that has the [ConversationParticipant.canManageParticipants] or the [ConversationParticipant.isOwner] permission.
                */
            canEdit?: boolean;
            /**
                * True if a user can remove own messages in the conversation. The permission is given by default.
                * Could be changed only by the user that has the [ConversationParticipant.canManageParticipants] or the [ConversationParticipant.isOwner] permission.
                */
            canRemove?: boolean;
            /**
                * True if a user can manage conversation participants: edit permissions and add/remove participants.
                * Could be changed only by the user that has the [ConversationParticipant.canManageParticipants] or the [ConversationParticipant.isOwner] permission.
                */
            canManageParticipants?: boolean;
            /**
                * True if a user can edit other users' messages in the conversation.
                * Could be changed only by the user that has the [ConversationParticipant.canManageParticipants] or the [ConversationParticipant.isOwner] permission.
                */
            canEditAll?: boolean;
            /**
                * True if a user can remove other users' messages in the conversation.
                * Could be changed only by the user that has the [ConversationParticipant.canManageParticipants] or the [ConversationParticipant.isOwner] permission.
                */
            canRemoveAll?: boolean;
            /**
                * The sequence of the message event that was marked as last read by this user in the conversation.
                * Participants mark events as read via [Conversation.markAsRead].
                * Is '0' if the participant hasn't marked any event as read.
                */
            lastRead?: number;
    }
    /**
        * @hidden
        */
    export interface User {
            /**
                * Messaging user id. It's used to identify users only within the Messaging module.
                */
            userId: number;
            /**
                * The Voximplant user identifier (e.g. 'username@appname.accname').
                */
            userName: string;
            /**
                * The user's display name specified in [Voximplant control panel](https://manage.voximplant.com) or via [HTTP API](https://voximplant.com/docs/references/httpapi).
                */
            displayName: string;
            /**
                * @hidden
                * True if the user was deleted.
                */
            deleted?: boolean;
            /**
                * Array of conversation UUIDs the current user belongs to.
                * Not available for all other users (undefined).
                */
            conversationsList: Array<string> | undefined;
            /**
                * @hidden
                * List of UUIDs for the conversations the user has left. Only available if user queries information about themselves.
                */
            leaveConversationList?: Array<string>;
            /**
                * Array of [MessengerEvents] the current user is subscribed to (when they occur, the user receives push notifications).
                * Not available for all other users (undefined).
                * The current user subscriptions can be set via the [Messenger.manageNotification] method.
                */
            notificationEvents: Array<Messaging.MessengerEvents> | undefined;
            /**
                * Public custom data available to all users. Can be set via [Messenger.editUser].
                */
            customData: Object;
            /**
                * Private custom data available only to the current user.
                * Undefined for all other users.
                */
            privateCustomData: Object | undefined;
    }
}

declare module 'voximplant-websdk/Call/EndpointListDescription' {
    /**
        * @hidden
        */
    export interface EndpointListDescription {
            endpoints: {
                    [id: string]: EndpointDescription;
            };
    }
    /**
        * @hidden
        */
    export interface EndpointDescription {
            place: number;
            type: 'call' | 'player';
            tracks: {
                    [id: string]: 'audio' | 'video' | 'sharing';
            };
    }
    /**
        * @hidden
        */
    export interface EndpointInfoData {
            id: string;
            place: number;
            username: string;
            displayName: string;
            sipURI: string;
    }
}

declare module 'voximplant-websdk/Types' {
    /**
        * @hidden
        */
    export enum BrowserMode {
            Firefox = 0,
            Chrome = 1
    }
    /**
        * @hidden
        */
    export enum TrackType {
            audio,
            video,
            sharing
    }
    /**
        * Call related errors.
        * @hidden
        */
    export enum CallError {
            /**
                * The call is already in requested state
                */
            ALREADY_IN_THIS_STATE = 0,
            /**
                * Requested functionality is disabled
                */
            FUNCTIONALITY_IS_DISABLED = 1,
            /**
                * Operation is incorrect, f.ex.
                */
            INCORRECT_OPERATION = 2,
            /**
                * Internal error occurred
                */
            INTERNAL_ERROR = 3,
            /**
                * Operation can't be performed due to the call is on hold.
                */
            MEDIA_IS_ON_HOLD = 4,
            /**
                * Operation is rejected
                */
            REJECTED = 5,
            /**
                * Operation is not completed in time
                */
            TIMEOUT = 6
    }
}

declare module 'voximplant-websdk/Hardware/src' {
    /**
        * @hidden
        */
    export { AudioDeviceManager } from 'voximplant-websdk/Hardware/src/AudioDeviceManager';
    /**
        * @hidden
        */
    export { AudioParams } from 'voximplant-websdk/Hardware/src/AudioParams';
    /**
        * @hidden
        */
    export { CameraManager } from 'voximplant-websdk/Hardware/src/CameraManager';
    /**
        * @hidden
        */
    export { CameraParams } from 'voximplant-websdk/Hardware/src/CameraParams';
    /**
        * @hidden
        */
    export { SharingStream } from 'voximplant-websdk/Hardware/src/SharingStream';
    /**
        * @hidden
        */
    export { StreamManager } from 'voximplant-websdk/Hardware/src/StreamManager';
    /**
        * @hidden
        */
    export { IOSCacheManager } from 'voximplant-websdk/Hardware/src/IOSCacheManager';
}

declare module 'voximplant-websdk/PeerConnection/PeerConnection' {
    import { Logger } from 'voximplant-websdk/Logger';
    import { Call } from 'voximplant-websdk/Call/Call';
    import { VideoFlags } from 'voximplant-websdk/Structures';
    import { TrackType } from 'voximplant-websdk/Types';
    import { ReInviteQ } from 'voximplant-websdk/PeerConnection/ReInviteQ';
    import { EventHandlers } from 'voximplant-websdk/EventHandlers';
    /**
        * @hidden
        */
    export enum PeerConnectionState {
            IDLE = 0,
            REMOTEOFFER = 1,
            LOCALOFFER = 2,
            ESTABLISHING = 3,
            ESTABLISHED = 4,
            CLOSED = 5
    }
    /**
        * @hidden
        */
    export enum PeerConnectionMode {
            CLIENT_SERVER_V1 = 0,
            P2P = 1,
            CONFERENCE = 2
    }
    /**
        * Peer connection wrapper. Will have implementations for WebRTC/ORTC
        * @hidden
        */
    export abstract class PeerConnection {
            protected id: string;
            protected mode: PeerConnectionMode;
            protected videoEnabled: VideoFlags;
            protected _localStream: MediaStream;
            protected logger: Logger;
            protected state: PeerConnectionState;
            protected _call: Call;
            protected pendingCandidates: any;
            protected candidateSendTimer: any;
            protected canSendCandidates: boolean;
            protected reInviteQ: ReInviteQ;
            protected sinkId: any;
            /**
                * @hidden
                * @param state
                */
            protected onHold: boolean;
            protected _canReInvite: {
                    (): boolean;
            };
            protected muteMicState: boolean;
            protected renegotiationInProgress: boolean;
            constructor(id: string, mode: PeerConnectionMode, videoEnabled: VideoFlags);
            protected _remoteStreams: Array<MediaStream>;
            readonly remoteStreams: MediaStream[];
            abstract _hdnFRSPrep(): void;
            abstract hasLocalAudio(): boolean;
            abstract hasLocalVideo(): boolean;
            abstract enableVideo(flag: boolean): void;
            abstract getTransceivers(): RTCRtpTransceiver[];
            abstract getRemoteDescription(): string;
            abstract _fixFFSoundBug(): void;
            abstract updateHoldState(): void;
            getId(): string;
            getState(): PeerConnectionState;
            processRemoteAnswer(headers: {
                    [id: string]: string;
            }, sdp: string): Promise<void>;
            getLocalOffer(): Promise<RTCSessionDescription>;
            getLocalAnswer(): Promise<RTCSessionDescription>;
            processRemoteOffer(sdp: string): Promise<string>;
            close(): void;
            addRemoteCandidate(candidate: string, mLineIndex: number): Promise<void>;
            handleReinvite(headers: {
                    [id: string]: string;
            }, sdp: string, hasVideo: boolean): Promise<void>;
            addCandidateToSend(attrString: any, mLineIndex: any): void;
            canStartSendingCandidates(): void;
            sendDTMF(key: string): void;
            setVideoEnabled(newVal: VideoFlags): void;
            setVideoFlags(newFlags: VideoFlags): void;
            /**
                * Get sdp audio/video directions from sdp
                * @hidden
                */
            getDirections(): Object;
            /**
                * @hidden
                * @param state
                */
            setHoldKey(state: any): void;
            getTrackKind(sdp: string): {
                    [id: string]: TrackType;
            };
            sendMedia(audio: boolean, video: boolean): Promise<EventHandlers.Updated>;
            /**
                * Hold/Unhold action for protocol v3 (Fully implement RFC 4566
                * @param newState
                */
            hold(newState: boolean): Promise<EventHandlers.Updated>;
            hdnFRS(): Promise<EventHandlers.Updated>;
            abstract _hdnFRS(): void;
            muteMicrophone(newState: boolean): void;
            restoreMute(): void;
            restoreVideoSending(): void;
            addCustomMedia(stream: MediaStream): Promise<void>;
            /**
                * @hidden
                * @param {MediaStream} stream
                */
            fastAddCustomMedia(stream: MediaStream): void;
            /**
                * @hidden
                * @param {MediaStream} stream
                */
            fastRemoveCustomMedia(stream: MediaStream): void;
            removeCustomMedia(stream: MediaStream): Promise<void>;
            /**
                * @param {MediaStream} stream
                */
            updateCustomMedia(stream: MediaStream): void;
            /**
                * @param {MediaStreamTrack} newTrack
                */
            replaceVideoTrack(newTrack: MediaStreamTrack): void;
            abstract getConfiguration(): RTCConfiguration;
            abstract setConfiguration(config: RTCConfiguration): any;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
            protected abstract _processRemoteAnswer(headers: {
                    [id: string]: string;
            }, sdp: string): Promise<void>;
            protected abstract _getLocalOffer(): Promise<RTCSessionDescription>;
            protected abstract _getLocalAnswer(): Promise<RTCSessionDescription>;
            protected abstract _processRemoteOffer(sdp: string): Promise<string>;
            protected abstract _close(): any;
            protected abstract _addRemoteCandidate(candidate: string, mLineIndex: number): Promise<void>;
            protected abstract _sendDTMF(key: string, duration: number, gap: number): void;
            protected abstract _getDirections(): Object;
            protected abstract _getStreamActivity(): Object;
            protected abstract _handleReinvite(headers: {
                    [id: string]: string;
            }, sdp: string, hasVideo: boolean): Promise<void>;
            protected setState(st: PeerConnectionState): void;
            protected sendLocalCandidateToPeer(cand: string, mLineIndex: number): void;
            protected abstract _hold(newState: boolean): void;
            protected abstract _addCustomMedia(stream: MediaStream): void;
            protected abstract _removeCustomMedia(stream: MediaStream): void;
            protected abstract _updateCustomMedia(stream: MediaStream): void;
    }
}

declare module 'voximplant-websdk/Call/CallManager' {
    import { Call } from 'voximplant-websdk/Call/Call';
    import { VoxSignalingHandler } from 'voximplant-websdk/Signaling/VoxSignalingHandler';
    import { CallSettings, VideoSettings } from 'voximplant-websdk/Structures';
    import { CallStatsManager } from "voximplant-websdk/Stats/CallStatsManager";
    /**
        * Implenets signaling protocol and local call management'
        * Singleton
        * All call manipulation MUST be there
        * @hidden
        */
    export class CallManager implements VoxSignalingHandler {
            rtcStatsCollectionInterval: number;
            rtcStatsInquiryInterval: number;
            callStats: CallStatsManager;
            protocolVersion: string;
            _h264first: boolean;
            constructor();
            readonly calls: {
                    [id: string]: Call;
            };
            /**
                * Get active call count
                * @hidden
                * @returns {number}
                */
            readonly numCalls: number;
            static get(): CallManager;
            /**
                * Remove all non X- headers
                * @param headers
                * @returns {{}}
                */
            static cleanHeaders(headers: {
                    [id: string]: string;
            }): {
                    [id: string]: string;
            };
            /**
                * Place an outgoing call
                * @param {string} number Number to place call
                * @param {object} headers Additional headers
                * @param {boolean} video Initial state of video - enabled/disabled
                * @param {object} extraParams DEPRECATED
                */
            call(sets: CallSettings): Call;
            callConference(sets: CallSettings): Call;
            /**
                * Check if sdp have video section with send flow
                * @param sdp
                * @returns {boolean}
                */
            isSDPHasVideo(sdp: any): boolean;
            handleConnectionFailed(id: string, code: number, reason: string, headers: {
                    [id: string]: string;
            }): void;
            onSignalingConnected(): void;
            onSignalingClosed(): void;
            onSignalingConnectionFailed(errorMessage: string): void;
            onMediaConnectionFailed(): void;
            transferCall(call1: Call, call2: Call): void;
            /**
                * Fx for backward compatibility with hidden Fx Client.removeCall
                * @param call_id
                */
            removeCall(call_id: string): void;
            setProtocolVersion(ver: string): void;
            setAllCallsVolume(level: number): void;
            useVideoSource(id: string): Promise<void>;
            setVideoSettings(settings: VideoSettings): Promise<void>;
            useAudioSource(id: string): Promise<void>;
            iceServers: {
                    [callId: string]: RTCIceServer[];
            };
            onICEResult(id: string, result: boolean, config?: any): void;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/PeerConnection/SDP/Interfaces' {
    /**
        * Created by irbisadm on 15/04/16.
        */
    import { SdpAttribute } from "voximplant-websdk/PeerConnection/SDP/ParserSDP/Interfaces";
    /**
        * Parsed sections with parsed codecs
        * @hidden
        */
    export interface CodecSorterCodecList {
            /**
                * part of sdp before media section
                */
            prefix: string;
            /**
                * Media sections
                */
            sections: Array<CodecSorterSection>;
    }
    /**
        * Parsed section of codec
        * @hidden
        */
    export interface CodecSorterSection {
            /**
                * kind of media section
                * @see https://tools.ietf.org/html/rfc4566#section-5.14
                */
            kind: any;
            /**
                * First line without codec order
                */
            firstLine: string;
            /**
                * Part of media section before codec
                */
            prefix: string;
            /**
                * List of codec parsed by /r/n point
                */
            codec: Array<Array<string>>;
            /**
                * Part of media section after codec definition
                */
            sufix: string;
    }
    /**
        * Object holding media section for sorting by end user
        * @example
        *  //Google Chrome 54
        *  codecList = {
        *    "sections":[
        *      {
        *        "kind":"audio",
        *        "codec":
        *          [
        *            "opus/48000/2",
        *            "ISAC/16000",
        *            "ISAC/32000",
        *            "G722/8000",
        *            "PCMU/8000",
        *            "PCMA/8000",
        *            "CN/32000",
        *            "CN/16000",
        *            "CN/8000",
        *            "telephone-event/8000"
        *          ]
        *      },
        *      {
        *        "kind":"video",
        *        "codec":
        *          [
        *            "VP8/90000",
        *            "VP9/90000",
        *            "H264/90000",
        *            "red/90000",
        *            "ulpfec/90000",
        *            "rtx/90000",
        *            "rtx/90000",
        *            "rtx/90000",
        *            "rtx/90000"
        *          ]
        *      }
        *    ]
        *  }
        */
    export interface CodecSorterUserCodecList {
            /**
                * List of sections for end user
                */
            sections: CodecSorterUserSections[];
    }
    /**
        *  Description of one media section
        *  @example
        *   section = {
        *    "kind":"audio",
        *    "codec":
        *      [
        *        "opus/48000/2",
        *        "ISAC/16000",
        *        "ISAC/32000",
        *        "G722/8000",
        *        "PCMU/8000",
        *        "PCMA/8000",
        *        "CN/32000",
        *        "CN/16000",
        *        "CN/8000",
        *        "telephone-event/8000"
        *      ]
        *   }
        */
    export interface CodecSorterUserSections {
            /**
                * kind of media - list accepted media shorted for "audio" and "video"
                */
            kind: 'audio' | 'video';
            /**
                * list of payload description for end user
                */
            codec: SdpAttribute[];
    }
}

declare module 'voximplant-websdk/Stats/Structures' {
    export module Statistic {
            /**
                * Enumeration of the call quality issue levels.
                * Quality issue events are [CallEvents.QualityIssueCodecMismatch], [CallEvents.QualityIssueHighMediaLatency], [CallEvents.QualityIssueICEDisconnected], [CallEvents.QualityIssueLocalVideoDegradation] and [CallEvents.QualityIssuePacketLoss].
                */
            enum QualityIssueLevel {
                    /**
                        * Indicates that a detected issue has a critical impact on a call quality.
                        * In most cases it results in lost media stream between call participants or broken functionality.
                        */
                    Critical,
                    /**
                        * Indicates that a detected issue may have a major impact on a call quality.
                        * For audio calls it may result in a corrupted stream (discord or robotic voice) for call participants, audio delays and glitches.
                        * For video calls it may result in significant video artifacts (pixelating, blurring, color bleeding, flickering, noise), one-way/no video stream between the call participants
                        */
                    Major,
                    /**
                        * Indicates that a detected issue may have a minor impact on a call quality.
                        * For audio calls it may result in temporary audio artifacts.
                        * For video calls it may result in video artifacts in case of a dynamically changing video stream.
                        */
                    Minor,
                    /**
                        * Indicates that no issue is detected or it is already resolved.
                        */
                    None
            }
            /**
                * Structure that represents statistics for outbound audio stream. Available via [CallStats].
                */
            interface OutboundAudioStats {
                    /**
                        * Audio level value is between 0..1 (linear), where 1.0 represents 0 dBov, 0 represents silence, and 0.5 represents approximately 6 dBSPL change in the sound pressure level from 0 dBov.
                        * Only in Chrome
                        * */
                    audioLevel?: number;
                    /**
                        * Total number of bytes  sent within the audio stream.
                        * */
                    bytesSent: number;
                    /**
                        * Audio codec type for the audio stream.
                        * Only in Chrome
                        * */
                    codec?: string;
                    /**
                        * Total number of packets sent within the audio stream.
                        * */
                    packetsSent: number;
                    /**
                        * The time at which the call statistics are collected (in UNIX timestamp format).
                        * */
                    timestamp: number;
            }
            /**
                * Structure that represents statistics for outbound video stream. Available via [CallStats].
                */
            interface OutboundVideoStats {
                    /**
                        * Total number of bytes  sent within the video stream.
                        * */
                    bytesSent: number;
                    /**
                        * Video codec name for the video stream.
                        * Only in Chrome
                        * */
                    codec: string;
                    /**
                        * Bitrate that the encoder is actually producing. Measured in bits per seconds and calculated over a 1 second window.
                        * Only in Firefox
                        * */
                    encoderBitrate: string;
                    /**
                        * The number of complete frames in the last second
                        * Only in Firefox
                        * */
                    fps: string;
                    /**
                        * Video frame height sent within the video stream at the moment the statistics are collected.
                        * Only in Chrome
                        * */
                    frameHeight: string;
                    /**
                        * Video frame width sent within the video stream at the moment the statistics are collected.
                        * Only in Chrome
                        * */
                    frameWidth: string;
                    /**
                        * Total number of packets sent within the video stream.
                        * */
                    packetsSent: number;
                    /**
                        * Target bitrate for video encoder that does not count the size of the IP and other transport layers like TCP or UDP. Measured in bits per second and calculated over a 1 second window
                        * Only in Safari
                        * */
                    targetBitrate: number;
                    /**
                        * The time at which the call statistics are collected (in UNIX timestamp format).
                        * */
                    timestamp: number;
            }
            interface InboundAudioStats {
                    /**
                        * Total number of bytes received within the audio stream.
                        * */
                    bytesReceived: number;
                    /**
                        * Audio codec name for the audio stream, e.g. "opus".
                        * Only in Chrome
                        * */
                    codec: number;
                    /**
                        * Average time packets stay in a jitter buffer (temporary storage buffer used to capture incoming data packets). It is used to ensure the continuity of streams by smoothing out packet arrival times during periods of network congestion. It's calculated as jitterBufferDelay for the last [Config.rtcStatsCollectionInterval] (sum of the time each frame takes from the time it is received and to the time it exits the jitter buffer) divided by jitterBufferEmittedCount for the same interval (total number of frames that have come out of the jitter buffer). Measured in milliseconds.
                        * Only in Chrome
                        * */
                    jitterBufferMs: number;
                    /**
                        * Packet loss in the audio stream. Values are in the range 0..1, where 0 means no loss and 1 means full loss.
                        * */
                    loss: number;
                    /**
                        * Total number of audio packets lost for the audio stream.
                        * */
                    packetsLost: number;
                    /**
                        * Total number of packets received within the audio stream.
                        * */
                    packetsReceived: number;
                    /**
                        * The time at which the call statistics are collected (in UNIX timestamp format).
                        * */
                    timestamp: number;
            }
            interface InboundVideoStats {
                    /**
                        * Total number of bytes received within the video stream.
                        * */
                    bytesReceived: number;
                    /**
                        * Video codec name for the video stream, e.g. "VP8".
                        * Only in Chrome
                        * */
                    codec: number;
                    /**
                        * Video frame height received within the video stream at the moment the statistics are collected.
                        * Only in Chrome
                        * */
                    frameHeight: number;
                    /**
                        * Video frame width received within the video stream at the moment the statistics are collected.
                        * Only in Chrome
                        * */
                    frameWidth: number;
                    /**
                        * Temporary storage buffer used to capture incoming data packets. It is used to ensure the continuity of streams by smoothing out packet arrival times during periods of network congestion. Measured in milliseconds.
                        * @hidden
                        * */
                    jitterBufferMs: number;
                    /**
                        * Packet loss in the video stream. Values are in the range 0..1, where 0 means no loss and 1 means full loss.
                        * */
                    loss: number;
                    /**
                        * Total number of video packets lost for the video stream.
                        * */
                    packetsLost: number;
                    /**
                        * Total number of packets received within the video stream.
                        * */
                    packetsReceived: number;
                    /**
                        * The time at which the call statistics are collected (in UNIX timestamp format).
                        * */
                    timestamp: number;
                    framesDecoded: number;
                    framesDropped: number;
                    framesReceived: number;
            }
            /**
                * Statistics for endpoints existing in the call at the moment of the stats collection.
                * */
            interface EndpointStats {
                    /**
                        * Total number of audio bytes received from the endpoint in the call.
                        */
                    audioBytesReceived?: number;
                    /**
                        * Total number of audio packets lost from the endpoint in the call.
                        */
                    audioPacketsLost?: number;
                    /**
                        * Total number of audio packets received from the endpoint in the call.
                        */
                    audioPacketsReceived?: number;
                    /**
                        * Statistics for all active incoming video streams from the [Endpoint] at the moment of the stats collection.
                        * @typeDef
                        */
                    remoteAudioStats?: {
                            [id: string]: InboundAudioStats;
                    };
                    /**
                        * Statistics for all active incoming audio streams from the [Endpoint] at the moment of the stats collection.
                        * @typeDef
                        */
                    remoteVideoStats?: {
                            [id: string]: InboundVideoStats;
                    };
                    /**
                        * The time at which the call statistics are collected (in UNIX timestamp format).
                        */
                    timestamp?: number;
                    /**
                        * Total number of bytes (audio and video) received from the endpoint in the call.
                        */
                    totalBytesReceived?: number;
                    /**
                        * Total number of packets (audio and video) received from the endpoint in the call.
                        */
                    totalPacketsReceived?: number;
                    /**
                        * Total number of video bytes received from the endpoint in the call.
                        */
                    videoBytesReceived?: number;
                    /**
                        * Total number of video packets lost from the endpoint in the call.
                        */
                    videoPacketsLost?: number;
                    /**
                        * Total number of video packets received from the endpoint in the call.
                        */
                    videoPacketsReceived?: number;
            }
            /**
                * Statistics for a [Call]. Reported in a handler function for [CallEvents.CallStatsReceived].
                */
            interface CallStats {
                    /**
                        * Total number of audio bytes received for the call.
                        */
                    audioBytesReceived?: number;
                    /**
                        * Total number of audio bytes sent for the call.
                        */
                    audioBytesSent?: number;
                    /**
                        * Total packet loss in the audio stream(s) related to the call session. Values are in the range 0..1, where 0 means no loss and 1 means full loss.
                        */
                    audioLoss?: number;
                    /**
                        * Total number of audio packets lost for the call.
                        */
                    audioPacketsLost?: number;
                    /**
                        * Total number of audio packets received for the call.
                        */
                    audioPacketsReceived?: number;
                    /**
                        * Total number of audio packets sent for the call.
                        */
                    audioPacketsSent?: number;
                    /**
                        * It is calculated by the underlying congestion control by combining the available bitrate for all the outgoing RTP streams using a current selected candidate pair. It is measured in bits per second and the bitrate is calculated over a 1 second window.
                        * Only in Chrome
                        * */
                    availableOutgoingBitrate?: number;
                    /**
                        * Statistics for endpoints existing in the call at the moment of the stats collection.
                        */
                    endpointStats?: Map<string, EndpointStats>;
                    /**
                        * Statistics for all active outgoing audio streams of the call at the moment of the stats collection.
                        */
                    localAudioStats?: Map<string, OutboundAudioStats>;
                    /**
                        * The type of the local ICE candidate.
                        * Only in Chrome and Firefox
                        */
                    localCandidateType?: string;
                    /**
                        * Statistics for all active outgoing video streams of the call at the moment of the stats collection.
                        */
                    localVideoStats?: Map<string, OutboundVideoStats>;
                    /**
                        * The type of network interface used by the base of a local candidate (the address the ICE agent sends from). This stat only tells you about the network interface used by the first "hop"; it's possible that a connection will be bottlenecked by another type of network. For example, when using Wi-Fi tethering, the networkType of the relevant candidate would be "wifi", even when the next hop is over a cellular connection.
                        * Only in Chrome and Firefox
                        */
                    networkType?: string;
                    /**
                        * The type of the remote ICE candidate.
                        * Only in Chrome and Firefox
                        */
                    remoteCandidateType?: string;
                    /**
                        * The latest round trip time measured in seconds.
                        * Only in Chrome
                        */
                    rtt?: number;
                    /**
                        * The time at which the call statistics are collected (in UNIX timestamp format, microseconds).
                        */
                    timestamp?: number;
                    /**
                        * Total number of bytes (audio and video) received in the call.
                        */
                    totalBytesReceived?: number;
                    /**
                        * Total number of bytes (audio and video) sent in the call.
                        */
                    totalBytesSent?: number;
                    /**
                        * Total incoming packet loss for the call.
                        */
                    totalLoss?: number;
                    /**
                        * Total number of incoming packets lost (audio and video) in the call.
                        */
                    totalPacketsLost?: number;
                    /**
                        * Total number of packets (audio and video) received in the call.
                        */
                    totalPacketsReceived?: number;
                    /**
                        * Total number of packets (audio and video) sent in the call.
                        */
                    totalPacketsSent?: number;
                    /**
                        * Total number of video bytes received for the call.
                        */
                    videoBytesReceived?: number;
                    /**
                        * Total number of video bytes sent for the call.
                        */
                    videoBytesSent?: number;
                    /**
                        * Total packet loss in the video stream(s) related to the call session. Values are in the range 0..1, where 0 means no loss and 1 means full loss.
                        */
                    videoLoss?: number;
                    /**
                        * Total number of video packets lost for the call.
                        */
                    videoPacketsLost?: number;
                    /**
                        * Total number of video packets received for the call.
                        */
                    videoPacketsReceived?: number;
                    /**
                        * Total number of video packets sent for the call.
                        */
                    videoPacketsSent?: number;
            }
            /**
                * @hidden
                */
            interface PrevCallStats {
                    jitterBuffer?: {
                            [trackId: string]: {
                                    delay: number;
                                    emittedCount: number;
                            };
                    };
            }
            /**
                * @hidden
                */
            interface CodecMismatchStory {
                    audioLevel: QualityIssueLevel;
                    videoLevel: QualityIssueLevel;
                    sharingLevel: QualityIssueLevel;
                    audioChecks: number;
                    videoChecks: number;
                    sharingChecks: number;
            }
            /**
                * @hidden
                */
            interface HighMediaLatencyStory {
                    levels: QualityIssueLevel[];
                    latencies: number[];
                    prevLevel: QualityIssueLevel;
                    lastJitterBuffers: {
                            [trackId: string]: {
                                    delay: number;
                                    emittedCount: number;
                            };
                    };
            }
            /**
                * @hidden
                */
            interface ICEDisconnectedStory {
                    level: QualityIssueLevel;
            }
            /**
                * @hidden
                */
            interface LocalVideoDegradationStory {
                    videoLevel: QualityIssueLevel;
                    sharingLevel: QualityIssueLevel;
            }
            /**
                * @hidden
                */
            interface NoAudioSignalStory {
                    level: QualityIssueLevel;
            }
            /**
                * @hidden
                */
            interface PacketLossStory {
                    level: QualityIssueLevel;
                    lastLost: number;
                    lastTotal: number;
                    checks: number;
            }
            /**
                * @hidden
                */
            interface CallQualityIssues {
                    codecMismatch: CodecMismatchStory;
                    highMediaLatency: HighMediaLatencyStory;
                    ICEDisconnected: ICEDisconnectedStory;
                    localVideoDegradation: LocalVideoDegradationStory;
                    noAudioSignal: NoAudioSignalStory;
                    packetLoss: PacketLossStory;
            }
    }
}

declare module 'voximplant-websdk/Signaling/MsgEvent' {
    /**
      * IM gen 2
      * @hidden
      */
    export enum MsgEvent {
        onError = "onError",
        onCreateConversation = "onCreateConversation",
        onEditConversation = "onEditConversation",
        onRemoveConversation = "onRemoveConversation",
        onGetConversation = "onGetConversation",
        onGetPublicConversations = "onGetPublicConversations",
        onGetUser = "onGetUser",
        onEditUser = "onEditUser",
        onSetStatus = "onSetStatus",
        onSendMessage = "onSendMessage",
        onEditMessage = "onEditMessage",
        onRemoveMessage = "onRemoveMessage",
        isRead = "isRead",
        onTyping = "onTyping",
        onSubscribe = "onSubscribe",
        onUnsubscribe = "onUnsubscribe",
        onGetSubscriptionList = "onGetSubscriptionList",
        onCreateBot = "onCreateBot",
        onRemoveBot = "onRemoveBot",
        onRetransmitEvents = "onRetransmitEvents"
    }
}

declare module 'voximplant-websdk/Signaling/MsgAction' {
    /**
        * IM gen 2
        * @hidden
        */
    export enum MsgAction {
            /**
                * @hidden
                */
            UNKNOWN = "UNKNOWN",
            createConversation = "createConversation",
            editConversation = "editConversation",
            removeConversation = "removeConversation",
            joinConversation = "joinConversation",
            leaveConversation = "leaveConversation",
            getConversation = "getConversation",
            getConversations = "getConversations",
            getPublicConversations = "getPublicConversations",
            /**
                * @hidden
                */
            searchConversations = "searchConversations",
            /**
                * @hidden
                */
            removeEmptyConversation = "removeEmptyConversation",
            addParticipants = "addParticipants",
            editParticipants = "editParticipants",
            removeParticipants = "removeParticipants",
            getUser = "getUser",
            getUsers = "getUsers",
            editUser = "editUser",
            setStatus = "setStatus",
            sendMessage = "sendMessage",
            editMessage = "editMessage",
            removeMessage = "removeMessage",
            typingMessage = "typingMessage",
            isRead = "isRead",
            subscribe = "subscribe",
            unsubscribe = "unsubscribe",
            manageNotification = "manageNotification",
            getSubscriptionList = "getSubscriptionList",
            /**
                * @hidden
                */
            createBot = "createBot",
            /**
                * @hidden
                */
            removeBot = "removeBot",
            retransmitEvents = "retransmitEvents"
    }
}

declare module 'voximplant-websdk/Hardware/src/AudioDeviceManager' {
    import { Call } from 'voximplant-websdk/Call/Call';
    import { AudioOutputInfo, AudioSourceInfo } from 'voximplant-websdk/Structures';
    import { AudioParams } from 'voximplant-websdk/Hardware/src/AudioParams';
    /**
        * @hidden
        */
    export class AudioDeviceManager {
            /**
                * @hidden
                */
            constructor();
            /**
                * @hidden
                */
            getAudioContext(): any;
            /**
                * Create an AudioContext object inside SDK. This function must be used on a user gesture at Google Chrome 66 and above
                * See <a href="https://developers.google.com/web/updates/2017/09/autoplay-policy-changes#webaudio"> Google Developers Blog post</a> about this issue
                */
            prepareAudioContext(): void;
            /**
                * Get the AudioDeviceManager instance
                */
            static get(): AudioDeviceManager;
            /**
                * Return available audio input devices (sound card/processor). Note that if new passive microphone was plugged into the same sound card, the method will return that sound card; if new microphone has its own sound processor, the method will return the updated array with new device.
                */
            getInputDevices(): Promise<Array<AudioSourceInfo>>;
            /**
                * Return available audio output devices (sound card/processor). If new plugged device has its own sound processor, the method will return the updated array with new device.
                */
            getOutputDevices(): Promise<Array<AudioOutputInfo>>;
            /**
                * Return default audio settings as the [AudioParams] object.
                */
            getDefaultAudioSettings(): AudioParams;
            /**
                * Set default audio settings for calls.
                */
            setDefaultAudioSettings(params: AudioParams): void;
            /**
                * Set audio settings for specified call.
                */
            setCallAudioSettings(call: Call, params: AudioParams): Promise<void>;
            /**
                * Return audio settings of specified call as the [AudioParams] object.
                */
            getCallAudioSettings(call: Call): AudioParams;
            /**
                * @hidden
                */
            getCallConstraints(callID: string): Object;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Hardware/src/AudioParams' {
    /**
        *
        */
    export interface AudioParams {
            /**
                * Unique ID of microphone. It can be received via the [AudioDeviceManager.getInputDevices] method.
                */
            inputId?: string;
            /**
                * Unique ID of a sound card/processor. It can be received via the [AudioDeviceManager.getOutputDevices] method.
                */
            outputId?: string;
            /**
                * Should participant's echo be cancelled or not? If it's true, echo is cancelled; it's *true* by default.
                */
            echoCancellation?: boolean;
            /**
                * If this value is a true or false, the user agent will attempt to obtain media with automatic gain control enabled or disabled as specified, if possible.
                */
            autoGainControl?: boolean;
            /**
                * If it's true, backgroung noise is suppressed. It's *true* by default.
                */
            noiseSuppression?: boolean;
            /**
                * If it's true, all audio settings must suit each other strictly; the incorrect settings will cause an error. If it's false, the incorrect values will be changed to the best appropriate values. It's *false* by default.
                */
            strict?: boolean;
            /**
                * @hidden
                */
            disableAudio?: boolean;
            /**
                * @hidden
                */
            advanced?: any;
    }
}

declare module 'voximplant-websdk/Hardware/src/CameraManager' {
    import { CameraParams } from 'voximplant-websdk/Hardware/src/CameraParams';
    import { VideoSourceInfo } from 'voximplant-websdk/Structures';
    import { Call } from 'voximplant-websdk/Call/Call';
    /**
        * @hidden
        */
    export class CameraManager {
            /**
                * @hidden
                */
            constructor();
            /**
                * Get the CameraManager instance
                */
            static get(): CameraManager;
            /**
                * Set default video settings for calls.
                */
            setDefaultVideoSettings(params: CameraParams): Promise<void>;
            /**
                * Return default video settings as the [CameraParams] object.
                */
            getDefaultVideoSettings(): CameraParams;
            /**
                * Set video settings for the specified call.
                */
            setCallVideoSettings(call: Call, params: CameraParams): Promise<void>;
            /**
                * Return video settings of the specified call as the [CameraParams] object.
                */
            getCallVideoSettings(call: Call): CameraParams;
            /**
                * @hidden
                */
            getCallConstraints(callID: string): Object;
            /**
                * Return available video input devices (web camera(s)).
                */
            getInputDevices(): Promise<Array<VideoSourceInfo>>;
            /**
                * @hidden
                */
            static legacyParamConverter(videoParams: any): CameraParams;
            /**
                * Start camera resolution test for each video source in system.</br>
                * *Attention!* This procedure may take a lot of time and will send multiple Camera requests for
                * the Mozilla Firefox and Apple Safari browsers!</br>
                * Please, don't run it without warning user's request and attention.</br>
                * After running this function, please, save result to a browser storage (like LocalStorage or IndexedDB) and use it
                * in future with the [loadResolutionTestResult] function to restore
                * results.
                * This function mandatory only if you will use Hardware.VideoQuality.VIDEO_QUALITY_HIGH,Hardware.VideoQuality.VIDEO_QUALITY_MEDIUM or
                * Hardware.VideoQuality.VIDEO_QUALITY_LOW enums as video settings and strongly not recommended to use in another case.
                * @returns {Promise<any>}
                */
            testResolutions(cameraId?: string): Promise<any>;
            /**
                * Restoring a camera resolution test result previously got by [testResolutions]
                * function.
                * @returns {Promise<void>}
                */
            loadResolutionTestResult(data: any): boolean;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Hardware/src/CameraParams' {
    import Hardware from 'voximplant-websdk/Hardware';
    /**
        * @hidden
        */
    export interface CameraParams {
            /**
                * Unique ID of camera. It can be received via the [CameraManager.getInputDevices] method.
                */
            cameraId?: string;
            /**
                * One of the <a href="//voximplant.com/docs/references/websdk/enums/hardware.videoquality.html">video quality</a> values. The parameter is prior than <a href="#framewidth">frameWidth</a> and <a href="#frameheight">frameHeight</a> parameters.
                */
            videoQuality?: Hardware.VideoQuality;
            /**
                * Camera to use for video capture. If it's true, the front camera of your device will be used; if it's false, the rear camera will be in use. It's *true* by default in mobile browsers.
                */
            facingMode?: boolean;
            /**
                * Width of a frame in pixels. The parameter is less prior than <a href="#videoquality">videoQuality</a>.
                */
            frameWidth?: number;
            /**
                * Height of a frame in pixels. The parameter is less prior than <a href="#videoquality">videoQuality</a>.
                */
            frameHeight?: number;
            /**
                * If it's true, all video settings must suit each other strictly; the incorrect settings will cause an error. If it's false, the incorrect values will be changed to the best appropriate values. It's *false* by default.
                */
            strict?: boolean;
            /**
                * Frames per second.
                */
            frameRate?: number;
    }
}

declare module 'voximplant-websdk/Hardware/src/SharingStream' {
    import { MediaRenderer } from 'voximplant-websdk/Media/MediaRenderer';
    /**
      * @hidden
      */
    export interface SharingStream {
        renderer?: MediaRenderer;
        stream: MediaStream;
    }
}

declare module 'voximplant-websdk/Hardware/src/StreamManager' {
    import Hardware from 'voximplant-websdk/Hardware';
    import { EventListenerOption, EventTarget } from 'voximplant-websdk/EventTarget';
    import { Call } from 'voximplant-websdk/Call/Call';
    import { MediaRenderer } from 'voximplant-websdk/Media/MediaRenderer';
    import { SharingStream } from 'voximplant-websdk/Hardware/src/SharingStream';
    import { TrackType } from 'voximplant-websdk/Types';
    /**
        * @hidden
        */
    export class StreamManager extends EventTarget<Hardware.HardwareEvents> {
            isLocalVideoRequested: boolean;
            /**
                * @hidden
                */
            constructor();
            /**
                * Get the StreamManager instance
                */
            static get(): StreamManager;
            /**
                * @hidden
                * @param {Call} call
                * @returns {Promise<MediaStream>}
                */
            getCallStream(call: Call, ignore?: boolean): Promise<MediaStream>;
            /**
                * @hidden
                * @param {Call} call
                * @returns {Promise<MediaStream>}
                * @private
                */
            _updateCallStream(call: Call): Promise<MediaStream>;
            /**
                * @hidden
                * @param {Call} call
                * @returns {Promise<EventHandlers.Updated>}
                */
            updateCallStream(call: Call): Promise<void>;
            /**
                * @hidden
                * @param {Call} call
                */
            remCallStream(call: Call): void;
            /**
                * @hidden
                * @param {Call} call
                */
            _remCallStream(stream: MediaStream): void;
            /**
                * @hidden
                */
            clear(): void;
            /**
                * List of currently used containers for local audio and video streams.
                */
            getLocalMediaRenderers(): MediaRenderer[];
            /**
                * Turn on local video. The container for local video elements must be specified via in the
                * [Config.localVideoContainerId] field in the [Client.init] config.
                *   If it's not specified, local videos will be appended to end of the *<body>* element.
                *  Use the <a href="#hidelocalvideo">hideLocalVideo</a> method to turn off local video.
                */
            showLocalVideo(placeOnDom?: boolean): Promise<MediaRenderer>;
            updateLocalVideo(): void;
            /**
                * Turn off local video. Use the <a href="#showlocalvideo">showLocalVideo</a> method to turn on local video.
                */
            hideLocalVideo(): Promise<void>;
            /**
                * Register a handler for the specified event. The method is a shorter equivalent for *addEventListener*. One event can have more than one handler; handlers are executed in order of registration.
                * Use the [StreamManager.off] method to delete a handler.
                */
            on(event: Hardware.HardwareEvents, handler: (ev: any) => void, options?: EventListenerOption): void;
            /**
                * Remove a handler for the specified event. The method is a shorter equivalent for *removeEventListener*. If a number of events has the same function as a handler, the method can be called multiple times with the same handler argument.
                */
            off(event: Hardware.HardwareEvents, handler?: (ev: any) => void): void;
            /**
                * Get sharing media and create renderer if need.
                * @hidden
                * @param {Call} call
                * @param {boolean} showLocalVideo
                * @returns {Promise<Hardware.SharingStream>}
                */
            _newScreenSharing(call: Call, showLocalVideo: boolean, replaceVideo?: boolean): Promise<SharingStream>;
            /**
                * @hidden
                * @param {Call} call
                * @returns {Hardware.SharingStream[]}
                * @private
                */
            _getScreenSharing(call: Call): SharingStream[];
            /**
                * @hidden
                * @param {Call} call
                * @param {SharingStream} sharingStream
                * @returns {Promise<void>}
                * @private
                */
            _clearScreenSharing(call: Call, sharingStream: SharingStream): Promise<void>;
            /**
                * @hidden
                * @param {Call} call
                * @returns {{[p: string]: TrackType}}
                * @private
                */
            _getTracksKind(call: Call): {
                    [id: string]: TrackType;
            };
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/Hardware/src/IOSCacheManager' {
    import { Call } from 'voximplant-websdk/Call/Call';
    import { MediaRenderer } from 'voximplant-websdk/Media/MediaRenderer';
    /**
        * @hidden
        */
    export class IOSCacheManager {
            static get(): IOSCacheManager;
            constructor();
            getStream(constrains: {
                    [id: string]: any;
            }): Promise<MediaStream>;
            clear(call: Call): void;
            registerMediaRenderer(call: Call, mediaRenderer: MediaRenderer): void;
    }
}

declare module 'voximplant-websdk/PeerConnection/ReInviteQ' {
    /**
        * @hidden
        */
    import { Call } from "voximplant-websdk/Call/Call";
    /**
        * @hidden
        */
    export class ReInviteQ {
            constructor(call: Call, _pcStatus: {
                    (): boolean;
            });
            runNext(): void;
            add(member: ReIviteQMember): void;
            clear(): void;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
    /**
        * @hidden
        */
    export interface ReIviteQMember {
            resolve: Function;
            reject: Function;
            fx: Function;
    }
}

declare module 'voximplant-websdk/Stats/CallStatsManager' {
    import { Call } from 'voximplant-websdk/Call/Call';
    import { Statistic } from 'voximplant-websdk/Stats/Structures';
    /**
        * @hidden
        */
    export class CallStatsManager {
            constructor();
            static get(): CallStatsManager;
            readonly calls: WeakMap<Call, {
                    nextDeliveryTimer?: number;
                    prevStats?: Statistic.PrevCallStats;
            }>;
            addCall(call: Call): void;
            deleteCall(call: Call): Promise<boolean>;
            sendStatistics(call: Call, statistics: {
                    raw: Array<any>;
                    formatted: Array<any>;
            }): void;
            /**
                * @hidden
                * @return {string}
                * @private
                */
            _traceName(): string;
    }
}

declare module 'voximplant-websdk/PeerConnection/SDP/ParserSDP/Interfaces' {
    /** Generic representation of attribute. */
    export interface SdpAttribute {
            /** Attribute name. */
            name: string;
            /** Attribute value or grouped value. */
            value: any;
    }
    /** This structure declares SDP \a rtpmap attribute. */
    export interface SdpRtpmap {
            /** Payload type. */
            pt: string;
            /** Encoding name. */
            encName: string;
            /** Clock rate. */
            clockRate: number;
            /** Parameter. */
            param: string;
    }
    /** This structure describes SDP \a fmtp attribute. */
    export interface SdpFmtp {
            /** Format type. */
            fmt: string;
            /** Format specific parameter. */
            fmtParam: string;
    }
    /** This structure describes SDP \a rtcp attribute. */
    export interface SdpRtcpAttr {
            /** RTCP port number. */
            port: number;
            /** Optional network type. */
            netType?: string;
            /** Optional address type. */
            addrType?: string;
            /** Optional address. */
            addr?: string;
    }
    /** This structure describes SDP connection info ("c=" line). */
    export interface SdpConn {
            /** Network type ("IN"). */
            netType: string;
            /** Address type ("IP4", "IP6"). */
            addrType: string;
            /** The address. */
            addr: string;
    }
    /** This structure describes SDP bandwidth info ("b=" line). */
    export interface SdpBandw {
            /** Bandwidth modifier. */
            modifier: string;
            /** Bandwidth value. */
            value: number;
    }
    /**
        * This structure describes SDP media descriptor. A SDP media descriptor
        * starts with "m=" line and contains the media attributes and optional
        * connection line.
        */
    export interface SdpMedia {
            /** Media descriptor line ("m=" line)*/
            descr: SdpMediaDescr;
            /** Optional connection info.*/
            conn?: SdpConn;
            /** Number of bandwidth info.*/
            bandwCount?: number;
            /** Bandwidth info. */
            bandw?: SdpBandw[];
            /** Number of attributes.*/
            attrCount?: number;
            /** Attributes.*/
            attr?: SdpAttribute[];
    }
    /**Media descriptor line ("m=" line)*/
    export interface SdpMediaDescr {
            /** Media type ("audio", "video")*/
            media: "audio" | "video" | string;
            /** Port number.*/
            port: number;
            /** Port count, used only when >2*/
            portCount?: number;
            /** Transport ("RTP/AVP")*/
            transport: string;
            /** Number of formats.*/
            fmtCount: number;
            /** Media formats.*/
            fmt: string[];
    }
    /**
        * This structure describes SDP session description. A SDP session descriptor
        * contains complete information about a session, and normally is exchanged
        * with remote media peer using signaling protocol such as SIP.
        */
    export interface SdpSession {
            /** Session origin (o= line)*/
            origin: SdpSessionOrigin;
            /** Subject line (s=)*/
            name: string;
            /** Connection line (c=)*/
            conn: SdpConn;
            /** Number of bandwidth info (b=) */
            bandwCount: number;
            /** Bandwidth info array (b=) */
            bandw: SdpBandw[];
            /** Session time (t= line) */
            time: SdpSessionTime;
            /** Number of attributes.*/
            attrCount: number;
            /** Attributes array.*/
            attr: SdpAttribute[];
            /** Number of media.*/
            mediaCount: number;
            /** Media array.*/
            media: SdpMedia[];
    }
    /** Session origin (o= line) */
    export interface SdpSessionOrigin {
            /** User*/
            user: string;
            /** Session ID*/
            id: string;
            /** Session version*/
            version: string;
            /** Network type ("IN")*/
            netType: string;
            /** Address type ("IP4", "IP6")*/
            addrType: string;
            /** The address.*/
            addr: string;
    }
    /** Session time (t= line) */
    export interface SdpSessionTime {
            /** Start time.*/
            start: number;
            /** Stop time.*/
            stop: number;
    }
}

declare module 'voximplant-websdk/Hardware' {
    import * as Implement from 'voximplant-websdk/Hardware/src';
    export module Hardware {
            /**
                * Events that are triggered when hardware device is added/removed/updated.
                */
            enum HardwareEvents {
                    /**
                        * Event is triggered each time when device is added/removed. Devices that trigger the event: microphones, video camera and sound output (available only in Google Chrome).
                        */
                    DevicesUpdated,
                    /**
                        * Event is triggered when local video or audio is started. E.g. when local video or screen sharing is stared.
                        */
                    MediaRendererAdded,
                    MediaRendererUpdated,
                    /**
                        * Event is triggered when local video or audio streaming is stopped. E.g. when local video or screen sharing streaming is stopped.
                        */
                    MediaRendererRemoved,
                    /**
                        * Event is triggered before local video or audio streaming is stopped. E.g. before local video or screen sharing streaming is stopped.
                        */
                    BeforeMediaRendererRemoved
            }
            /**
                * Enum that represents video quality.
                */
            enum VideoQuality {
                    /**
                        * Set better video quality for the current web camera.
                        * This option uses the last value from the [CameraManager.testResolutions] function result,
                        * or the data set to the [CameraManager.loadResolutionTestResult].
                        * If there is no result for a target web camera, use 1280x720 resolution
                        */
                    VIDEO_QUALITY_HIGH,
                    /**
                        * Set medium video quality for the current web camera.
                        * This option uses the last value from the [CameraManager.testResolutions] function result,
                        * or the data set to the [CameraManager.loadResolutionTestResult].
                        * If there is no result for a target web camera, use 640x480 resolution
                        */
                    VIDEO_QUALITY_LOW,
                    /**
                        * Set lower video quality for the current web camera.
                        * This option uses the last value from the [CameraManager.testResolutions] function result,
                        * or the data set to the [CameraManager.loadResolutionTestResult].
                        * If there is no result for a target web camera, use 320x240 resolution
                        */
                    VIDEO_QUALITY_MEDIUM,
                    /**
                        * 160x120 resolution
                        */
                    VIDEO_SIZE_QQVGA,
                    /**
                        * 176x144 resolution
                        */
                    VIDEO_SIZE_QCIF,
                    /**
                        * 320x240 resolution
                        */
                    VIDEO_SIZE_QVGA,
                    /**
                        * 352x288 resolution
                        */
                    VIDEO_SIZE_CIF,
                    /**
                        * 640x360 resolution
                        */
                    VIDEO_SIZE_nHD,
                    /**
                        * 640x480 resolution
                        */
                    VIDEO_SIZE_VGA,
                    /**
                        * 800x600 resolution
                        */
                    VIDEO_SIZE_SVGA,
                    /**
                        * 1280x720 resolution
                        */
                    VIDEO_SIZE_HD,
                    /**
                        * 1600x1200 resolution
                        */
                    VIDEO_SIZE_UXGA,
                    /**
                        * 1920x1080 resolution
                        */
                    VIDEO_SIZE_FHD,
                    /**
                        * 3840x2160 resolution
                        */
                    VIDEO_SIZE_UHD
            }
            /**
                * Interface that may be used to manage audio devices, i.e. see current active device, select another active device and get the list of available devices.
                */
            class AudioDeviceManager extends Implement.AudioDeviceManager {
            }
            /**
                * Audio constraints. Audio device will be chosen according to these settings.</br>
                * Settings are specified via
                * [AudioDeviceManager.setDefaultAudioSettings]
                *   and
                *   [AudioDeviceManager.setCallAudioSettings].
                */
            interface AudioParams extends Implement.AudioParams {
            }
            /**
                * Interface that may be used to manage cameras on Android device.
                */
            class CameraManager extends Implement.CameraManager {
            }
            /**
                * Camera constraints. Hardware camera will be chosen according to these settings.</br>
                * Settings are specified via
                * [CameraManager.setDefaultVideoSettings]
                *   and [CameraManager.setCallVideoSettings].
                */
            interface CameraParams extends Implement.CameraParams {
            }
            /**
                * @hidden
                */
            interface SharingStream extends Implement.SharingStream {
            }
            /**
                * Interface for extended management of local audio/video streams.
                */
            class StreamManager extends Implement.StreamManager {
            }
            /**
                * @hidden
                */
            class IOSCacheManager extends Implement.IOSCacheManager {
            }
    }
    export default Hardware;
}

